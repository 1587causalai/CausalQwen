# `examples` 目录说明

本目录中的示例脚本旨在演示 `CausalQwen` 项目的核心功能，特别是在处理真实世界数据（如存在标签噪声）时的表现。

## 两种实现风格：`原始版本` vs `scikit-learn 版本`

您会注意到，目录中的许多脚本都成对出现，例如：

*   `real_world_regression_tutorial.py`
*   `real_world_sklearn_tutorial.py`

这两套脚本实现了完全相同的科学目标：在加州房价数据集上，比较 `CausalEngine` 与传统机器学习模型在不同标签异常水平下的性能。然而，它们采用了两种截然不同的代码实现和 API 设计理念。

这种"同一目的，两种实现"的结构为我们提供了一个绝佳的机会来交叉验证核心算法的正确性与健壮性。

### 1. 原始版本 (例如: `real_world_regression_tutorial.py`)

这套脚本可以被看作是项目的"内部"或"v1"版本。

*   **核心抽象**: 依赖一个名为 `BaselineBenchmark` 的高级封装类。这个类内部处理了数据分割、模型训练、评估等所有步骤。
*   **使用方式**: 用户通过配置参数，然后调用一个核心函数（`benchmark.compare_models(...)`）来启动整个实验流程。
*   **优点**: 对于固定的实验流程，调用非常简洁。
*   **缺点**: 灵活性和透明度较低。用户很难自定义实验流程或深入了解底层的训练细节。

### 2. scikit-learn 版本 (例如: `real_world_sklearn_tutorial.py`)

这是项目**推荐的、现代化的**实现方式。

*   **核心抽象**: 将 `CausalEngine` 封装成了与 `scikit-learn` API 完全兼容的模型（例如 `MLPCausalRegressor`）。这些模型具备标准的 `.fit(X, y)` 和 `.predict(X)` 接口。
*   **使用方式**: 用户可以像使用 scikit-learn 中任何一个标准模型一样来使用 `CausalEngine`。整个实验流程被清晰地、一步步地在脚本中展示出来。
*   **优点**:
    *   **高度灵活与透明**: 用户可以完全掌控实验的每一个环节。
    *   **符合行业标准**: 任何熟悉 scikit-learn 的开发者都能零成本上手。
    *   **易于集成**: 可以无缝地与 `scikit-learn` 的生态（如 `Pipeline`, `GridSearchCV`）结合。

## 结论与建议

两套代码最终都导向了相同的科学结论，验证了 `CausalEngine` 的有效性。

我们强烈建议新用户和开发者：

> **优先学习和使用带有 `_sklearn` 后缀的脚本。**

它们不仅代表了项目未来的方向，也提供了更优秀、更灵活的编程体验。保留原始版本的脚本主要是为了历史追溯和逻辑的交叉验证。 