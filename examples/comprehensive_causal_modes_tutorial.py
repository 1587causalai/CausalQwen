#!/usr/bin/env python3
"""
ğŸ  å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹ï¼šåŠ å·æˆ¿ä»·é¢„æµ‹
=========================================

è¿™ä¸ªæ•™ç¨‹æ¼”ç¤ºæ‰€æœ‰5ç§CausalEngineæ¨ç†æ¨¡å¼åœ¨çœŸå®ä¸–ç•Œå›å½’ä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚

æ•°æ®é›†ï¼šåŠ å·æˆ¿ä»·æ•°æ®é›†ï¼ˆCalifornia Housing Datasetï¼‰
- 20,640ä¸ªæ ·æœ¬
- 8ä¸ªç‰¹å¾ï¼ˆæˆ¿å±‹å¹´é¾„ã€æ”¶å…¥ã€äººå£ç­‰ï¼‰
- ç›®æ ‡ï¼šé¢„æµ‹æˆ¿ä»·ä¸­ä½æ•°

æˆ‘ä»¬å°†æ¯”è¾ƒæ‰€æœ‰7ç§æ–¹æ³•ï¼š
1. sklearn MLPRegressorï¼ˆä¼ ç»Ÿç¥ç»ç½‘ç»œï¼‰
2. PyTorch MLPï¼ˆä¼ ç»Ÿæ·±åº¦å­¦ä¹ ï¼‰
3. CausalEngine - deterministicï¼ˆç¡®å®šæ€§æ¨ç†ï¼‰
4. CausalEngine - exogenousï¼ˆå¤–ç”Ÿå™ªå£°ä¸»å¯¼ï¼‰
5. CausalEngine - endogenousï¼ˆå†…ç”Ÿä¸ç¡®å®šæ€§ä¸»å¯¼ï¼‰
6. CausalEngine - standardï¼ˆå†…ç”Ÿ+å¤–ç”Ÿæ··åˆï¼‰
7. CausalEngine - samplingï¼ˆé‡‡æ ·å¼å› æœæ¨ç†ï¼‰

å…³é”®äº®ç‚¹ï¼š
- 5ç§CausalEngineæ¨ç†æ¨¡å¼çš„å…¨é¢å¯¹æ¯”
- çœŸå®ä¸–ç•Œæ•°æ®çš„é²æ£’æ€§æµ‹è¯•
- å› æœæ¨ç†ä¸åŒæ¨¡å¼çš„æ€§èƒ½å·®å¼‚åˆ†æ

å®éªŒè®¾è®¡è¯´æ˜
==================================================================
æœ¬è„šæœ¬ä¸“æ³¨äºå…¨é¢è¯„ä¼°CausalEngineçš„5ç§æ¨ç†æ¨¡å¼ï¼Œæ—¨åœ¨æ­ç¤ºä¸åŒå› æœæ¨ç†ç­–ç•¥
åœ¨çœŸå®å›å½’ä»»åŠ¡ä¸Šçš„æ€§èƒ½ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚

æ ¸å¿ƒå®éªŒï¼šå…¨æ¨¡å¼æ€§èƒ½å¯¹æ¯” (åœ¨25%æ ‡ç­¾å™ªå£°ä¸‹)
--------------------------------------------------
- **ç›®æ ‡**: æ¯”è¾ƒæ‰€æœ‰5ç§CausalEngineæ¨¡å¼å’Œä¼ ç»Ÿæ–¹æ³•çš„é¢„æµ‹æ€§èƒ½
- **è®¾ç½®**: 25%æ ‡ç­¾å™ªå£°ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œæ•°æ®è´¨é‡æŒ‘æˆ˜
- **å¯¹æ¯”æ¨¡å‹**: 
  - ä¼ ç»Ÿæ–¹æ³•: sklearn MLPRegressor, PyTorch MLP
  - CausalEngine: deterministic, exogenous, endogenous, standard, sampling
- **åˆ†æé‡ç‚¹**: 
  - å“ªç§å› æœæ¨ç†æ¨¡å¼è¡¨ç°æœ€ä¼˜ï¼Ÿ
  - ä¸åŒæ¨¡å¼çš„æ€§èƒ½ç‰¹ç‚¹å’Œå·®å¼‚
  - å› æœæ¨ç†ç›¸å¯¹ä¼ ç»Ÿæ–¹æ³•çš„ä¼˜åŠ¿
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
import warnings
import os
import sys

# è®¾ç½®matplotlibåç«¯ä¸ºéäº¤äº’å¼ï¼Œé¿å…å¼¹å‡ºçª—å£
plt.switch_backend('Agg')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•æ¨¡å—
from causal_sklearn.benchmarks import BaselineBenchmark

warnings.filterwarnings('ignore')


class ComprehensiveTutorialConfig:
    """
    å…¨é¢æ•™ç¨‹é…ç½®ç±» - æµ‹è¯•æ‰€æœ‰CausalEngineæ¨¡å¼
    
    ğŸ”§ åœ¨è¿™é‡Œä¿®æ”¹å‚æ•°æ¥è‡ªå®šä¹‰å®éªŒè®¾ç½®ï¼
    """
    
    # ğŸ¯ æ•°æ®åˆ†å‰²å‚æ•°
    TEST_SIZE = 0.2          # æµ‹è¯•é›†æ¯”ä¾‹
    VAL_SIZE = 0.2           # éªŒè¯é›†æ¯”ä¾‹ (ç›¸å¯¹äºè®­ç»ƒé›†)
    RANDOM_STATE = 42        # éšæœºç§å­
    
    # ğŸ¤– CausalEngineå‚æ•° - æµ‹è¯•æ‰€æœ‰5ç§æ¨¡å¼ï¼
    CAUSAL_MODES = ['deterministic', 'exogenous', 'endogenous', 'standard', 'sampling']
    CAUSAL_HIDDEN_SIZES = (128, 64)              # CausalEngineéšè—å±‚
    CAUSAL_MAX_EPOCHS = 1000                     # æœ€å¤§è®­ç»ƒè½®æ•°
    CAUSAL_LR = 0.01                             # CausalEngineå­¦ä¹ ç‡
    CAUSAL_PATIENCE = 50                         # æ—©åœpatience
    CAUSAL_TOL = 1e-4                            # æ—©åœtolerance
    CAUSAL_GAMMA_INIT = 1.0                      # gammaåˆå§‹åŒ–
    CAUSAL_B_NOISE_INIT = 1.0                    # b_noiseåˆå§‹åŒ–
    CAUSAL_B_NOISE_TRAINABLE = True              # b_noiseæ˜¯å¦å¯è®­ç»ƒ
    
    # ğŸ§  ä¼ ç»Ÿæ–¹æ³•å‚æ•°
    SKLEARN_HIDDEN_LAYERS = (128, 64)            # sklearn MLPéšè—å±‚
    SKLEARN_MAX_ITER = 1000                      # sklearnæœ€å¤§è¿­ä»£æ•°
    SKLEARN_LR = 0.01                            # sklearnå­¦ä¹ ç‡
    
    PYTORCH_EPOCHS = 3000                        # PyTorchè®­ç»ƒè½®æ•°
    PYTORCH_LR = 0.03                            # PyTorchå­¦ä¹ ç‡
    PYTORCH_PATIENCE = 20                        # PyTorchæ—©åœpatience
    
    # ğŸ“Š å®éªŒå‚æ•°
    ANOMALY_RATIO = 0.25                         # æ ‡ç­¾å¼‚å¸¸æ¯”ä¾‹ (25%å™ªå£°æŒ‘æˆ˜)
    SAVE_PLOTS = True                            # æ˜¯å¦ä¿å­˜å›¾è¡¨
    VERBOSE = True                               # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
    
    # ğŸ“ˆ å¯è§†åŒ–å‚æ•°
    FIGURE_DPI = 300                             # å›¾è¡¨åˆ†è¾¨ç‡
    FIGURE_SIZE_ANALYSIS = (16, 12)              # æ•°æ®åˆ†æå›¾è¡¨å¤§å°
    FIGURE_SIZE_PERFORMANCE = (20, 14)           # æ€§èƒ½å¯¹æ¯”å›¾è¡¨å¤§å°ï¼ˆæ›´å¤§ä»¥å®¹çº³7ä¸ªæ–¹æ³•ï¼‰
    FIGURE_SIZE_MODES_COMPARISON = (18, 12)      # CausalEngineæ¨¡å¼å¯¹æ¯”å›¾è¡¨å¤§å°
    
    # ğŸ“ è¾“å‡ºç›®å½•å‚æ•°
    OUTPUT_DIR = "results/comprehensive_causal_modes"


class ComprehensiveCausalModesTutorial:
    """
    å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹ç±»
    
    æ¼”ç¤ºæ‰€æœ‰5ç§CausalEngineæ¨ç†æ¨¡å¼åœ¨çœŸå®ä¸–ç•Œå›å½’ä»»åŠ¡ä¸­çš„æ€§èƒ½ç‰¹ç‚¹
    """
    
    def __init__(self, config=None):
        self.config = config if config is not None else ComprehensiveTutorialConfig()
        self.X = None
        self.y = None
        self.feature_names = None
        self.results = {}
        self._ensure_output_dir()
    
    def _ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.config.OUTPUT_DIR):
            os.makedirs(self.config.OUTPUT_DIR)
            print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {self.config.OUTPUT_DIR}/")
    
    def _get_output_path(self, filename):
        """è·å–è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
        return os.path.join(self.config.OUTPUT_DIR, filename)
        
    def load_and_explore_data(self, verbose=True):
        """åŠ è½½å¹¶æ¢ç´¢åŠ å·æˆ¿ä»·æ•°æ®é›†"""
        if verbose:
            print("ğŸ  å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹ - åŠ å·æˆ¿ä»·é¢„æµ‹")
            print("=" * 70)
            print("ğŸ“Š æ­£åœ¨åŠ è½½åŠ å·æˆ¿ä»·æ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®
        housing = fetch_california_housing()
        self.X, self.y = housing.data, housing.target
        self.feature_names = housing.feature_names
        
        if verbose:
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
            print(f"   - æ ·æœ¬æ•°é‡: {self.X.shape[0]:,}")
            print(f"   - ç‰¹å¾æ•°é‡: {self.X.shape[1]}")
            print(f"   - ç‰¹å¾åç§°: {', '.join(self.feature_names)}")
            print(f"   - ç›®æ ‡èŒƒå›´: ${self.y.min():.2f} - ${self.y.max():.2f} (ç™¾ä¸‡ç¾å…ƒ)")
            print(f"   - ç›®æ ‡å‡å€¼: ${self.y.mean():.2f}")
            print(f"   - ç›®æ ‡æ ‡å‡†å·®: ${self.y.std():.2f}")
        
        return self.X, self.y
    
    def visualize_data(self, save_plots=None):
        """æ•°æ®å¯è§†åŒ–åˆ†æ"""
        if save_plots is None:
            save_plots = self.config.SAVE_PLOTS
            
        print("\nğŸ“ˆ æ•°æ®åˆ†å¸ƒåˆ†æ")
        print("-" * 30)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=self.config.FIGURE_SIZE_ANALYSIS)
        fig.suptitle('California Housing Dataset Analysis - Comprehensive CausalEngine Modes Tutorial', fontsize=16, fontweight='bold')
        
        # 1. ç›®æ ‡å˜é‡åˆ†å¸ƒ
        axes[0, 0].hist(self.y, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('House Price Distribution')
        axes[0, 0].set_xlabel('House Price ($100k)')
        axes[0, 0].set_ylabel('Frequency')
        axes[0, 0].axvline(self.y.mean(), color='red', linestyle='--', label=f'Mean: ${self.y.mean():.2f}')
        axes[0, 0].legend()
        
        # 2. ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
        df = pd.DataFrame(self.X, columns=self.feature_names)
        df['MedHouseVal'] = self.y
        corr_matrix = df.corr()
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, ax=axes[0, 1], cbar_kws={'shrink': 0.8})
        axes[0, 1].set_title('Feature Correlation Matrix')
        
        # 3. ç‰¹å¾åˆ†å¸ƒç®±çº¿å›¾
        df_features = pd.DataFrame(self.X, columns=self.feature_names)
        df_features_normalized = (df_features - df_features.mean()) / df_features.std()
        df_features_normalized.boxplot(ax=axes[1, 0])
        axes[1, 0].set_title('Feature Distribution (Standardized)')
        axes[1, 0].set_xlabel('Features')
        axes[1, 0].set_ylabel('Standardized Values')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 4. æœ€é‡è¦ç‰¹å¾ä¸ç›®æ ‡çš„æ•£ç‚¹å›¾
        most_corr_feature = corr_matrix['MedHouseVal'].abs().sort_values(ascending=False).index[1]
        most_corr_idx = list(self.feature_names).index(most_corr_feature)
        axes[1, 1].scatter(self.X[:, most_corr_idx], self.y, alpha=0.5, s=1)
        axes[1, 1].set_title(f'Most Correlated Feature: {most_corr_feature}')
        axes[1, 1].set_xlabel(most_corr_feature)
        axes[1, 1].set_ylabel('House Price ($100k)')
        
        plt.tight_layout()
        
        if save_plots:
            output_path = self._get_output_path('comprehensive_data_analysis.png')
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š æ•°æ®åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()  # å…³é—­å›¾å½¢ï¼Œé¿å…å†…å­˜æ³„æ¼
        
        # æ•°æ®ç»Ÿè®¡æ‘˜è¦
        print("\nğŸ“‹ æ•°æ®ç»Ÿè®¡æ‘˜è¦:")
        print(f"  - æœ€ç›¸å…³ç‰¹å¾: {most_corr_feature} (ç›¸å…³ç³»æ•°: {corr_matrix.loc[most_corr_feature, 'MedHouseVal']:.3f})")
        print(f"  - å¼‚å¸¸å€¼æ£€æµ‹: {np.sum(np.abs(self.y - self.y.mean()) > 3 * self.y.std())} ä¸ªæ½œåœ¨å¼‚å¸¸å€¼")
        print(f"  - æ•°æ®å®Œæ•´æ€§: æ— ç¼ºå¤±å€¼" if not np.any(np.isnan(self.X)) else "  - è­¦å‘Š: å­˜åœ¨ç¼ºå¤±å€¼")
    
    def run_comprehensive_benchmark(self, test_size=None, val_size=None, anomaly_ratio=None, verbose=None):
        """è¿è¡Œå…¨é¢çš„åŸºå‡†æµ‹è¯• - åŒ…å«æ‰€æœ‰5ç§CausalEngineæ¨¡å¼"""
        # ä½¿ç”¨é…ç½®å‚æ•°ä½œä¸ºé»˜è®¤å€¼
        if test_size is None:
            test_size = self.config.TEST_SIZE
        if val_size is None:
            val_size = self.config.VAL_SIZE
        if anomaly_ratio is None:
            anomaly_ratio = self.config.ANOMALY_RATIO
        if verbose is None:
            verbose = self.config.VERBOSE
            
        if verbose:
            print("\nğŸš€ å¼€å§‹å…¨é¢åŸºå‡†æµ‹è¯• - æµ‹è¯•æ‰€æœ‰5ç§CausalEngineæ¨¡å¼")
            print("=" * 80)
            print(f"ğŸ”§ å®éªŒé…ç½®:")
            print(f"   - æµ‹è¯•é›†æ¯”ä¾‹: {test_size:.1%}")
            print(f"   - éªŒè¯é›†æ¯”ä¾‹: {val_size:.1%}")
            print(f"   - å¼‚å¸¸æ ‡ç­¾æ¯”ä¾‹: {anomaly_ratio:.1%}")
            print(f"   - éšæœºç§å­: {self.config.RANDOM_STATE}")
            print(f"   - CausalEngineæ¨¡å¼: {', '.join(self.config.CAUSAL_MODES)}")
            print(f"   - CausalEngineç½‘ç»œ: {self.config.CAUSAL_HIDDEN_SIZES}")
            print(f"   - æœ€å¤§è®­ç»ƒè½®æ•°: {self.config.CAUSAL_MAX_EPOCHS}")
            print(f"   - æ—©åœpatience: {self.config.CAUSAL_PATIENCE}")
            print(f"   - æ€»è®¡å¯¹æ¯”æ–¹æ³•: {len(self.config.CAUSAL_MODES) + 2} ç§ (5ç§CausalEngine + 2ç§ä¼ ç»Ÿ)")
        
        # ä½¿ç”¨åŸºå‡†æµ‹è¯•æ¨¡å—
        benchmark = BaselineBenchmark()
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        self.results = benchmark.compare_models(
            X=self.X,
            y=self.y,
            task_type='regression',
            test_size=test_size,
            val_size=val_size,
            anomaly_ratio=anomaly_ratio,
            random_state=self.config.RANDOM_STATE,
            verbose=verbose,
            # CausalEngineå‚æ•° - åŒ…å«æ‰€æœ‰5ç§æ¨¡å¼
            causal_modes=self.config.CAUSAL_MODES,
            hidden_sizes=self.config.CAUSAL_HIDDEN_SIZES,
            max_epochs=self.config.CAUSAL_MAX_EPOCHS,
            lr=self.config.CAUSAL_LR,
            patience=self.config.CAUSAL_PATIENCE,
            tol=self.config.CAUSAL_TOL,
            gamma_init=self.config.CAUSAL_GAMMA_INIT,
            b_noise_init=self.config.CAUSAL_B_NOISE_INIT,
            b_noise_trainable=self.config.CAUSAL_B_NOISE_TRAINABLE,
            # sklearn/PyTorchå‚æ•°
            hidden_layer_sizes=self.config.SKLEARN_HIDDEN_LAYERS,
            max_iter=self.config.SKLEARN_MAX_ITER,
            learning_rate=self.config.SKLEARN_LR
        )
        
        if verbose:
            print(f"\nğŸ“Š å…¨é¢åŸºå‡†æµ‹è¯•ç»“æœ (å¼‚å¸¸æ¯”ä¾‹: {anomaly_ratio:.0%})")
            benchmark.print_results(self.results, 'regression')
        
        return self.results
    
    def analyze_causal_modes_performance(self, verbose=True):
        """ä¸“é—¨åˆ†æCausalEngineä¸åŒæ¨¡å¼çš„æ€§èƒ½ç‰¹ç‚¹"""
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        if verbose:
            print("\nğŸ”¬ CausalEngineæ¨¡å¼æ·±åº¦åˆ†æ")
            print("=" * 70)
        
        # æå–CausalEngineæ¨¡å¼ç»“æœ
        causal_results = {}
        traditional_results = {}
        
        for method, metrics in self.results.items():
            if method in self.config.CAUSAL_MODES:
                causal_results[method] = metrics
            elif method in ['sklearn', 'pytorch']:
                traditional_results[method] = metrics
        
        if verbose:
            print(f"ğŸ¯ CausalEngineæ¨¡å¼æ€§èƒ½å¯¹æ¯” (å…±{len(causal_results)}ç§æ¨¡å¼):")
            print("-" * 50)
            
            # æŒ‰RÂ²åˆ†æ•°æ’åº
            causal_r2_scores = {mode: metrics['test']['RÂ²'] for mode, metrics in causal_results.items()}
            sorted_causal = sorted(causal_r2_scores.items(), key=lambda x: x[1], reverse=True)
            
            for i, (mode, r2) in enumerate(sorted_causal, 1):
                mae = causal_results[mode]['test']['MAE']
                rmse = causal_results[mode]['test']['RMSE']
                print(f"   {i}. {mode:<12} - RÂ²: {r2:.4f}, MAE: {mae:.3f}, RMSE: {rmse:.3f}")
            
            # æ¨¡å¼ç‰¹ç‚¹åˆ†æ
            print(f"\nğŸ“Š æ¨¡å¼ç‰¹ç‚¹åˆ†æ:")
            print("-" * 30)
            
            best_mode = sorted_causal[0][0]
            worst_mode = sorted_causal[-1][0]
            performance_gap = sorted_causal[0][1] - sorted_causal[-1][1]
            
            print(f"   ğŸ† æœ€ä½³æ¨¡å¼: {best_mode} (RÂ² = {sorted_causal[0][1]:.4f})")
            print(f"   ğŸ“‰ æœ€å¼±æ¨¡å¼: {worst_mode} (RÂ² = {sorted_causal[-1][1]:.4f})")
            print(f"   ğŸ“ æ€§èƒ½å·®è·: {performance_gap:.4f} ({performance_gap/sorted_causal[-1][1]*100:.1f}%)")
            
            # ä¸ä¼ ç»Ÿæ–¹æ³•æ¯”è¾ƒ
            if traditional_results:
                print(f"\nğŸ†š CausalEngine vs ä¼ ç»Ÿæ–¹æ³•:")
                print("-" * 40)
                
                traditional_r2_scores = {method: metrics['test']['RÂ²'] for method, metrics in traditional_results.items()}
                best_traditional = max(traditional_r2_scores.keys(), key=lambda x: traditional_r2_scores[x])
                best_traditional_r2 = traditional_r2_scores[best_traditional]
                
                print(f"   æœ€ä½³ä¼ ç»Ÿæ–¹æ³•: {best_traditional} (RÂ² = {best_traditional_r2:.4f})")
                print(f"   æœ€ä½³CausalEngine: {best_mode} (RÂ² = {sorted_causal[0][1]:.4f})")
                
                improvement = (sorted_causal[0][1] - best_traditional_r2) / abs(best_traditional_r2) * 100
                print(f"   æ€§èƒ½æå‡: {improvement:+.2f}%")
                
                # ç»Ÿè®¡æœ‰å¤šå°‘CausalEngineæ¨¡å¼ä¼˜äºæœ€ä½³ä¼ ç»Ÿæ–¹æ³•
                better_modes = sum(1 for _, r2 in sorted_causal if r2 > best_traditional_r2)
                print(f"   ä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„CausalEngineæ¨¡å¼: {better_modes}/{len(sorted_causal)}")
        
        return causal_results, traditional_results
    
    def create_comprehensive_performance_visualization(self, save_plot=None):
        """åˆ›å»ºå…¨é¢çš„æ€§èƒ½å¯è§†åŒ–å›¾è¡¨ - å±•ç¤ºæ‰€æœ‰7ç§æ–¹æ³•"""
        if save_plot is None:
            save_plot = self.config.SAVE_PLOTS
            
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        print("\nğŸ“Š åˆ›å»ºå…¨é¢æ€§èƒ½å¯è§†åŒ–å›¾è¡¨")
        print("-" * 40)
        
        # å‡†å¤‡æ•°æ® - æŒ‰ç…§é€»è¾‘é¡ºåºæ’åˆ—ï¼šä¼ ç»Ÿæ–¹æ³• + CausalEngineæ¨¡å¼
        methods_order = ['sklearn', 'pytorch'] + self.config.CAUSAL_MODES
        methods = [m for m in methods_order if m in self.results]
        
        # ä¸ºä¸åŒç±»å‹çš„æ–¹æ³•è®¾ç½®é¢œè‰²
        colors = []
        for method in methods:
            if method == 'sklearn':
                colors.append('#1f77b4')  # è“è‰²
            elif method == 'pytorch':
                colors.append('#ff7f0e')  # æ©™è‰²
            elif method in self.config.CAUSAL_MODES:
                colors.append('#2ca02c')  # ç»¿è‰²ç³»
            else:
                colors.append('#d62728')  # çº¢è‰²
        
        metrics = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        
        # åˆ›å»ºå­å›¾ - 2x2å¸ƒå±€å±•ç¤º4ä¸ªæŒ‡æ ‡
        fig, axes = plt.subplots(2, 2, figsize=self.config.FIGURE_SIZE_PERFORMANCE)
        fig.suptitle('Comprehensive CausalEngine Modes vs Traditional Methods\nCalifornia Housing Performance (25% Label Noise)', 
                     fontsize=16, fontweight='bold')
        axes = axes.flatten()
        
        for i, metric in enumerate(metrics):
            values = [self.results[method]['test'][metric] for method in methods]
            
            bars = axes[i].bar(range(len(methods)), values, color=colors, alpha=0.8, edgecolor='black')
            axes[i].set_title(f'{metric} (Test Set)', fontweight='bold')
            axes[i].set_ylabel(metric)
            
            # è®¾ç½®Xè½´æ ‡ç­¾
            method_labels = []
            for method in methods:
                if method == 'sklearn':
                    method_labels.append('sklearn\nMLP')
                elif method == 'pytorch':
                    method_labels.append('PyTorch\nMLP')
                else:
                    method_labels.append(f'CausalEngine\n({method})')
            
            axes[i].set_xticks(range(len(methods)))
            axes[i].set_xticklabels(method_labels, rotation=45, ha='right')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, values):
                height = bar.get_height()
                axes[i].text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
            
            # é«˜äº®æœ€ä½³ç»“æœ
            if metric == 'RÂ²':
                best_idx = values.index(max(values))
            else:
                best_idx = values.index(min(values))
            bars[best_idx].set_color('gold')
            bars[best_idx].set_edgecolor('red')
            bars[best_idx].set_linewidth(3)
        
        plt.tight_layout()
        
        if save_plot:
            output_path = self._get_output_path('comprehensive_performance_comparison.png')
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š å…¨é¢æ€§èƒ½å›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()
    
    def create_causal_modes_comparison(self, save_plot=None):
        """åˆ›å»ºä¸“é—¨çš„CausalEngineæ¨¡å¼å¯¹æ¯”å›¾è¡¨"""
        if save_plot is None:
            save_plot = self.config.SAVE_PLOTS
            
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        print("\nğŸ“Š åˆ›å»ºCausalEngineæ¨¡å¼ä¸“é¡¹å¯¹æ¯”å›¾è¡¨")
        print("-" * 45)
        
        # æå–CausalEngineæ¨¡å¼ç»“æœ
        causal_methods = [m for m in self.config.CAUSAL_MODES if m in self.results]
        
        if len(causal_methods) < 2:
            print("âŒ éœ€è¦è‡³å°‘2ç§CausalEngineæ¨¡å¼æ¥è¿›è¡Œå¯¹æ¯”")
            return
        
        # åˆ›å»ºé›·è¾¾å›¾æ˜¾ç¤ºCausalEngineæ¨¡å¼çš„å¤šç»´æ€§èƒ½
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=self.config.FIGURE_SIZE_MODES_COMPARISON)
        fig.suptitle('CausalEngine Modes Detailed Comparison', fontsize=16, fontweight='bold')
        
        # å·¦å›¾ï¼šæ€§èƒ½æ¡å½¢å›¾
        metrics = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        colors = plt.cm.Set3(np.linspace(0, 1, len(causal_methods)))
        
        x = np.arange(len(metrics))
        width = 0.15
        
        for i, method in enumerate(causal_methods):
            values = [self.results[method]['test'][metric] for metric in metrics]
            ax1.bar(x + i * width, values, width, label=f'{method}', color=colors[i], alpha=0.8)
        
        ax1.set_xlabel('Metrics')
        ax1.set_ylabel('Values')
        ax1.set_title('CausalEngine Modes Performance Comparison')
        ax1.set_xticks(x + width * (len(causal_methods) - 1) / 2)
        ax1.set_xticklabels(metrics)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å³å›¾ï¼šRÂ²æ€§èƒ½æ’å
        r2_scores = [(method, self.results[method]['test']['RÂ²']) for method in causal_methods]
        r2_scores.sort(key=lambda x: x[1], reverse=True)
        
        methods_sorted = [item[0] for item in r2_scores]
        r2_values = [item[1] for item in r2_scores]
        
        bars = ax2.bar(range(len(methods_sorted)), r2_values, color=colors[:len(methods_sorted)], alpha=0.8)
        ax2.set_xlabel('CausalEngine Modes')
        ax2.set_ylabel('RÂ² Score')
        ax2.set_title('CausalEngine Modes RÂ² Performance Ranking')
        ax2.set_xticks(range(len(methods_sorted)))
        ax2.set_xticklabels(methods_sorted, rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, r2_values):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        # é«˜äº®æœ€ä½³æ¨¡å¼
        bars[0].set_color('gold')
        bars[0].set_edgecolor('red')
        bars[0].set_linewidth(3)
        
        plt.tight_layout()
        
        if save_plot:
            output_path = self._get_output_path('causal_modes_detailed_comparison.png')
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š CausalEngineæ¨¡å¼å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()
    
    def print_comprehensive_summary(self):
        """æ‰“å°å…¨é¢çš„æ€»ç»“æŠ¥å‘Š"""
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        print("\nğŸ“‹ å…¨é¢å®éªŒæ€»ç»“æŠ¥å‘Š")
        print("=" * 80)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_methods = len(self.results)
        causal_methods = len([m for m in self.results if m in self.config.CAUSAL_MODES])
        traditional_methods = len([m for m in self.results if m in ['sklearn', 'pytorch']])
        
        print(f"ğŸ”¢ å®éªŒè§„æ¨¡:")
        print(f"   - æ€»è®¡æµ‹è¯•æ–¹æ³•: {total_methods}")
        print(f"   - CausalEngineæ¨¡å¼: {causal_methods}")
        print(f"   - ä¼ ç»Ÿæ–¹æ³•: {traditional_methods}")
        print(f"   - æ•°æ®é›†å¤§å°: {self.X.shape[0]:,} æ ·æœ¬ Ã— {self.X.shape[1]} ç‰¹å¾")
        print(f"   - å¼‚å¸¸æ ‡ç­¾æ¯”ä¾‹: {self.config.ANOMALY_RATIO:.1%}")
        
        # æ€§èƒ½æ’å
        print(f"\nğŸ† æ€»ä½“æ€§èƒ½æ’å (æŒ‰RÂ²åˆ†æ•°):")
        print("-" * 50)
        
        all_r2_scores = [(method, metrics['test']['RÂ²']) for method, metrics in self.results.items()]
        all_r2_scores.sort(key=lambda x: x[1], reverse=True)
        
        for i, (method, r2) in enumerate(all_r2_scores, 1):
            method_type = "CausalEngine" if method in self.config.CAUSAL_MODES else "Traditional"
            print(f"   {i:2d}. {method:<15} ({method_type:<12}) - RÂ²: {r2:.4f}")
        
        # CausalEngineä¼˜åŠ¿åˆ†æ
        print(f"\nğŸ¯ CausalEngineæ¨¡å¼åˆ†æ:")
        print("-" * 40)
        
        causal_results = [(method, metrics['test']['RÂ²']) for method, metrics in self.results.items() 
                         if method in self.config.CAUSAL_MODES]
        traditional_results = [(method, metrics['test']['RÂ²']) for method, metrics in self.results.items() 
                              if method in ['sklearn', 'pytorch']]
        
        if causal_results and traditional_results:
            best_causal = max(causal_results, key=lambda x: x[1])
            best_traditional = max(traditional_results, key=lambda x: x[1])
            
            print(f"   æœ€ä½³CausalEngineæ¨¡å¼: {best_causal[0]} (RÂ² = {best_causal[1]:.4f})")
            print(f"   æœ€ä½³ä¼ ç»Ÿæ–¹æ³•: {best_traditional[0]} (RÂ² = {best_traditional[1]:.4f})")
            
            improvement = (best_causal[1] - best_traditional[1]) / abs(best_traditional[1]) * 100
            print(f"   æ€§èƒ½æå‡: {improvement:+.2f}%")
            
            # ç»Ÿè®¡ä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„CausalEngineæ¨¡å¼æ•°é‡
            better_causal_count = sum(1 for _, r2 in causal_results if r2 > best_traditional[1])
            print(f"   ä¼˜äºæœ€ä½³ä¼ ç»Ÿæ–¹æ³•çš„CausalEngineæ¨¡å¼: {better_causal_count}/{len(causal_results)}")
        
        # å…³é”®å‘ç°
        print(f"\nğŸ’¡ å…³é”®å‘ç°:")
        print("-" * 20)
        
        if len(all_r2_scores) > 0:
            top_method = all_r2_scores[0]
            if top_method[0] in self.config.CAUSAL_MODES:
                print(f"   âœ… CausalEngineæ¨¡å¼ '{top_method[0]}' å–å¾—æœ€ä½³æ€§èƒ½")
                print(f"   âœ… å› æœæ¨ç†ç›¸å¯¹ä¼ ç»Ÿæ–¹æ³•æ˜¾ç¤ºå‡ºæ˜æ˜¾ä¼˜åŠ¿")
            else:
                print(f"   âš ï¸ ä¼ ç»Ÿæ–¹æ³• '{top_method[0]}' åœ¨æ­¤æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä¼˜")
                print(f"   âš ï¸ å»ºè®®è¿›ä¸€æ­¥è°ƒä¼˜CausalEngineå‚æ•°")
            
            # æ£€æŸ¥CausalEngineæ¨¡å¼é—´çš„å·®å¼‚
            if len(causal_results) > 1:
                causal_r2_values = [r2 for _, r2 in causal_results]
                causal_std = np.std(causal_r2_values)
                print(f"   ğŸ“Š CausalEngineæ¨¡å¼é—´æ€§èƒ½æ ‡å‡†å·®: {causal_std:.4f}")
                if causal_std < 0.01:
                    print(f"   ğŸ“ˆ ä¸åŒCausalEngineæ¨¡å¼æ€§èƒ½è¾ƒä¸ºæ¥è¿‘")
                else:
                    print(f"   ğŸ“ˆ ä¸åŒCausalEngineæ¨¡å¼å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®å¼‚")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹"""
    print("ğŸ  å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹")
    print("ğŸ¯ ç›®æ ‡ï¼šæµ‹è¯•æ‰€æœ‰5ç§CausalEngineæ¨ç†æ¨¡å¼åœ¨çœŸå®ä¸–ç•Œå›å½’ä»»åŠ¡ä¸­çš„è¡¨ç°")
    print("=" * 90)
    
    # åˆ›å»ºé…ç½®å®ä¾‹
    config = ComprehensiveTutorialConfig()
    
    print(f"ğŸ”§ å½“å‰é…ç½®:")
    print(f"   - CausalEngineæ¨¡å¼: {', '.join(config.CAUSAL_MODES)} (å…±{len(config.CAUSAL_MODES)}ç§)")
    print(f"   - ç½‘ç»œæ¶æ„: {config.CAUSAL_HIDDEN_SIZES}")
    print(f"   - æœ€å¤§è½®æ•°: {config.CAUSAL_MAX_EPOCHS}")
    print(f"   - æ—©åœpatience: {config.CAUSAL_PATIENCE}")
    print(f"   - å¼‚å¸¸æ¯”ä¾‹: {config.ANOMALY_RATIO:.1%}")
    print(f"   - æ€»è®¡å¯¹æ¯”æ–¹æ³•: {len(config.CAUSAL_MODES) + 2} ç§")
    print(f"   - è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}/")
    print()
    
    # åˆ›å»ºæ•™ç¨‹å®ä¾‹
    tutorial = ComprehensiveCausalModesTutorial(config)
    
    # 1. åŠ è½½å’Œæ¢ç´¢æ•°æ®
    tutorial.load_and_explore_data()
    
    # 2. æ•°æ®å¯è§†åŒ–
    tutorial.visualize_data()
    
    # 3. è¿è¡Œå…¨é¢åŸºå‡†æµ‹è¯• - æµ‹è¯•æ‰€æœ‰5ç§CausalEngineæ¨¡å¼
    tutorial.run_comprehensive_benchmark()
    
    # 4. ä¸“é—¨åˆ†æCausalEngineæ¨¡å¼æ€§èƒ½
    tutorial.analyze_causal_modes_performance()
    
    # 5. åˆ›å»ºå…¨é¢æ€§èƒ½å¯è§†åŒ–
    tutorial.create_comprehensive_performance_visualization()
    
    # 6. åˆ›å»ºCausalEngineæ¨¡å¼ä¸“é¡¹å¯¹æ¯”
    tutorial.create_causal_modes_comparison()
    
    # 7. æ‰“å°å…¨é¢æ€»ç»“æŠ¥å‘Š
    tutorial.print_comprehensive_summary()
    
    print("\nğŸ‰ å…¨é¢CausalEngineæ¨¡å¼æ•™ç¨‹å®Œæˆï¼")
    print("ğŸ“‹ å®éªŒæ€»ç»“:")
    print(f"   - ä½¿ç”¨äº†çœŸå®ä¸–ç•Œçš„åŠ å·æˆ¿ä»·æ•°æ®é›† ({tutorial.X.shape[0]:,} æ ·æœ¬)")
    print(f"   - æµ‹è¯•äº†æ‰€æœ‰ {len(config.CAUSAL_MODES)} ç§CausalEngineæ¨ç†æ¨¡å¼")
    print(f"   - ä¸ 2 ç§ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œäº†å…¨é¢å¯¹æ¯”")
    print(f"   - åœ¨ {config.ANOMALY_RATIO:.0%} æ ‡ç­¾å™ªå£°ç¯å¢ƒä¸‹éªŒè¯äº†é²æ£’æ€§")
    print("   - æä¾›äº†è¯¦ç»†çš„æ¨¡å¼ç‰¹ç‚¹åˆ†æå’Œå¯è§†åŒ–")
    
    print("\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
    if config.SAVE_PLOTS:
        print(f"   - {config.OUTPUT_DIR}/comprehensive_data_analysis.png           (æ•°æ®åˆ†æå›¾)")
        print(f"   - {config.OUTPUT_DIR}/comprehensive_performance_comparison.png  (å…¨é¢æ€§èƒ½å¯¹æ¯”å›¾)")
        print(f"   - {config.OUTPUT_DIR}/causal_modes_detailed_comparison.png      (CausalEngineæ¨¡å¼ä¸“é¡¹å¯¹æ¯”å›¾)")
    
    print("\nğŸ’¡ æç¤ºï¼šé€šè¿‡ä¿®æ”¹ComprehensiveTutorialConfigç±»æ¥è‡ªå®šä¹‰å®éªŒå‚æ•°ï¼")
    print("ğŸ”¬ ä¸‹ä¸€æ­¥ï¼šå¯ä»¥å°è¯•ä¸åŒçš„æ•°æ®é›†æˆ–è°ƒæ•´æ¨¡å‹å‚æ•°æ¥è¿›ä¸€æ­¥éªŒè¯CausalEngineçš„ä¼˜è¶Šæ€§")


if __name__ == "__main__":
    main()