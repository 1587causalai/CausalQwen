#!/usr/bin/env python3
"""
ğŸ  æ‰©å±•ç‰ˆçœŸå®ä¸–ç•Œå›å½’æ•™ç¨‹ï¼šåŠ å·æˆ¿ä»·é¢„æµ‹ - Sklearnç‰ˆæœ¬
========================================================

è¿™ä¸ªæ•™ç¨‹æ¼”ç¤ºCausalEngineä¸å¤šç§å¼ºåŠ›ä¼ ç»Ÿæ–¹æ³•åœ¨çœŸå®ä¸–ç•Œå›å½’ä»»åŠ¡ä¸­çš„æ€§èƒ½å¯¹æ¯”ã€‚

ä¸åŸç‰ˆæ‰©å±•æ•™ç¨‹çš„åŒºåˆ«ï¼š
- ç›´æ¥ä½¿ç”¨sklearn-styleçš„MLPCausalRegressorã€MLPHuberRegressorç­‰å°è£…å¥½çš„learners
- ä¸ä¾èµ–BaselineBenchmarkç±»ï¼Œç›´æ¥è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œæ¯”è¾ƒ
- ä¿æŒæ‰€æœ‰åŸæœ‰åŠŸèƒ½ï¼šæ•°æ®æ¢ç´¢ã€å¯è§†åŒ–ã€æ€§èƒ½æ¯”è¾ƒã€é²æ£’æ€§æµ‹è¯•
- åŒ…å«æ›´å…¨é¢çš„é²æ£’æ€§å›å½’å™¨å¯¹æ¯”

æ•°æ®é›†ï¼šåŠ å·æˆ¿ä»·æ•°æ®é›†ï¼ˆCalifornia Housing Datasetï¼‰
- 20,640ä¸ªæ ·æœ¬
- 8ä¸ªç‰¹å¾ï¼ˆæˆ¿å±‹å¹´é¾„ã€æ”¶å…¥ã€äººå£ç­‰ï¼‰
- ç›®æ ‡ï¼šé¢„æµ‹æˆ¿ä»·ä¸­ä½æ•°

æˆ‘ä»¬å°†æ¯”è¾ƒ10ç§æ–¹æ³•ï¼š
1. sklearn MLPRegressorï¼ˆä¼ ç»Ÿç¥ç»ç½‘ç»œï¼‰
2. PyTorch MLPï¼ˆä¼ ç»Ÿæ·±åº¦å­¦ä¹ ï¼‰
3. MLP Huberï¼ˆHuberæŸå¤±ç¨³å¥å›å½’ï¼‰
4. MLP Pinballï¼ˆPinballæŸå¤±ç¨³å¥å›å½’ï¼‰
5. MLP Cauchyï¼ˆCauchyæŸå¤±ç¨³å¥å›å½’ï¼‰
6. Random Forestï¼ˆéšæœºæ£®æ—ï¼‰
7. CatBoostï¼ˆå¼ºåŠ›æ¢¯åº¦æå‡ï¼‰
8. XGBoostï¼ˆå¼ºåŠ›æ¢¯åº¦æå‡ï¼‰
9. CausalEngine - deterministicï¼ˆç¡®å®šæ€§å› æœæ¨ç†ï¼‰
10. CausalEngine - standardï¼ˆæ ‡å‡†å› æœæ¨ç†ï¼‰

å…³é”®äº®ç‚¹ï¼š
- çœŸå®ä¸–ç•Œæ•°æ®çš„é²æ£’æ€§æµ‹è¯•
- 8ç§å¼ºåŠ›ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•å¯¹æ¯”ï¼ˆ2ç§ç¥ç»ç½‘ç»œ + 3ç§ç¨³å¥å›å½’ + 3ç§é›†æˆæ–¹æ³•ï¼‰
- 3ç§ç¨³å¥ç¥ç»ç½‘ç»œå›å½’æ–¹æ³•ï¼ˆHuberã€Pinballã€Cauchyï¼‰
- 3ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼ˆRandom Forestã€CatBoostã€XGBoostï¼‰
- 2ç§å› æœæ¨ç†æ–¹æ³•ï¼ˆdeterministicã€standardï¼‰
- ç»Ÿä¸€ç¥ç»ç½‘ç»œå‚æ•°é…ç½®ç¡®ä¿å…¬å¹³æ¯”è¾ƒ
- å› æœæ¨ç†vsä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½å·®å¼‚åˆ†æ
- ç›´æ¥ä½¿ç”¨sklearn-style learners

å®éªŒè®¾è®¡è¯´æ˜
==================================================================
æœ¬è„šæœ¬åŒ…å«ä¸¤ç»„æ ¸å¿ƒå®éªŒï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°CausalEngineåœ¨çœŸå®å›å½’ä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚
æ‰€æœ‰å®éªŒå‚æ•°å‡å¯åœ¨ä¸‹æ–¹çš„ `TutorialConfig` ç±»ä¸­è¿›è¡Œä¿®æ”¹ã€‚

å®éªŒä¸€ï¼šæ ¸å¿ƒæ€§èƒ½å¯¹æ¯” (åœ¨25%æ ‡ç­¾å¼‚å¸¸ä¸‹)
--------------------------------------------------
- **ç›®æ ‡**: æ¯”è¾ƒCausalEngineå’Œ8ç§ä¼ ç»Ÿæ–¹æ³•åœ¨å«æœ‰å›ºå®šæ ‡ç­¾å¼‚å¸¸æ•°æ®ä¸Šçš„é¢„æµ‹æ€§èƒ½ã€‚
- **è®¾ç½®**: é»˜è®¤è®¾ç½®25%çš„æ ‡ç­¾å¼‚å¸¸ï¼ˆ`ANOMALY_RATIO = 0.25`ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­å¸¸è§çš„æ•°æ®è´¨é‡é—®é¢˜ã€‚
- **å¯¹æ¯”æ¨¡å‹**: 
  - ä¼ ç»Ÿæ–¹æ³•: sklearn MLP, PyTorch MLP, MLP Huber, MLP Pinball, MLP Cauchy, Random Forest, CatBoost, XGBoost
  - CausalEngine: deterministic, standard

å®éªŒäºŒï¼šé²æ£’æ€§åˆ†æ (è·¨è¶Šä¸åŒæ ‡ç­¾å¼‚å¸¸æ°´å¹³)
--------------------------------------------------
- **ç›®æ ‡**: æ¢ç©¶æ¨¡å‹æ€§èƒ½éšæ ‡ç­¾å¼‚å¸¸æ°´å¹³å¢åŠ æ—¶çš„å˜åŒ–æƒ…å†µï¼Œè¯„ä¼°å…¶ç¨³å®šæ€§ã€‚
- **è®¾ç½®**: åœ¨ä¸€ç³»åˆ—æ ‡ç­¾å¼‚å¸¸æ¯”ä¾‹ï¼ˆå¦‚0%, 10%, 20%, 30%, 40%ï¼‰ä¸‹åˆ†åˆ«è¿è¡Œæµ‹è¯•ã€‚
- **å¯¹æ¯”æ¨¡å‹**: æ‰€æœ‰10ç§æ–¹æ³•åœ¨ä¸åŒæ ‡ç­¾å¼‚å¸¸æ°´å¹³ä¸‹çš„è¡¨ç°
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error
import warnings
import os
import sys
import time

# è®¾ç½®matplotlibåç«¯ä¸ºéäº¤äº’å¼ï¼Œé¿å…å¼¹å‡ºçª—å£
plt.switch_backend('Agg')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æˆ‘ä»¬çš„sklearn-style learners
from causal_sklearn.regressor import (
    MLPCausalRegressor, MLPPytorchRegressor, 
    MLPHuberRegressor, MLPPinballRegressor, MLPCauchyRegressor
)

warnings.filterwarnings('ignore')

# Try to import CatBoost and XGBoost
try:
    from catboost import CatBoostRegressor
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False
    print("âš ï¸ CatBoost not available, will skip CatBoost in comparisons")

try:
    from xgboost import XGBRegressor
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("âš ï¸ XGBoost not available, will skip XGBoost in comparisons")


class TutorialConfig:
    """
    æ‰©å±•æ•™ç¨‹é…ç½®ç±» - æ–¹ä¾¿è°ƒæ•´å„ç§å‚æ•°
    
    ğŸ”§ åœ¨è¿™é‡Œä¿®æ”¹å‚æ•°æ¥è‡ªå®šä¹‰å®éªŒè®¾ç½®ï¼
    """
    
    # ğŸ¯ æ•°æ®åˆ†å‰²å‚æ•°
    TEST_SIZE = 0.2          # æµ‹è¯•é›†æ¯”ä¾‹
    VAL_SIZE = 0.2           # éªŒè¯é›†æ¯”ä¾‹ (ç›¸å¯¹äºè®­ç»ƒé›†)
    RANDOM_STATE = 42        # éšæœºç§å­
    
    # ğŸ§  ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½® - æ‰€æœ‰ç¥ç»ç½‘ç»œæ–¹æ³•ä½¿ç”¨ç›¸åŒå‚æ•°ç¡®ä¿å…¬å¹³æ¯”è¾ƒ
    # =========================================================================
    # ğŸ”§ åœ¨è¿™é‡Œä¿®æ”¹æ‰€æœ‰ç¥ç»ç½‘ç»œæ–¹æ³•çš„å…±åŒå‚æ•°ï¼
    NN_HIDDEN_SIZES = (128, 64, 32)                 # ğŸ”§ ç»Ÿä¸€ç¥ç»ç½‘ç»œéšè—å±‚ç»“æ„
    NN_MAX_EPOCHS = 3000                            # æœ€å¤§è®­ç»ƒè½®æ•°
    NN_LEARNING_RATE = 0.01                         # å­¦ä¹ ç‡
    NN_PATIENCE = 50                                # æ—©åœpatience
    NN_TOLERANCE = 1e-4                             # æ—©åœtolerance
    # =========================================================================
    
    # âœ¨ [æ–°åŠŸèƒ½] æ˜¯å¦å¯¹ç¥ç»ç½‘ç»œè¾“å…¥è¿›è¡Œç‰¹å¾æ ‡å‡†åŒ–
    USE_SCALER = True                               # æ¨è: Trueã€‚è®¾ä¸ºFalseå¯è§‚å¯Ÿæ— æ ‡å‡†åŒ–æ—¶ç¥ç»ç½‘ç»œçš„æ€§èƒ½
    
    # ğŸ¤– CausalEngineå‚æ•° - ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_MODES = ['deterministic', 'standard']    # å¯é€‰: ['deterministic', 'exogenous', 'endogenous', 'standard', 'sampling']
    CAUSAL_HIDDEN_SIZES = NN_HIDDEN_SIZES          # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_MAX_EPOCHS = NN_MAX_EPOCHS               # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_LR = NN_LEARNING_RATE                    # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_PATIENCE = NN_PATIENCE                   # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_TOL = NN_TOLERANCE                       # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    CAUSAL_GAMMA_INIT = 1.0                         # gammaåˆå§‹åŒ–
    CAUSAL_B_NOISE_INIT = 1.0                       # b_noiseåˆå§‹åŒ–
    CAUSAL_B_NOISE_TRAINABLE = True                 # b_noiseæ˜¯å¦å¯è®­ç»ƒ
    
    # ğŸ§  ä¼ ç»Ÿç¥ç»ç½‘ç»œæ–¹æ³•å‚æ•° - ä½¿ç”¨ç»Ÿä¸€é…ç½®
    SKLEARN_HIDDEN_LAYERS = NN_HIDDEN_SIZES         # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    SKLEARN_MAX_ITER = NN_MAX_EPOCHS                # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    SKLEARN_LR = NN_LEARNING_RATE                   # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    
    PYTORCH_EPOCHS = NN_MAX_EPOCHS                  # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    PYTORCH_LR = NN_LEARNING_RATE                   # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    PYTORCH_PATIENCE = NN_PATIENCE                  # ä½¿ç”¨ç»Ÿä¸€ç¥ç»ç½‘ç»œé…ç½®
    
    # ğŸ¯ é²æ£’æ€§å›å½’å™¨å‚æ•°
    HUBER_DELTA = 1.0                               # HuberæŸå¤±deltaå‚æ•°
    PINBALL_QUANTILE = 0.5                          # PinballæŸå¤±åˆ†ä½æ•°ï¼ˆä¸­ä½æ•°å›å½’ï¼‰
    
    # ğŸŒ² ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•å‚æ•°
    RF_N_ESTIMATORS = 100                           # éšæœºæ£®æ—æ ‘çš„æ•°é‡
    RF_MAX_DEPTH = None                             # éšæœºæ£®æ—æœ€å¤§æ·±åº¦
    CATBOOST_ITERATIONS = 1000                      # CatBoostè¿­ä»£æ¬¡æ•°
    CATBOOST_DEPTH = 6                              # CatBoostæ·±åº¦
    XGBOOST_N_ESTIMATORS = 1000                     # XGBoostè¿­ä»£æ¬¡æ•°
    XGBOOST_DEPTH = 6                               # XGBoostæ·±åº¦
    
    # ğŸ“Š å®éªŒå‚æ•°
    ANOMALY_RATIO = 0.3                            # æ ‡ç­¾å¼‚å¸¸æ¯”ä¾‹ (æ ¸å¿ƒå®éªŒé»˜è®¤å€¼: 30%æ ‡ç­¾å¼‚å¸¸æŒ‘æˆ˜) 
    SAVE_PLOTS = True                               # æ˜¯å¦ä¿å­˜å›¾è¡¨
    VERBOSE = True                                  # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
    
    # ğŸ›¡ï¸ é²æ£’æ€§æµ‹è¯•å‚æ•° - éªŒè¯"CausalEngineé²æ£’æ€§ä¼˜åŠ¿"çš„å‡è®¾
    ROBUSTNESS_ANOMALY_RATIOS = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]  # æ ‡ç­¾å¼‚å¸¸æ°´å¹³
    RUN_ROBUSTNESS_TEST = True                      # æ˜¯å¦è¿è¡Œé²æ£’æ€§æµ‹è¯•
    
    # ğŸ“ˆ å¯è§†åŒ–å‚æ•°
    FIGURE_DPI = 300                                # å›¾è¡¨åˆ†è¾¨ç‡
    FIGURE_SIZE_ANALYSIS = (16, 12)                 # æ•°æ®åˆ†æå›¾è¡¨å¤§å°
    FIGURE_SIZE_PERFORMANCE = (16, 12)              # æ€§èƒ½å¯¹æ¯”å›¾è¡¨å¤§å°
    FIGURE_SIZE_ROBUSTNESS = (18, 14)               # é²æ£’æ€§æµ‹è¯•å›¾è¡¨å¤§å° (æ›´å¤§å®¹çº³æ›´å¤šæ–¹æ³•)
    
    # ğŸ“ è¾“å‡ºç›®å½•å‚æ•°
    OUTPUT_DIR = "results/real_world_regression_tutorial_extended_sklearn"  # è¾“å‡ºç›®å½•åç§°


class ExtendedCaliforniaHousingSklearnTutorial:
    """
    æ‰©å±•ç‰ˆåŠ å·æˆ¿ä»·å›å½’æ•™ç¨‹ä¸»ç±» - Sklearnç‰ˆæœ¬
    
    ä½¿ç”¨sklearn-style learnersæ¼”ç¤ºCausalEngineä¸å¤šç§å¼ºåŠ›æ–¹æ³•çš„æ€§èƒ½å¯¹æ¯”
    """
    
    def __init__(self, config=None):
        self.config = config if config is not None else TutorialConfig()
        self.X = None
        self.y = None
        self.feature_names = None
        self.results = {}
        self._ensure_output_dir()
    
    def _ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.config.OUTPUT_DIR):
            os.makedirs(self.config.OUTPUT_DIR)
            if self.config.VERBOSE:
                print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {self.config.OUTPUT_DIR}/")
    
    def _get_output_path(self, filename):
        """è·å–è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
        return os.path.join(self.config.OUTPUT_DIR, filename)
        
    def _get_clean_method_name(self, method_key: str) -> str:
        """Removes prefixes and suffixes from method names for clean display."""
        name = method_key.replace('causal_', '').replace('_mlp', '').replace('mlp_', '')
        return name
        
    def load_and_explore_data(self, verbose=True):
        """åŠ è½½å¹¶æ¢ç´¢åŠ å·æˆ¿ä»·æ•°æ®é›†"""
        if verbose:
            print("ğŸ  æ‰©å±•ç‰ˆåŠ å·æˆ¿ä»·é¢„æµ‹ - çœŸå®ä¸–ç•Œå›å½’æ•™ç¨‹ (Sklearnç‰ˆæœ¬)")
            print("=" * 70)
            print("ğŸ“Š æ­£åœ¨åŠ è½½åŠ å·æˆ¿ä»·æ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®
        housing = fetch_california_housing()
        self.X, self.y = housing.data, housing.target
        self.feature_names = housing.feature_names
        
        if verbose:
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
            print(f"   - æ ·æœ¬æ•°é‡: {self.X.shape[0]:,}")
            print(f"   - ç‰¹å¾æ•°é‡: {self.X.shape[1]}")
            print(f"   - ç‰¹å¾åç§°: {', '.join(self.feature_names)}")
            print(f"   - ç›®æ ‡èŒƒå›´: ${self.y.min():.2f} - ${self.y.max():.2f} (ç™¾ä¸‡ç¾å…ƒ)")
            print(f"   - ç›®æ ‡å‡å€¼: ${self.y.mean():.2f}")
            print(f"   - ç›®æ ‡æ ‡å‡†å·®: ${self.y.std():.2f}")
            
            # ç»Ÿè®¡å¯ç”¨æ–¹æ³•
            total_methods = len(self.config.CAUSAL_MODES) + 5  # 5ç§ä¼ ç»Ÿæ–¹æ³•åŸºç¡€
            if CATBOOST_AVAILABLE:
                total_methods += 1
            if XGBOOST_AVAILABLE:
                total_methods += 1

            ensemble_methods = "Random Forest"
            if CATBOOST_AVAILABLE:
                ensemble_methods += ", CatBoost"
            if XGBOOST_AVAILABLE:
                ensemble_methods += ", XGBoost"
            ensemble_count = sum([1 for m in [CATBOOST_AVAILABLE, XGBOOST_AVAILABLE, True]])

            print(f"\nğŸ¯ å°†æ¯”è¾ƒ {total_methods} ç§æ–¹æ³•:")
            print(f"   - CausalEngine ({len(self.config.CAUSAL_MODES)}ç§): {', '.join(self.config.CAUSAL_MODES)}")
            print(f"   - ä¼ ç»Ÿç¥ç»ç½‘ç»œ (2ç§): sklearn MLP, PyTorch MLP")
            print(f"   - é²æ£’æ€§å›å½’å™¨ (3ç§): Huber, Pinball, Cauchy")
            print(f"   - é›†æˆå­¦ä¹  ({ensemble_count}ç§): {ensemble_methods}")
        
        return self.X, self.y
    
    def visualize_data(self, save_plots=None):
        """æ•°æ®å¯è§†åŒ–åˆ†æ"""
        if save_plots is None:
            save_plots = self.config.SAVE_PLOTS
            
        print("\nğŸ“ˆ æ•°æ®åˆ†å¸ƒåˆ†æ")
        print("-" * 30)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=self.config.FIGURE_SIZE_ANALYSIS)
        fig.suptitle('California Housing Dataset Analysis - Extended Sklearn Version', fontsize=16, fontweight='bold')
        
        # 1. ç›®æ ‡å˜é‡åˆ†å¸ƒ
        axes[0, 0].hist(self.y, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('House Price Distribution')
        axes[0, 0].set_xlabel('House Price ($100k)')
        axes[0, 0].set_ylabel('Frequency')
        axes[0, 0].axvline(self.y.mean(), color='red', linestyle='--', label=f'Mean: ${self.y.mean():.2f}')
        axes[0, 0].legend()
        
        # 2. ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
        df = pd.DataFrame(self.X, columns=self.feature_names)
        df['MedHouseVal'] = self.y
        corr_matrix = df.corr()
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, ax=axes[0, 1], cbar_kws={'shrink': 0.8})
        axes[0, 1].set_title('Feature Correlation Matrix')
        
        # 3. ç‰¹å¾åˆ†å¸ƒç®±çº¿å›¾
        df_features = pd.DataFrame(self.X, columns=self.feature_names)
        df_features_normalized = (df_features - df_features.mean()) / df_features.std()
        df_features_normalized.boxplot(ax=axes[1, 0])
        axes[1, 0].set_title('Feature Distribution (Standardized)')
        axes[1, 0].set_xlabel('Features')
        axes[1, 0].set_ylabel('Standardized Values')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 4. æœ€é‡è¦ç‰¹å¾ä¸ç›®æ ‡çš„æ•£ç‚¹å›¾
        most_corr_feature = corr_matrix['MedHouseVal'].abs().sort_values(ascending=False).index[1]
        most_corr_idx = list(self.feature_names).index(most_corr_feature)
        axes[1, 1].scatter(self.X[:, most_corr_idx], self.y, alpha=0.5, s=1)
        axes[1, 1].set_title(f'Most Correlated Feature: {most_corr_feature}')
        axes[1, 1].set_xlabel(most_corr_feature)
        axes[1, 1].set_ylabel('House Price ($100k)')
        
        plt.tight_layout()
        
        if save_plots:
            # ä½¿ç”¨ä¸åŸå§‹ç‰ˆæœ¬ä¸€è‡´çš„æ–‡ä»¶å
            output_path = self._get_output_path('extended_data_analysis.png')
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š æ•°æ®åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()  # å…³é—­å›¾å½¢ï¼Œé¿å…å†…å­˜æ³„æ¼
        
        # æ•°æ®ç»Ÿè®¡æ‘˜è¦
        print("\nğŸ“‹ æ•°æ®ç»Ÿè®¡æ‘˜è¦:")
        print(f"  - æœ€ç›¸å…³ç‰¹å¾: {most_corr_feature} (ç›¸å…³ç³»æ•°: {corr_matrix.loc[most_corr_feature, 'MedHouseVal']:.3f})")
        print(f"  - å¼‚å¸¸å€¼æ£€æµ‹: {np.sum(np.abs(self.y - self.y.mean()) > 3 * self.y.std())} ä¸ªæ½œåœ¨å¼‚å¸¸å€¼")
        print(f"  - æ•°æ®å®Œæ•´æ€§: æ— ç¼ºå¤±å€¼" if not np.any(np.isnan(self.X)) else "  - è­¦å‘Š: å­˜åœ¨ç¼ºå¤±å€¼")
    
    def _inject_label_anomalies(self, y, anomaly_ratio, random_state=42):
        """æ³¨å…¥æ ‡ç­¾å¼‚å¸¸"""
        if anomaly_ratio <= 0:
            return y.copy()
            
        np.random.seed(random_state)
        y_noisy = y.copy()
        n_anomalies = int(len(y) * anomaly_ratio)
        
        # éšæœºé€‰æ‹©å¼‚å¸¸æ ·æœ¬
        anomaly_indices = np.random.choice(len(y), n_anomalies, replace=False)
        
        # æ·»åŠ å¼‚å¸¸ - ä½¿ç”¨æ ‡å‡†å·®çš„å€æ•°ä½œä¸ºå¼‚å¸¸å¼ºåº¦
        anomaly_strength = np.std(y) * 2.0  # 2å€æ ‡å‡†å·®çš„å¼‚å¸¸
        anomalies = np.random.normal(0, anomaly_strength, n_anomalies)
        y_noisy[anomaly_indices] += anomalies
        
        return y_noisy
    
    def _train_models(self, X_train, y_train, X_val, y_val, anomaly_ratio, verbose=True):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        if verbose:
            print(f"\nğŸ”§ è®­ç»ƒæ¨¡å‹ (å¼‚å¸¸æ¯”ä¾‹: {anomaly_ratio:.1%})")
            print("-" * 50)
        
        # æ•°æ®é¢„å¤„ç† - æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        
        # æ³¨å…¥æ ‡ç­¾å¼‚å¸¸åˆ°è®­ç»ƒæ ‡ç­¾
        y_train_noisy = self._inject_label_anomalies(y_train, anomaly_ratio, random_state=self.config.RANDOM_STATE)
        
        models = {}
        
        # 1. Sklearn MLPRegressor
        if verbose:
            print("   ğŸ”§ è®­ç»ƒ sklearn MLPRegressor...")
        sklearn_model = MLPRegressor(
            hidden_layer_sizes=self.config.SKLEARN_HIDDEN_LAYERS,
            max_iter=self.config.SKLEARN_MAX_ITER,
            learning_rate_init=self.config.SKLEARN_LR,
            early_stopping=True,
            validation_fraction=0.2,
            n_iter_no_change=self.config.NN_PATIENCE,
            tol=self.config.NN_TOLERANCE,
            random_state=self.config.RANDOM_STATE,
            alpha=0.0001  # L2æ­£åˆ™åŒ–
        )
        sklearn_model.fit(X_train_scaled, y_train_noisy)
        models['sklearn_mlp'] = (sklearn_model, scaler)
        
        # 2. PyTorch MLP
        if verbose:
            print("   ğŸ”§ è®­ç»ƒ PyTorch MLPRegressor...")
        pytorch_model = MLPPytorchRegressor(
            hidden_layer_sizes=self.config.NN_HIDDEN_SIZES,
            max_iter=self.config.PYTORCH_EPOCHS,
            learning_rate=self.config.PYTORCH_LR,
            early_stopping=True,
            validation_fraction=0.2,
            n_iter_no_change=self.config.PYTORCH_PATIENCE,
            tol=self.config.NN_TOLERANCE,
            random_state=self.config.RANDOM_STATE,
            verbose=False,
            alpha=0.0001
        )
        pytorch_model.fit(X_train_scaled, y_train_noisy)
        models['pytorch_mlp'] = (pytorch_model, scaler)
        
        # 3. MLP Huber Regressor
        if verbose:
            print("   ğŸ”§ è®­ç»ƒ MLP Huber Regressor...")
        huber_model = MLPHuberRegressor(
            hidden_layer_sizes=self.config.NN_HIDDEN_SIZES,
            max_iter=self.config.NN_MAX_EPOCHS,
            learning_rate=self.config.NN_LEARNING_RATE,
            early_stopping=True,
            validation_fraction=0.2,
            n_iter_no_change=self.config.NN_PATIENCE,
            tol=self.config.NN_TOLERANCE,
            delta=self.config.HUBER_DELTA,
            random_state=self.config.RANDOM_STATE,
            verbose=False,
            alpha=0.0001
        )
        huber_model.fit(X_train_scaled, y_train_noisy)
        models['mlp_huber'] = (huber_model, scaler)
        
        # 4. MLP Pinball Regressor
        if verbose:
            print("   ğŸ”§ è®­ç»ƒ MLP Pinball Regressor...")
        pinball_model = MLPPinballRegressor(
            hidden_layer_sizes=self.config.NN_HIDDEN_SIZES,
            max_iter=self.config.NN_MAX_EPOCHS,
            learning_rate=self.config.NN_LEARNING_RATE,
            early_stopping=True,
            validation_fraction=0.2,
            n_iter_no_change=self.config.NN_PATIENCE,
            tol=self.config.NN_TOLERANCE,
            quantile=self.config.PINBALL_QUANTILE,
            random_state=self.config.RANDOM_STATE,
            verbose=False,
            alpha=0.0001
        )
        pinball_model.fit(X_train_scaled, y_train_noisy)
        models['mlp_pinball'] = (pinball_model, scaler)
        
        # 5. MLP Cauchy Regressor
        if verbose:
            print("   ğŸ”§ è®­ç»ƒ MLP Cauchy Regressor...")
        cauchy_model = MLPCauchyRegressor(
            hidden_layer_sizes=self.config.NN_HIDDEN_SIZES,
            max_iter=self.config.NN_MAX_EPOCHS,
            learning_rate=self.config.NN_LEARNING_RATE,
            early_stopping=True,
            validation_fraction=0.2,
            n_iter_no_change=self.config.NN_PATIENCE,
            tol=self.config.NN_TOLERANCE,
            random_state=self.config.RANDOM_STATE,
            verbose=False,
            alpha=0.0001
        )
        cauchy_model.fit(X_train_scaled, y_train_noisy)
        models['mlp_cauchy'] = (cauchy_model, scaler)
        
        # 6. Random Forest
        if verbose:
            print("   ğŸ”§ è®­ç»ƒ Random Forest...")
        # Random Forest doesn't need scaling
        rf_model = RandomForestRegressor(
            n_estimators=self.config.RF_N_ESTIMATORS,
            max_depth=self.config.RF_MAX_DEPTH,
            random_state=self.config.RANDOM_STATE,
            n_jobs=-1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        )
        rf_model.fit(X_train, y_train_noisy)  # RFä¸éœ€è¦æ ‡å‡†åŒ–
        # ä¸ºRFåˆ›å»ºä¸€ä¸ªæ’ç­‰ç¼©æ”¾å™¨ä»¥ä¿æŒæ¥å£ä¸€è‡´
        identity_scaler = StandardScaler()
        identity_scaler.fit(X_train)
        identity_scaler.scale_ = np.ones(X_train.shape[1])
        identity_scaler.mean_ = np.zeros(X_train.shape[1])
        models['random_forest'] = (rf_model, identity_scaler)
        
        # 7. CatBoost (å¦‚æœå¯ç”¨)
        if CATBOOST_AVAILABLE:
            if verbose:
                print("   ğŸ”§ è®­ç»ƒ CatBoost...")
            catboost_model = CatBoostRegressor(
                iterations=self.config.CATBOOST_ITERATIONS,
                depth=self.config.CATBOOST_DEPTH,
                learning_rate=0.1,
                random_seed=self.config.RANDOM_STATE,
                verbose=False  # å…³é—­CatBoostçš„è¯¦ç»†è¾“å‡º
            )
            catboost_model.fit(X_train, y_train_noisy)  # CatBoostä¹Ÿä¸éœ€è¦æ ‡å‡†åŒ–
            # ä¸ºCatBooståˆ›å»ºä¸€ä¸ªæ’ç­‰ç¼©æ”¾å™¨ä»¥ä¿æŒæ¥å£ä¸€è‡´
            identity_scaler_cat = StandardScaler()
            identity_scaler_cat.fit(X_train)
            identity_scaler_cat.scale_ = np.ones(X_train.shape[1])
            identity_scaler_cat.mean_ = np.zeros(X_train.shape[1])
            models['catboost'] = (catboost_model, identity_scaler_cat)
        
        # 8. XGBoost (å¦‚æœå¯ç”¨)
        if XGBOOST_AVAILABLE:
            if verbose:
                print("   ğŸ”§ è®­ç»ƒ XGBoost...")
            xgboost_model = XGBRegressor(
                n_estimators=self.config.XGBOOST_N_ESTIMATORS,
                max_depth=self.config.XGBOOST_DEPTH,
                learning_rate=0.05,
                random_state=self.config.RANDOM_STATE,
                n_jobs=-1,
                early_stopping_rounds=50
            )
            # XGBoost ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ—©åœ
            xgboost_model.fit(X_train, y_train_noisy, eval_set=[(X_val, y_val)], verbose=False)
            # ä¸ºXGBoostä¹Ÿåˆ›å»ºä¸€ä¸ªæ’ç­‰ç¼©æ”¾å™¨
            identity_scaler_xgb = StandardScaler()
            identity_scaler_xgb.fit(X_train)
            identity_scaler_xgb.scale_ = np.ones(X_train.shape[1])
            identity_scaler_xgb.mean_ = np.zeros(X_train.shape[1])
            models['xgboost'] = (xgboost_model, identity_scaler_xgb)
        
        # 9. CausalEngine å„ç§æ¨¡å¼
        for mode in self.config.CAUSAL_MODES:
            if verbose:
                print(f"   ğŸ”§ è®­ç»ƒ CausalEngine ({mode})...")
            causal_model = MLPCausalRegressor(
                perception_hidden_layers=self.config.CAUSAL_HIDDEN_SIZES,
                mode=mode,
                gamma_init=self.config.CAUSAL_GAMMA_INIT,
                b_noise_init=self.config.CAUSAL_B_NOISE_INIT,
                b_noise_trainable=self.config.CAUSAL_B_NOISE_TRAINABLE,
                max_iter=self.config.CAUSAL_MAX_EPOCHS,
                learning_rate=self.config.CAUSAL_LR,
                early_stopping=True,
                validation_fraction=0.2,
                n_iter_no_change=self.config.CAUSAL_PATIENCE,
                tol=self.config.CAUSAL_TOL,
                random_state=self.config.RANDOM_STATE,
                verbose=False,
                alpha=0.0001
            )
            causal_model.fit(X_train_scaled, y_train_noisy)
            models[f'causal_{mode}'] = (causal_model, scaler)
        
        return models
    
    def _evaluate_models(self, models, X_val, y_val, X_test, y_test):
        """è¯„ä¼°æ‰€æœ‰æ¨¡å‹"""
        results = {}
        
        for model_name, (model, scaler) in models.items():
            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–
            if self.config.USE_SCALER:
                # å¯¹äºéœ€è¦æ ‡å‡†åŒ–çš„æ¨¡å‹ï¼Œè¿›è¡Œæ ‡å‡†åŒ–
                if model_name in ['random_forest', 'catboost', 'xgboost']:
                    # RF, CatBoost, XGBoost ä¸éœ€è¦æ ‡å‡†åŒ–
                    X_val_processed = X_val
                    X_test_processed = X_test
                else:
                    # ç¥ç»ç½‘ç»œéœ€è¦æ ‡å‡†åŒ–
                    X_val_processed = scaler.transform(X_val)
                    X_test_processed = scaler.transform(X_test)
            else:
                # ä¸ä½¿ç”¨æ ‡å‡†åŒ–æ—¶ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½ç”¨åŸå§‹æ•°æ®
                X_val_processed = X_val
                X_test_processed = X_test
            
            # éªŒè¯é›†è¯„ä¼°
            y_val_pred = model.predict(X_val_processed)
            
            val_metrics = {
                'MAE': mean_absolute_error(y_val, y_val_pred),
                'MdAE': median_absolute_error(y_val, y_val_pred),
                'RMSE': np.sqrt(mean_squared_error(y_val, y_val_pred)),
                'RÂ²': r2_score(y_val, y_val_pred)
            }
            
            # æµ‹è¯•é›†è¯„ä¼°
            y_test_pred = model.predict(X_test_processed)
            
            test_metrics = {
                'MAE': mean_absolute_error(y_test, y_test_pred),
                'MdAE': median_absolute_error(y_test, y_test_pred),
                'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),
                'RÂ²': r2_score(y_test, y_test_pred)
            }
            
            results[model_name] = {
                'val': val_metrics,
                'test': test_metrics
            }
        
        return results
    
    def run_comprehensive_benchmark(self, test_size=None, val_size=None, anomaly_ratio=None, verbose=None):
        """è¿è¡Œå…¨é¢çš„åŸºå‡†æµ‹è¯•"""
        # ä½¿ç”¨é…ç½®å‚æ•°ä½œä¸ºé»˜è®¤å€¼
        if test_size is None:
            test_size = self.config.TEST_SIZE
        if val_size is None:
            val_size = self.config.VAL_SIZE
        if anomaly_ratio is None:
            anomaly_ratio = self.config.ANOMALY_RATIO
        if verbose is None:
            verbose = self.config.VERBOSE
            
        if verbose:
            print("\nğŸš€ å¼€å§‹æ‰©å±•ç‰ˆç»¼åˆåŸºå‡†æµ‹è¯• (Sklearnç‰ˆæœ¬)")
            print("=" * 70)
            print(f"ğŸ”§ å®éªŒé…ç½®:")
            print(f"   - æµ‹è¯•é›†æ¯”ä¾‹: {test_size:.1%}")
            print(f"   - éªŒè¯é›†æ¯”ä¾‹: {val_size:.1%}")
            print(f"   - æ ‡ç­¾å¼‚å¸¸æ¯”ä¾‹: {anomaly_ratio:.1%}")
            print(f"   - ä½¿ç”¨ç‰¹å¾ç¼©æ”¾ (Scaler): {'æ˜¯' if self.config.USE_SCALER else 'å¦'}")
            print(f"   - éšæœºç§å­: {self.config.RANDOM_STATE}")
            print(f"   - CausalEngineæ¨¡å¼: {', '.join(self.config.CAUSAL_MODES)}")
            print(f"   - ç¥ç»ç½‘ç»œç»“æ„: {self.config.NN_HIDDEN_SIZES}")
            print(f"   - æœ€å¤§è®­ç»ƒè½®æ•°: {self.config.NN_MAX_EPOCHS}")
            print(f"   - æ—©åœpatience: {self.config.NN_PATIENCE}")
        
        # æ•°æ®åˆ†å‰²
        X_temp, X_test, y_temp, y_test = train_test_split(
            self.X, self.y, 
            test_size=test_size, 
            random_state=self.config.RANDOM_STATE
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp,
            test_size=val_size,
            random_state=self.config.RANDOM_STATE
        )
        
        if verbose:
            print(f"\nğŸ“Š æ•°æ®åˆ†å‰²:")
            print(f"   - è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
            print(f"   - éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
            print(f"   - æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        models = self._train_models(X_train, y_train, X_val, y_val, anomaly_ratio, verbose)
        training_time = time.time() - start_time
        
        # è¯„ä¼°æ¨¡å‹
        core_results = self._evaluate_models(models, X_val, y_val, X_test, y_test)
        
        # å­˜å‚¨æ ¸å¿ƒæ€§èƒ½ç»“æœ (ä¸åŸå§‹ç‰ˆæœ¬ä¿æŒä¸€è‡´çš„ç»“æ„)
        if not hasattr(self, 'results'):
            self.results = {}
        self.results['core_performance'] = core_results
        
        if verbose:
            print(f"\nâ±ï¸ æ€»è®­ç»ƒæ—¶é—´: {training_time:.1f} ç§’")
            print(f"\nğŸ“Š æ‰©å±•ç‰ˆåŸºå‡†æµ‹è¯•ç»“æœ (å¼‚å¸¸æ¯”ä¾‹: {anomaly_ratio:.0%})")
            self._print_results()
        
        return core_results
    
    def generate_summary_report(self):
        """ç”Ÿæˆå®éªŒæ€»ç»“æŠ¥å‘Š - ä¸åŸå§‹ç‰ˆæœ¬åŠŸèƒ½å®Œå…¨å¯¹åº”"""
        if self.config.VERBOSE:
            print("\nğŸ“‹ ç”Ÿæˆå®éªŒæ€»ç»“æŠ¥å‘Š...")
        
        report_lines = []
        report_lines.append("# æ‰©å±•ç‰ˆåŠ å·æˆ¿ä»·å›å½’å®éªŒæ€»ç»“æŠ¥å‘Š")
        report_lines.append("")
        report_lines.append("ğŸ  **California Housing Dataset Regression Analysis**")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")
        
        # å®éªŒé…ç½®
        report_lines.append("## ğŸ“Š å®éªŒé…ç½®")
        report_lines.append("")
        report_lines.append(f"- **æ•°æ®é›†**: åŠ å·æˆ¿ä»·æ•°æ®é›†")
        report_lines.append(f"  - æ ·æœ¬æ•°: {self.X.shape[0]:,}")
        report_lines.append(f"  - ç‰¹å¾æ•°: {self.X.shape[1]}")
        report_lines.append(f"  - æˆ¿ä»·èŒƒå›´: ${self.y.min():.2f} - ${self.y.max():.2f} (10ä¸‡ç¾å…ƒ)")
        report_lines.append("")
        report_lines.append(f"- **æ•°æ®åˆ†å‰²**:")
        report_lines.append(f"  - æµ‹è¯•é›†æ¯”ä¾‹: {self.config.TEST_SIZE:.1%}")
        report_lines.append(f"  - éªŒè¯é›†æ¯”ä¾‹: {self.config.VAL_SIZE:.1%}")
        report_lines.append(f"  - éšæœºç§å­: {self.config.RANDOM_STATE}")
        report_lines.append("")
        report_lines.append(f"- **ç¥ç»ç½‘ç»œç»Ÿä¸€é…ç½®**:")
        report_lines.append(f"  - ç½‘ç»œç»“æ„: {self.config.NN_HIDDEN_SIZES}")
        report_lines.append(f"  - æœ€å¤§è½®æ•°: {self.config.NN_MAX_EPOCHS}")
        report_lines.append(f"  - å­¦ä¹ ç‡: {self.config.NN_LEARNING_RATE}")
        report_lines.append(f"  - æ—©åœpatience: {self.config.NN_PATIENCE}")
        report_lines.append("")
        
        # è®¡ç®—æ–¹æ³•æ•°é‡
        baseline_methods = ['sklearn', 'pytorch', 'huber', 'pinball', 'cauchy', 'random_forest']
        if CATBOOST_AVAILABLE:
            baseline_methods.append('catboost')
        if XGBOOST_AVAILABLE:
            baseline_methods.append('xgboost')
        causal_modes = self.config.CAUSAL_MODES
        
        report_lines.append(f"- **å®éªŒæ–¹æ³•**: {len(baseline_methods) + len(causal_modes)} ç§")
        report_lines.append(f"  - ä¼ ç»Ÿæ–¹æ³• ({len(baseline_methods)}ç§): {', '.join(baseline_methods)}")
        report_lines.append(f"  - CausalEngine ({len(causal_modes)}ç§): {', '.join(causal_modes)}")
        report_lines.append("")
        
        # æ ¸å¿ƒæ€§èƒ½æµ‹è¯•ç»“æœ
        if 'core_performance' in self.results:
            results = self.results['core_performance']
            report_lines.append("## ğŸ¯ æ ¸å¿ƒæ€§èƒ½æµ‹è¯•ç»“æœ")
            report_lines.append("")
            report_lines.append(f"**æ ‡ç­¾å¼‚å¸¸æ°´å¹³**: {self.config.ANOMALY_RATIO:.1%}")
            report_lines.append("")
            
            # åˆ›å»ºæ€§èƒ½è¡¨æ ¼ - æŒ‰MdAEæ’åº
            methods_by_mdae = sorted(results.keys(), key=lambda x: results[x]['test']['MdAE'])
            
            report_lines.append("### ğŸ“ˆ æµ‹è¯•é›†æ€§èƒ½æ’å (æŒ‰MdAEå‡åº)")
            report_lines.append("")
            
            # è¡¨æ ¼å¤´
            report_lines.append("| æ’å | æ–¹æ³• | MAE | MdAE | RMSE | RÂ² | æ–¹æ³•ç±»å‹ |")
            report_lines.append("|:----:|------|----:|-----:|-----:|---:|----------|")
            
            for i, method in enumerate(methods_by_mdae, 1):
                test_metrics = results[method]['test']
                
                # åˆ¤æ–­æ–¹æ³•ç±»å‹
                if any(mode in method for mode in ['deterministic', 'standard', 'exogenous', 'endogenous']):
                    method_type = "ğŸ¤– CausalEngine"
                elif any(robust in method.lower() for robust in ['huber', 'cauchy', 'pinball']):
                    method_type = "ğŸ›¡ï¸ ç¨³å¥å›å½’"
                elif method.lower() in ['catboost', 'random_forest', 'xgboost']:
                    method_type = "ğŸŒ² é›†æˆå­¦ä¹ "
                else:
                    method_type = "ğŸ§  ç¥ç»ç½‘ç»œ"
                
                report_lines.append(f"| {i} | **{self._get_clean_method_name(method)}** | "
                                  f"{test_metrics['MAE']:.4f} | "
                                  f"**{test_metrics['MdAE']:.4f}** | "
                                  f"{test_metrics['RMSE']:.4f} | "
                                  f"{test_metrics['RÂ²']:.4f} | "
                                  f"{method_type} |")
            
            report_lines.append("")
            
            # éªŒè¯é›†vsæµ‹è¯•é›†å¯¹æ¯”ï¼ˆå±•ç¤ºå™ªå£°å½±å“ï¼‰
            report_lines.append("### ğŸ” éªŒè¯é›† vs æµ‹è¯•é›†æ€§èƒ½å¯¹æ¯”")
            report_lines.append("")
            report_lines.append("*éªŒè¯é›†åŒ…å«æ ‡ç­¾å¼‚å¸¸ï¼Œæµ‹è¯•é›†ä¸ºçº¯å‡€æ•°æ®*")
            report_lines.append("")
            
            report_lines.append("| æ–¹æ³• | éªŒè¯é›†MdAE | æµ‹è¯•é›†MdAE | æ€§èƒ½æå‡ |")
            report_lines.append("|------|----------:|----------:|--------:|")
            
            for method in methods_by_mdae:
                val_mdae = results[method]['val']['MdAE']
                test_mdae = results[method]['test']['MdAE']
                improvement = ((val_mdae - test_mdae) / val_mdae) * 100
                
                report_lines.append(f"| {self._get_clean_method_name(method)} | "
                                  f"{val_mdae:.4f} | "
                                  f"{test_mdae:.4f} | "
                                  f"{improvement:+.1f}% |")
            
            report_lines.append("")
            
            # å…³é”®å‘ç°
            best_mdae_method = methods_by_mdae[0]
            best_mdae_score = results[best_mdae_method]['test']['MdAE']
            
            # è¯†åˆ«CausalEngineæ–¹æ³•
            causal_methods = [m for m in results.keys() if any(mode in m for mode in ['deterministic', 'standard', 'exogenous', 'endogenous'])]
            
            report_lines.append("### ğŸ† å…³é”®å‘ç°")
            report_lines.append("")
            report_lines.append(f"- **ğŸ¥‡ æœ€ä½³æ•´ä½“æ€§èƒ½**: `{self._get_clean_method_name(best_mdae_method)}` (MdAE: {best_mdae_score:.4f})")
            
            if causal_methods:
                best_causal = min(causal_methods, key=lambda x: results[x]['test']['MdAE'])
                causal_rank = methods_by_mdae.index(best_causal) + 1
                causal_score = results[best_causal]['test']['MdAE']
                report_lines.append(f"- **ğŸ¤– æœ€ä½³CausalEngine**: `{self._get_clean_method_name(best_causal)}` (æ’å: {causal_rank}/{len(methods_by_mdae)}, MdAE: {causal_score:.4f})")
                
                # CausalEngineæ¨¡å¼å¯¹æ¯”
                if len(causal_methods) > 1:
                    report_lines.append("")
                    report_lines.append("**CausalEngineæ¨¡å¼å¯¹æ¯”**:")
                    for causal_method in sorted(causal_methods, key=lambda x: results[x]['test']['MdAE']):
                        rank = methods_by_mdae.index(causal_method) + 1
                        score = results[causal_method]['test']['MdAE']
                        report_lines.append(f"  - `{self._get_clean_method_name(causal_method)}`: æ’å {rank}, MdAE {score:.4f}")
            
            # ä¼ ç»Ÿæ–¹æ³•åˆ†æ
            traditional_methods = [m for m in results.keys() if m not in causal_methods]
            if traditional_methods:
                best_traditional = min(traditional_methods, key=lambda x: results[x]['test']['MdAE'])
                traditional_rank = methods_by_mdae.index(best_traditional) + 1
                traditional_score = results[best_traditional]['test']['MdAE']
                report_lines.append(f"- **ğŸ… æœ€ä½³ä¼ ç»Ÿæ–¹æ³•**: `{self._get_clean_method_name(best_traditional)}` (æ’å: {traditional_rank}/{len(methods_by_mdae)}, MdAE: {traditional_score:.4f})")
            
            report_lines.append("")
        
        # é²æ£’æ€§æµ‹è¯•ç»“æœ
        if 'robustness' in self.results:
            robustness_results = self.results['robustness']
            report_lines.append("## ğŸ›¡ï¸ é²æ£’æ€§æµ‹è¯•ç»“æœ")
            report_lines.append("")
            
            noise_levels = sorted(robustness_results.keys())
            methods = list(robustness_results[noise_levels[0]].keys())
            
            report_lines.append("### ğŸ“Š MdAEæ€§èƒ½éšæ ‡ç­¾å¼‚å¸¸æ°´å¹³å˜åŒ–")
            report_lines.append("")
            
            # è¡¨æ ¼å¤´
            header = "| æ–¹æ³• | " + " | ".join([f"{r:.0%}" for r in noise_levels]) + " | ç¨³å®šæ€§* |"
            separator = "|------|" + "|".join([f"{'-'*(len(f'{r:.0%}')+1):->6}" for r in noise_levels]) + "|--------|"
            
            report_lines.append(header)
            report_lines.append(separator)
            
                            # æŒ‰0%æ ‡ç­¾å¼‚å¸¸æ€§èƒ½æ’åº
            methods_by_clean = sorted(methods, key=lambda x: robustness_results[0.0][x]['test']['MdAE'])
            
            for method in methods_by_clean:
                mdae_values = []
                scores = []
                for noise in noise_levels:
                    score = robustness_results[noise][method]['test']['MdAE']
                    scores.append(score)
                    mdae_values.append(f"{score:.4f}")
                
                # è®¡ç®—ç¨³å®šæ€§ (æœ€å¤§å€¼-æœ€å°å€¼)/æœ€å°å€¼
                stability = (max(scores) - min(scores)) / min(scores) * 100
                
                # æ–¹æ³•åæ ¼å¼åŒ–
                method_display = self._get_clean_method_name(method)
                
                report_lines.append(f"| {method_display} | " + 
                                  " | ".join(mdae_values) + 
                                  f" | {stability:.1f}% |")
            
            report_lines.append("")
            report_lines.append("*ç¨³å®šæ€§ = (æœ€å¤§MdAE - æœ€å°MdAE) / æœ€å°MdAE Ã— 100%ï¼Œè¶Šå°è¶Šç¨³å®š*")
            report_lines.append("")
            
            # é²æ£’æ€§åˆ†æ
            report_lines.append("### ğŸ” é²æ£’æ€§åˆ†æ")
            report_lines.append("")
            
            # æ‰¾å‡ºæœ€ç¨³å®šçš„æ–¹æ³•
            stability_scores = {}
            for method in methods:
                scores = [robustness_results[noise][method]['test']['MdAE'] for noise in noise_levels]
                stability_scores[method] = (max(scores) - min(scores)) / min(scores) * 100
            
            most_stable = min(stability_scores.keys(), key=lambda x: stability_scores[x])
            least_stable = max(stability_scores.keys(), key=lambda x: stability_scores[x])
            
            report_lines.append(f"- **ğŸ† æœ€ç¨³å®šæ–¹æ³•**: `{self._get_clean_method_name(most_stable)}` (ç¨³å®šæ€§: {stability_scores[most_stable]:.1f}%)")
            report_lines.append(f"- **âš ï¸ æœ€ä¸ç¨³å®šæ–¹æ³•**: `{self._get_clean_method_name(least_stable)}` (ç¨³å®šæ€§: {stability_scores[least_stable]:.1f}%)")
            
            report_lines.append("")
        
        # æ·»åŠ è„šæ³¨
        report_lines.append("---")
        report_lines.append("")
        report_lines.append("## ğŸ“ è¯´æ˜")
        report_lines.append("")
        report_lines.append("- **MdAE**: Median Absolute Error (ä¸­ä½æ•°ç»å¯¹è¯¯å·®) - ä¸»è¦è¯„ä¼°æŒ‡æ ‡")
        report_lines.append("- **MAE**: Mean Absolute Error (å¹³å‡ç»å¯¹è¯¯å·®)")
        report_lines.append("- **RMSE**: Root Mean Square Error (å‡æ–¹æ ¹è¯¯å·®)")
        report_lines.append("- **RÂ²**: å†³å®šç³»æ•° (è¶Šæ¥è¿‘1è¶Šå¥½)")
        report_lines.append("- **æ ‡ç­¾å¼‚å¸¸è®¾ç½®**: éªŒè¯é›†åŒ…å«äººå·¥æ ‡ç­¾å¼‚å¸¸ï¼Œæµ‹è¯•é›†ä¸ºçº¯å‡€æ•°æ®")
        report_lines.append("- **ç»Ÿä¸€é…ç½®**: æ‰€æœ‰ç¥ç»ç½‘ç»œæ–¹æ³•ä½¿ç”¨ç›¸åŒçš„è¶…å‚æ•°ç¡®ä¿å…¬å¹³æ¯”è¾ƒ")
        report_lines.append("")
        
        import pandas as pd
        report_lines.append(f"ğŸ“Š **ç”Ÿæˆæ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ä¿å­˜æŠ¥å‘Š - ä½¿ç”¨ä¸åŸå§‹ç‰ˆæœ¬ä¸€è‡´çš„æ–‡ä»¶å
        report_path = self._get_output_path('extended_experiment_summary.md')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        if self.config.VERBOSE:
            print(f"ğŸ“‹ å®éªŒæ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report_lines
    
    def _print_results(self):
        """æ‰“å°ç»“æœè¡¨æ ¼"""
        print("=" * 160)
        print(f"{'æ–¹æ³•':<20} {'éªŒè¯é›†':<65} {'æµ‹è¯•é›†':<65}")
        print(f"{'':20} {'MAE':<12} {'MdAE':<12} {'RMSE':<12} {'RÂ²':<12} {'MAE':<12} {'MdAE':<12} {'RMSE':<12} {'RÂ²':<12}")
        print("-" * 160)
        
        # æŒ‰æµ‹è¯•é›†MdAEæ’åºæ˜¾ç¤º - ä½¿ç”¨æ­£ç¡®çš„ç»“æœç»“æ„
        core_results = self.results.get('core_performance', self.results)
        sorted_methods = sorted(core_results.keys(), key=lambda x: core_results[x]['test']['MdAE'])
        
        for method in sorted_methods:
            metrics = core_results[method]
            val_m = metrics['val']
            test_m = metrics['test']
            
            # æ ¼å¼åŒ–æ–¹æ³•åç§°
            display_name = self._get_clean_method_name(method)
            
            print(f"{display_name:<20} {val_m['MAE']:<12.4f} {val_m['MdAE']:<12.4f} {val_m['RMSE']:<12.4f} {val_m['RÂ²']:<12.4f} "
                  f"{test_m['MAE']:<12.4f} {test_m['MdAE']:<12.4f} {test_m['RMSE']:<12.4f} {test_m['RÂ²']:<12.4f}")
        
        print("=" * 160)
        
        # æ˜¾ç¤ºæ’åå’Œæ€§èƒ½åˆ†æ
        best_method = sorted_methods[0]
        best_score = core_results[best_method]['test']['MdAE']
        print(f"\nğŸ† æœ€ä½³æ–¹æ³•: {self._get_clean_method_name(best_method)} (æµ‹è¯•é›†MdAE: {best_score:.4f})")
        
        # CausalEngineåˆ†æ
        causal_methods = [m for m in sorted_methods if 'causal' in m]
        if causal_methods:
            best_causal = causal_methods[0]
            causal_rank = sorted_methods.index(best_causal) + 1
            causal_score = core_results[best_causal]['test']['MdAE']
            print(f"ğŸ¤– æœ€ä½³CausalEngine: {self._get_clean_method_name(best_causal)} (æ’å: {causal_rank}/{len(sorted_methods)}, æµ‹è¯•é›†MdAE: {causal_score:.4f})")
    
    def analyze_performance(self, verbose=True):
        """åˆ†ææ€§èƒ½ç»“æœ"""
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        # è·å–æ­£ç¡®çš„ç»“æœç»“æ„
        core_results = self.results.get('core_performance', self.results)
        
        if verbose:
            print("\nğŸ” æ‰©å±•ç‰ˆæ€§èƒ½åˆ†æ")
            print("=" * 60)
        
        # æå–æµ‹è¯•é›†RÂ²åˆ†æ•°
        test_r2_scores = {}
        test_mdae_scores = {}
        for method, metrics in core_results.items():
            test_r2_scores[method] = metrics['test']['RÂ²']
            test_mdae_scores[method] = metrics['test']['MdAE']
        
        # æ‰¾åˆ°æœ€ä½³æ–¹æ³•ï¼ˆæŒ‰MdAEï¼‰
        best_method_mdae = min(test_mdae_scores.keys(), key=lambda x: test_mdae_scores[x])
        best_mdae = test_mdae_scores[best_method_mdae]
        
        # æ‰¾åˆ°æœ€ä½³æ–¹æ³•ï¼ˆæŒ‰RÂ²ï¼‰
        best_method_r2 = max(test_r2_scores.keys(), key=lambda x: test_r2_scores[x])
        best_r2 = test_r2_scores[best_method_r2]
        
        if verbose:
            print(f"ğŸ† æœ€ä½³æ–¹æ³• (MdAE): {self._get_clean_method_name(best_method_mdae)}")
            print(f"   MdAE = {best_mdae:.4f}")
            print(f"ğŸ† æœ€ä½³æ–¹æ³• (RÂ²): {self._get_clean_method_name(best_method_r2)}")
            print(f"   RÂ² = {best_r2:.4f}")
            print()
            print("ğŸ“Š æ€§èƒ½æ’å (æŒ‰MdAEå‡åº):")
            
            sorted_methods = sorted(test_mdae_scores.items(), key=lambda x: x[1])
            for i, (method, mdae) in enumerate(sorted_methods, 1):
                r2 = test_r2_scores[method]
                print(f"   {i}. {self._get_clean_method_name(method):<20} MdAE = {mdae:.4f}, RÂ² = {r2:.4f}")
        
        # åˆ†ç±»åˆ†æ
        causal_methods = [m for m in core_results.keys() if 'causal' in m]
        neural_methods = [m for m in core_results.keys() if 'mlp' in m and 'causal' not in m]
        ensemble_methods = [m for m in core_results.keys() if m in ['random_forest', 'catboost', 'xgboost']]
        
        if verbose and causal_methods:
            print(f"\nğŸ¯ æ–¹æ³•ç±»åˆ«åˆ†æ:")
            
            # CausalEngineåˆ†æ
            best_causal = min(causal_methods, key=lambda x: test_mdae_scores[x])
            print(f"   ğŸ¤– æœ€ä½³CausalEngine: {self._get_clean_method_name(best_causal)} (MdAE: {test_mdae_scores[best_causal]:.4f})")
            
            # ç¥ç»ç½‘ç»œåˆ†æ
            if neural_methods:
                best_neural = min(neural_methods, key=lambda x: test_mdae_scores[x])
                print(f"   ğŸ§  æœ€ä½³ç¥ç»ç½‘ç»œ: {self._get_clean_method_name(best_neural)} (MdAE: {test_mdae_scores[best_neural]:.4f})")
            
            # é›†æˆæ–¹æ³•åˆ†æ
            if ensemble_methods:
                best_ensemble = min(ensemble_methods, key=lambda x: test_mdae_scores[x])
                print(f"   ğŸŒ² æœ€ä½³é›†æˆæ–¹æ³•: {self._get_clean_method_name(best_ensemble)} (MdAE: {test_mdae_scores[best_ensemble]:.4f})")
            
            # æ€§èƒ½æå‡åˆ†æ
            all_traditional = neural_methods + ensemble_methods
            if all_traditional:
                best_traditional = min(all_traditional, key=lambda x: test_mdae_scores[x])
                improvement = ((test_mdae_scores[best_traditional] - test_mdae_scores[best_causal]) 
                             / test_mdae_scores[best_traditional]) * 100
                
                print(f"\nğŸ“ˆ CausalEngine vs ä¼ ç»Ÿæ–¹æ³•:")
                print(f"   æœ€ä½³CausalEngine: {self._get_clean_method_name(best_causal)} (MdAE: {test_mdae_scores[best_causal]:.4f})")
                print(f"   æœ€ä½³ä¼ ç»Ÿæ–¹æ³•: {self._get_clean_method_name(best_traditional)} (MdAE: {test_mdae_scores[best_traditional]:.4f})")
                print(f"   æ€§èƒ½æå‡: {improvement:+.2f}%")
                
                if improvement > 0:
                    print(f"   âœ… CausalEngineæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼")
                else:
                    print(f"   âš ï¸ åœ¨æ­¤è®¾ç½®ä¸‹ä¼ ç»Ÿæ–¹æ³•è¡¨ç°æ›´å¥½")
        
        return test_mdae_scores
    
    def create_performance_visualization(self, save_plot=None):
        """åˆ›å»ºæ€§èƒ½å¯è§†åŒ–å›¾è¡¨"""
        if save_plot is None:
            save_plot = self.config.SAVE_PLOTS
            
        if not self.results:
            print("âŒ è¯·å…ˆè¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        print("\nğŸ“Š åˆ›å»ºæ‰©å±•ç‰ˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨")
        print("-" * 30)
        
        # å‡†å¤‡æ•°æ®
        core_results = self.results.get('core_performance', self.results)
        methods = list(core_results.keys())
        clean_methods = [self._get_clean_method_name(m) for m in methods]
        metrics = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=self.config.FIGURE_SIZE_PERFORMANCE)
        fig.suptitle('Extended CausalEngine vs Traditional Methods: California Housing Performance (25% Label Anomaly) - Sklearn Version', 
                     fontsize=14, fontweight='bold')
        axes = axes.flatten()  # å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ä¾¿äºè®¿é—®
        
        # è®¾ç½®é¢œè‰²
        colors = []
        for method in methods:
            if 'causal' in method:
                colors.append('gold')  # CausalEngineç”¨é‡‘è‰²
            elif any(robust in method for robust in ['huber', 'pinball', 'cauchy']):
                colors.append('lightgreen')  # ç¨³å¥æ–¹æ³•ç”¨æµ…ç»¿
            elif method in ['random_forest', 'catboost', 'xgboost']:
                colors.append('lightcoral')  # é›†æˆæ–¹æ³•ç”¨æµ…çº¢
            else:
                colors.append('lightblue')  # ä¼ ç»Ÿç¥ç»ç½‘ç»œç”¨æµ…è“
        
        for i, metric in enumerate(metrics):
            values = [core_results[method]['test'][metric] for method in methods]
            
            bars = axes[i].bar(clean_methods, values, color=colors, alpha=0.8, edgecolor='black')
            axes[i].set_title(f'{metric} (Test Set)', fontweight='bold')
            axes[i].set_ylabel(metric)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, values):
                height = bar.get_height()
                axes[i].text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                           f'{value:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
            
            # é«˜äº®æœ€ä½³ç»“æœ
            if metric == 'RÂ²':
                best_idx = values.index(max(values))
            else:
                best_idx = values.index(min(values))
            bars[best_idx].set_color('gold')
            bars[best_idx].set_edgecolor('red')
            bars[best_idx].set_linewidth(2)
            
            axes[i].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        if save_plot:
            # ä½¿ç”¨ä¸åŸå§‹ç‰ˆæœ¬ä¸€è‡´çš„æ–‡ä»¶å
            output_path = self._get_output_path('core_performance_comparison.png')
            plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
            print(f"ğŸ“Š æ‰©å±•ç‰ˆæ€§èƒ½å›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        
        plt.close()  # å…³é—­å›¾å½¢ï¼Œé¿å…å†…å­˜æ³„æ¼
    
    def run_robustness_test(self, anomaly_ratios=None, verbose=None):
        """è¿è¡Œé²æ£’æ€§æµ‹è¯•ï¼ˆä¸åŒå¼‚å¸¸æ¯”ä¾‹ï¼‰"""
        if anomaly_ratios is None:
            anomaly_ratios = self.config.ROBUSTNESS_ANOMALY_RATIOS
        if verbose is None:
            verbose = self.config.VERBOSE
            
        if verbose:
            print("\nğŸ›¡ï¸ æ‰©å±•ç‰ˆé²æ£’æ€§æµ‹è¯•")
            print("=" * 60)
            print("æµ‹è¯•CausalEngineä¸å¤šç§æ–¹æ³•åœ¨ä¸åŒå¼‚å¸¸æ ‡ç­¾æ¯”ä¾‹ä¸‹çš„è¡¨ç°")
        
        robustness_results = {}
        
        # æ•°æ®åˆ†å‰²ï¼ˆå›ºå®šåˆ†å‰²ä»¥ç¡®ä¿ä¸€è‡´æ€§ï¼‰
        X_temp, X_test, y_temp, y_test = train_test_split(
            self.X, self.y, 
            test_size=0.2, 
            random_state=self.config.RANDOM_STATE
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp,
            test_size=0.2,
            random_state=self.config.RANDOM_STATE
        )
        
        total_tests = len(anomaly_ratios)
        for i, anomaly_ratio in enumerate(anomaly_ratios):
            if verbose:
                print(f"\nğŸ”¬ æµ‹è¯•å¼‚å¸¸æ¯”ä¾‹ {i+1}/{total_tests}: {anomaly_ratio:.1%}")
                print("-" * 30)
            
            # è®­ç»ƒæ¨¡å‹ (ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œä»…è®­ç»ƒæ ¸å¿ƒæ¨¡å‹)
            models = self._train_robustness_models(X_train, y_train, X_val, y_val, anomaly_ratio, verbose=False)
            
            # è¯„ä¼°æ¨¡å‹
            results = self._evaluate_models(models, X_val, y_val, X_test, y_test)
            robustness_results[anomaly_ratio] = results
            
            if verbose:
                print("ä¸»è¦æ–¹æ³• MdAE åˆ†æ•°:")
                core_methods = ['sklearn_mlp', 'pytorch_mlp', 'random_forest', 'mlp_huber'] + [f'causal_{mode}' for mode in self.config.CAUSAL_MODES]
                if CATBOOST_AVAILABLE:
                    core_methods.append('catboost')
                if XGBOOST_AVAILABLE:
                    core_methods.append('xgboost')
                
                for method in core_methods:
                    if method in results:
                        mdae = results[method]['test']['MdAE']
                        print(f"  {method:<15}: {mdae:.4f}")
        
        # å­˜å‚¨é²æ£’æ€§ç»“æœåˆ°ä¸»ç»“æœç»“æ„ï¼ˆä¸åŸå§‹ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
        if not hasattr(self, 'results'):
            self.results = {}
        self.results['robustness'] = robustness_results
        
        # å¯è§†åŒ–é²æ£’æ€§ç»“æœ
        if verbose:
            # æ‰“å°è¯¦ç»†çš„é²æ£’æ€§è¡¨æ ¼
            self._print_robustness_table(robustness_results, anomaly_ratios)
            # ç»˜åˆ¶é²æ£’æ€§å›¾è¡¨
            self._plot_robustness_results(robustness_results, anomaly_ratios)
            # åˆ†æé²æ£’æ€§è¶‹åŠ¿
            self._analyze_robustness_trends(robustness_results, anomaly_ratios)
        
        return robustness_results
    
    def _train_robustness_models(self, X_train, y_train, X_val, y_val, anomaly_ratio, verbose=False):
        """ä¸ºé²æ£’æ€§æµ‹è¯•è®­ç»ƒæ ¸å¿ƒæ¨¡å‹ï¼ˆç²¾ç®€ç‰ˆï¼‰"""
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–
        if self.config.USE_SCALER:
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
        else:
            # åˆ›å»ºä¸€ä¸ªæ’ç­‰å˜æ¢çš„scaler
            scaler = StandardScaler(with_mean=False, with_std=False)
            scaler.fit(X_train)
            X_train_scaled = X_train.copy() # æ˜ç¡®å¤åˆ¶
        
        # æ³¨å…¥æ ‡ç­¾å¼‚å¸¸
        y_train_noisy = self._inject_label_anomalies(y_train, anomaly_ratio, random_state=self.config.RANDOM_STATE)
        
        models = {}
        
        # è®­ç»ƒæ ¸å¿ƒæ¨¡å‹ - ä¸ºèŠ‚çœæ—¶é—´ï¼Œåªè®­ç»ƒä»£è¡¨æ€§æ¨¡å‹
        core_models_config = {
            'sklearn_mlp': MLPRegressor(
                hidden_layer_sizes=self.config.SKLEARN_HIDDEN_LAYERS,
                max_iter=self.config.SKLEARN_MAX_ITER,
                learning_rate_init=self.config.SKLEARN_LR,
                early_stopping=True,
                validation_fraction=0.2,
                n_iter_no_change=self.config.NN_PATIENCE,
                tol=self.config.NN_TOLERANCE,
                random_state=self.config.RANDOM_STATE,
                alpha=0.0001
            ),
            'pytorch_mlp': MLPPytorchRegressor(
                hidden_layer_sizes=self.config.NN_HIDDEN_SIZES,
                max_iter=self.config.PYTORCH_EPOCHS,
                learning_rate=self.config.PYTORCH_LR,
                early_stopping=True,
                validation_fraction=0.2,
                n_iter_no_change=self.config.PYTORCH_PATIENCE,
                tol=self.config.NN_TOLERANCE,
                random_state=self.config.RANDOM_STATE,
                verbose=False,
                alpha=0.0001
            ),
            'mlp_huber': MLPHuberRegressor(
                hidden_layer_sizes=self.config.NN_HIDDEN_SIZES,
                max_iter=self.config.NN_MAX_EPOCHS,
                learning_rate=self.config.NN_LEARNING_RATE,
                early_stopping=True,
                validation_fraction=0.2,
                n_iter_no_change=self.config.NN_PATIENCE,
                tol=self.config.NN_TOLERANCE,
                delta=self.config.HUBER_DELTA,
                random_state=self.config.RANDOM_STATE,
                verbose=False,
                alpha=0.0001
            ),
            'random_forest': RandomForestRegressor(
                n_estimators=self.config.RF_N_ESTIMATORS,
                max_depth=self.config.RF_MAX_DEPTH,
                random_state=self.config.RANDOM_STATE,
                n_jobs=-1
            )
        }
        
        # æ·»åŠ CatBoostï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if CATBOOST_AVAILABLE:
            core_models_config['catboost'] = CatBoostRegressor(
                iterations=self.config.CATBOOST_ITERATIONS,
                depth=self.config.CATBOOST_DEPTH,
                learning_rate=0.1,
                random_seed=self.config.RANDOM_STATE,
                verbose=False
            )
        
        # æ·»åŠ XGBoostï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if XGBOOST_AVAILABLE:
            core_models_config['xgboost'] = XGBRegressor(
                n_estimators=self.config.XGBOOST_N_ESTIMATORS,
                max_depth=self.config.XGBOOST_DEPTH,
                learning_rate=0.05,
                random_state=self.config.RANDOM_STATE,
                n_jobs=-1,
                early_stopping_rounds=50
            )
        
        # æ·»åŠ CausalEngineæ¨¡å¼
        for mode in self.config.CAUSAL_MODES:
            core_models_config[f'causal_{mode}'] = MLPCausalRegressor(
                perception_hidden_layers=self.config.CAUSAL_HIDDEN_SIZES,
                mode=mode,
                gamma_init=self.config.CAUSAL_GAMMA_INIT,
                b_noise_init=self.config.CAUSAL_B_NOISE_INIT,
                b_noise_trainable=self.config.CAUSAL_B_NOISE_TRAINABLE,
                max_iter=self.config.CAUSAL_MAX_EPOCHS,
                learning_rate=self.config.CAUSAL_LR,
                early_stopping=True,
                validation_fraction=0.2,
                n_iter_no_change=self.config.CAUSAL_PATIENCE,
                tol=self.config.CAUSAL_TOL,
                random_state=self.config.RANDOM_STATE,
                verbose=False,
                alpha=0.0001
            )
        
        # è®­ç»ƒæ¨¡å‹
        for model_name, model in core_models_config.items():
            if model_name in ['random_forest', 'catboost', 'xgboost']:
                # RF, CatBoost, XGBoostå§‹ç»ˆä½¿ç”¨åŸå§‹æ•°æ®
                if model_name == 'xgboost':
                    model.fit(X_train, y_train_noisy, eval_set=[(X_val, y_val)], verbose=False)
                else:
                    model.fit(X_train, y_train_noisy)
                # åˆ›å»ºæ’ç­‰ç¼©æ”¾å™¨
                identity_scaler = StandardScaler(with_mean=False, with_std=False)
                identity_scaler.fit(X_train)
                models[model_name] = (model, identity_scaler)
            else:
                # ç¥ç»ç½‘ç»œæ ¹æ®é…ç½®ä½¿ç”¨ç¼©æ”¾æˆ–åŸå§‹æ•°æ®
                model.fit(X_train_scaled, y_train_noisy)
                models[model_name] = (model, scaler)
        
        return models
    
    def _print_robustness_table(self, robustness_results, anomaly_ratios):
        """æ‰“å°é²æ£’æ€§æµ‹è¯•è¯¦ç»†è¡¨æ ¼"""
        print("\nğŸ“Š æ‰©å±•ç‰ˆé²æ£’æ€§æµ‹è¯•è¯¦ç»†ç»“æœè¡¨æ ¼")
        print("=" * 160)
        
        # è¡¨å¤´
        metrics = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        methods = list(robustness_results[anomaly_ratios[0]].keys())
        
        # æ‰“å°è¡¨å¤´
        header_line1 = f"{'å¼‚å¸¸æ¯”ä¾‹':<10} {'æ–¹æ³•':<20}"
        header_line2 = f"{'':10} {'':20}"
        
        for split in ['éªŒè¯é›†', 'æµ‹è¯•é›†']:
            header_line1 += f" {split:<40}"
            header_line2 += f" {metrics[0]:<9} {metrics[1]:<9} {metrics[2]:<9} {metrics[3]:<9}"
        
        print(header_line1)
        print(header_line2)
        print("-" * 160)
        
        # ä¸ºæ¯ä¸ªå¼‚å¸¸æ¯”ä¾‹æ‰“å°ç»“æœ
        for ratio in anomaly_ratios:
            ratio_str = f"{ratio:.0%}"
            
            for i, method in enumerate(methods):
                if method in robustness_results[ratio]:
                    results = robustness_results[ratio][method]
                    
                    # ç¬¬ä¸€è¡Œæ˜¾ç¤ºå¼‚å¸¸æ¯”ä¾‹ï¼Œåç»­è¡Œä¸ºç©º
                    ratio_display = ratio_str if i == 0 else ""
                    
                    line = f"{ratio_display:<10} {method:<20}"
                    
                    # éªŒè¯é›†æŒ‡æ ‡
                    val_metrics = results['val']
                    line += f" {val_metrics['MAE']:<9.4f} {val_metrics['MdAE']:<9.4f} {val_metrics['RMSE']:<9.4f} {val_metrics['RÂ²']:<9.4f}"
                    
                    # æµ‹è¯•é›†æŒ‡æ ‡
                    test_metrics = results['test']
                    line += f" {test_metrics['MAE']:<9.4f} {test_metrics['MdAE']:<9.4f} {test_metrics['RMSE']:<9.4f} {test_metrics['RÂ²']:<9.4f}"
                    
                    print(line)
            
            # åœ¨æ¯ä¸ªå¼‚å¸¸æ¯”ä¾‹ç»„ä¹‹é—´æ·»åŠ åˆ†éš”çº¿
            if ratio != anomaly_ratios[-1]:
                print("-" * 160)
        
        print("=" * 160)
        print("ğŸ’¡ è§‚å¯Ÿè¦ç‚¹ï¼š")
        print("   - RÂ² è¶Šé«˜è¶Šå¥½ï¼ˆæ¥è¿‘1.0ä¸ºæœ€ä½³ï¼‰")
        print("   - MAE, MdAE, RMSE è¶Šä½è¶Šå¥½ï¼ˆæ¥è¿‘0ä¸ºæœ€ä½³ï¼‰")
        print("   - å…³æ³¨å„æ–¹æ³•åœ¨å¼‚å¸¸æ¯”ä¾‹å¢åŠ æ—¶çš„æ€§èƒ½å˜åŒ–è¶‹åŠ¿")
    
    def _plot_robustness_results(self, robustness_results, anomaly_ratios):
        """ç»˜åˆ¶é²æ£’æ€§æµ‹è¯•ç»“æœ"""
        fig, axes = plt.subplots(2, 2, figsize=self.config.FIGURE_SIZE_ROBUSTNESS)
        fig.suptitle('Extended Robustness Test: Impact of Label Anomaly on Model Performance (Sklearn Version)', fontsize=16, fontweight='bold')
        
        methods = list(robustness_results[anomaly_ratios[0]].keys())
        
        # è®¾ç½®é¢œè‰²å’Œçº¿å‹
        method_styles = {}
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']
        
        for i, method in enumerate(methods):
            if 'causal' in method:
                method_styles[method] = {'color': 'red', 'linestyle': '-', 'linewidth': 3, 'marker': 'o', 'markersize': 8}
            elif any(robust in method for robust in ['huber', 'pinball', 'cauchy']):
                method_styles[method] = {'color': colors[i % len(colors)], 'linestyle': '--', 'linewidth': 2, 'marker': 's', 'markersize': 6}
            elif method in ['random_forest', 'catboost', 'xgboost']:
                method_styles[method] = {'color': colors[i % len(colors)], 'linestyle': '-.', 'linewidth': 2, 'marker': 'D', 'markersize': 6}
            else:
                method_styles[method] = {'color': colors[i % len(colors)], 'linestyle': ':', 'linewidth': 2, 'marker': '^', 'markersize': 6}
        
        # 4ä¸ªå›å½’æŒ‡æ ‡
        metrics = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        metric_labels = ['Mean Absolute Error (MAE)', 'Median Absolute Error (MdAE)', 'Root Mean Squared Error (RMSE)', 'R-squared Score (RÂ²)']
        
        # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºå­å›¾
        for idx, (metric, metric_label) in enumerate(zip(metrics, metric_labels)):
            row, col = idx // 2, idx % 2
            ax = axes[row, col]
            
            # ç»˜åˆ¶æ¯ä¸ªæ–¹æ³•çš„æ›²çº¿
            for method in methods:
                scores = []
                for ratio in anomaly_ratios:
                    if method in robustness_results[ratio]:
                        scores.append(robustness_results[ratio][method]['test'][metric])
                    else:
                        scores.append(np.nan)
                
                # ç®€åŒ–æ ‡ç­¾æ˜¾ç¤º
                label = self._get_clean_method_name(method)
                ax.plot(anomaly_ratios, scores, 
                       label=label, 
                       **method_styles[method])
            
            # è®¾ç½®å­å›¾å±æ€§
            ax.set_xlabel('Label Anomaly Ratio', fontsize=11)
            ax.set_ylabel(metric, fontsize=11)
            ax.set_title(metric_label, fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3)
            ax.legend(fontsize=8, loc='best')
            
            # # ä¸ºRÂ²æ·»åŠ ç‰¹æ®Šå¤„ç†ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ï¼Œå…¶ä»–æŒ‡æ ‡è¶Šä½è¶Šå¥½
            # if metric == 'RÂ²':
            #     ax.set_ylim(bottom=0)  # RÂ²ä»0å¼€å§‹æ˜¾ç¤º
            # else:
            #     ax.set_ylim(bottom=0)  # è¯¯å·®æŒ‡æ ‡ä»0å¼€å§‹æ˜¾ç¤º
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡ - ä½¿ç”¨ä¸åŸå§‹ç‰ˆæœ¬ä¸€è‡´çš„æ–‡ä»¶å
        output_path = self._get_output_path('extended_robustness_analysis.png')
        plt.savefig(output_path, dpi=self.config.FIGURE_DPI, bbox_inches='tight')
        print(f"ğŸ“Š æ‰©å±•ç‰ˆé²æ£’æ€§æµ‹è¯•å›¾è¡¨å·²ä¿å­˜ä¸º {output_path}")
        plt.close()  # å…³é—­å›¾å½¢ï¼Œé¿å…å†…å­˜æ³„æ¼
    
    def _analyze_robustness_trends(self, robustness_results, anomaly_ratios):
        """åˆ†æé²æ£’æ€§è¶‹åŠ¿"""
        print("\nğŸ”¬ æ‰©å±•ç‰ˆé²æ£’æ€§è¶‹åŠ¿åˆ†æ")
        print("=" * 60)
        
        methods = list(robustness_results[anomaly_ratios[0]].keys())
        
        # åˆ†æMdAEæŒ‡æ ‡çš„å˜åŒ–è¶‹åŠ¿
        print("ğŸ“ˆ MdAEæŒ‡æ ‡éšå¼‚å¸¸æ¯”ä¾‹å˜åŒ–è¶‹åŠ¿ï¼š")
        print("-" * 40)
        
        stability_scores = {}
        for method in methods:
            mdae_scores = []
            for ratio in anomaly_ratios:
                if method in robustness_results[ratio]:
                    mdae_scores.append(robustness_results[ratio][method]['test']['MdAE'])
                else:
                    mdae_scores.append(np.nan)
            
            # è®¡ç®—æ€§èƒ½ä¸‹é™æƒ…å†µ
            clean_mdae = mdae_scores[0] if len(mdae_scores) > 0 and not np.isnan(mdae_scores[0]) else 0
            final_mdae = mdae_scores[-1] if len(mdae_scores) > 0 and not np.isnan(mdae_scores[-1]) else 0
            
            if clean_mdae > 0:
                performance_degradation = ((final_mdae - clean_mdae) / clean_mdae) * 100
                stability_score = (max(mdae_scores) - min(mdae_scores)) / min(mdae_scores) * 100
                stability_scores[method] = stability_score
            else:
                performance_degradation = float('inf')
                stability_scores[method] = float('inf')
            
            display_name = self._get_clean_method_name(method)
            print(f"  {display_name}:")
            print(f"    - é›¶å¼‚å¸¸æ—¶MdAE: {clean_mdae:.4f}")
            print(f"    - æœ€é«˜å¼‚å¸¸æ—¶MdAE: {final_mdae:.4f}")
            print(f"    - æ€§èƒ½ä¸‹é™: {performance_degradation:+.1f}%")
            print(f"    - ç¨³å®šæ€§è¯„åˆ†: {stability_scores[method]:.1f}%")
        
        # éªŒè¯å‡è®¾
        print("\nğŸ¯ å‡è®¾éªŒè¯ç»“æœï¼š")
        print("-" * 40)
        
        # æ‰¾å‡ºæœ€ç¨³å®šçš„æ–¹æ³•
        most_stable = min(stability_scores.keys(), key=lambda x: stability_scores[x])
        least_stable = max(stability_scores.keys(), key=lambda x: stability_scores[x])
        
        print(f"âœ… æœ€ç¨³å®šæ–¹æ³•: {self._get_clean_method_name(most_stable)} (ç¨³å®šæ€§: {stability_scores[most_stable]:.1f}%)")
        print(f"âš ï¸ æœ€ä¸ç¨³å®šæ–¹æ³•: {self._get_clean_method_name(least_stable)} (ç¨³å®šæ€§: {stability_scores[least_stable]:.1f}%)")
        
        # åˆ†æCausalEngine vs å…¶ä»–æ–¹æ³•
        causal_methods = [m for m in methods if 'causal' in m]
        non_causal_methods = [m for m in methods if 'causal' not in m]
        
        if causal_methods and non_causal_methods:
            # æ‰¾å‡ºæœ€ä½³CausalEngineå’Œæœ€ä½³ä¼ ç»Ÿæ–¹æ³•
            best_causal = min(causal_methods, key=lambda x: stability_scores[x])
            best_traditional = min(non_causal_methods, key=lambda x: stability_scores[x])
            
            print(f"\nï¿½ï¿½ CausalEngine vs ä¼ ç»Ÿæ–¹æ³•ç¨³å®šæ€§å¯¹æ¯”:")
            print(f"   æœ€ä½³CausalEngine: {self._get_clean_method_name(best_causal)} (ç¨³å®šæ€§: {stability_scores[best_causal]:.1f}%)")
            print(f"   æœ€ä½³ä¼ ç»Ÿæ–¹æ³•: {self._get_clean_method_name(best_traditional)} (ç¨³å®šæ€§: {stability_scores[best_traditional]:.1f}%)")
            
            if stability_scores[best_causal] < stability_scores[best_traditional]:
                print(f"   âœ… CausalEngineæ›´ç¨³å®šï¼")
            else:
                print(f"   âš ï¸ ä¼ ç»Ÿæ–¹æ³•åœ¨æ­¤å®éªŒä¸­æ›´ç¨³å®š")
        
        # ç»¼åˆç»“è®º
        causal_in_top3 = any(method in sorted(stability_scores.keys(), key=lambda x: stability_scores[x])[:3] for method in causal_methods)
        
        print(f"\nğŸ† ç»¼åˆç»“è®º:")
        if causal_in_top3:
            print("   âœ¨ CausalEngineåœ¨é²æ£’æ€§æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒéªŒè¯äº†å…¶åœ¨å™ªå£°ç¯å¢ƒä¸­çš„ç¨³å®šæ€§ä¼˜åŠ¿")
        else:
            print("   ğŸ”¬ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–CausalEngineå‚æ•°ä»¥æå‡é²æ£’æ€§")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„æ‰©å±•ç‰ˆæ•™ç¨‹"""
    print("ğŸ  CausalEngineæ‰©å±•ç‰ˆçœŸå®ä¸–ç•Œå›å½’æ•™ç¨‹ - Sklearnç‰ˆæœ¬")
    print("ğŸ¯ ç›®æ ‡ï¼šåœ¨åŠ å·æˆ¿ä»·é¢„æµ‹ä»»åŠ¡ä¸­å±•ç¤ºCausalEngineä¸å¤šç§å¼ºåŠ›æ–¹æ³•çš„æ€§èƒ½å¯¹æ¯”")
    print("ğŸ”§ ç‰¹ç‚¹ï¼šä½¿ç”¨sklearn-style learnersï¼ŒåŒ…å«é²æ£’æ€§å›å½’å™¨å’Œé›†æˆå­¦ä¹ æ–¹æ³•")
    print("=" * 80)
    
    # åˆ›å»ºé…ç½®å®ä¾‹ï¼ˆåœ¨è¿™é‡Œå¯ä»¥è‡ªå®šä¹‰é…ç½®ï¼‰
    config = TutorialConfig()
    
    # ğŸ”§ å¿«é€Ÿé…ç½®ç¤ºä¾‹ - å–æ¶ˆæ³¨é‡Šæ¥ä¿®æ”¹å‚æ•°ï¼š
    # config.CAUSAL_MODES = ['deterministic', 'standard', 'endogenous']  # æ·»åŠ æ›´å¤šæ¨¡å¼
    # config.NN_MAX_EPOCHS = 1000  # å‡å°‘è®­ç»ƒè½®æ•°ä»¥åŠ å¿«é€Ÿåº¦
    # config.ANOMALY_RATIO = 0.1   # è®¾ç½®10%å¼‚å¸¸æ ‡ç­¾
    # config.RUN_ROBUSTNESS_TEST = False  # è·³è¿‡é²æ£’æ€§æµ‹è¯•
    
    print(f"ğŸ”§ å½“å‰é…ç½®:")
    print(f"   - CausalEngineæ¨¡å¼: {', '.join(config.CAUSAL_MODES)}")
    print(f"   - ç¥ç»ç½‘ç»œæ¶æ„: {config.NN_HIDDEN_SIZES}")
    print(f"   - æœ€å¤§è½®æ•°: {config.NN_MAX_EPOCHS}")
    print(f"   - æ—©åœpatience: {config.NN_PATIENCE}")
    print(f"   - å¼‚å¸¸æ¯”ä¾‹: {config.ANOMALY_RATIO:.1%}")
    print(f"   - è¿è¡Œé²æ£’æ€§æµ‹è¯•: {'æ˜¯' if config.RUN_ROBUSTNESS_TEST else 'å¦'}")
    print(f"   - è¾“å‡ºç›®å½•: {config.OUTPUT_DIR}/")
    print()
    
    # åˆ›å»ºæ•™ç¨‹å®ä¾‹
    tutorial = ExtendedCaliforniaHousingSklearnTutorial(config)
    
    # 1. åŠ è½½å’Œæ¢ç´¢æ•°æ®
    tutorial.load_and_explore_data()
    
    # 2. æ•°æ®å¯è§†åŒ–
    tutorial.visualize_data()
    
    # 3. è¿è¡Œç»¼åˆåŸºå‡†æµ‹è¯•
    tutorial.run_comprehensive_benchmark()
    
    # 4. æ€§èƒ½åˆ†æ
    tutorial.analyze_performance()
    
    # 5. åˆ›å»ºæ€§èƒ½å¯è§†åŒ–
    tutorial.create_performance_visualization()
    
    # 6. é²æ£’æ€§æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    if config.RUN_ROBUSTNESS_TEST:
        tutorial.run_robustness_test()
    else:
        print("\nğŸ›¡ï¸ è·³è¿‡é²æ£’æ€§æµ‹è¯•ï¼ˆé…ç½®ä¸­ç¦ç”¨ï¼‰")
    
    # 7. ç”Ÿæˆç»¼åˆå®éªŒæŠ¥å‘Š - ä¸åŸå§‹ç‰ˆæœ¬å®Œå…¨å¯¹åº”
    tutorial.generate_summary_report()
    
    print("\nğŸ‰ æ‰©å±•ç‰ˆæ•™ç¨‹å®Œæˆï¼")
    print("ğŸ“‹ æ€»ç»“:")
    print("   - ä½¿ç”¨äº†çœŸå®ä¸–ç•Œçš„åŠ å·æˆ¿ä»·æ•°æ®é›†")
    methods_count = len(config.CAUSAL_MODES) + 5 + (1 if CATBOOST_AVAILABLE else 0) + (1 if XGBOOST_AVAILABLE else 0)
    print(f"   - æ¯”è¾ƒäº†{methods_count}ç§ä¸åŒçš„æ–¹æ³•")
    print("   - åŒ…å«3ç§é²æ£’æ€§ç¥ç»ç½‘ç»œå›å½’å™¨ï¼ˆHuberã€Pinballã€Cauchyï¼‰")
    print("   - åŒ…å«å¼ºåŠ›é›†æˆå­¦ä¹ æ–¹æ³•ï¼ˆRandom Forestã€CatBoostã€XGBoostï¼‰")
    print("   - å±•ç¤ºäº†CausalEngineçš„æ€§èƒ½ä¼˜åŠ¿")
    print("   - ç›´æ¥ä½¿ç”¨sklearn-style learners")
    if config.RUN_ROBUSTNESS_TEST:
        print("   - æµ‹è¯•äº†æ¨¡å‹çš„é²æ£’æ€§")
    print("   - æä¾›äº†è¯¦ç»†çš„å¯è§†åŒ–åˆ†æ")
    print("\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
    if config.SAVE_PLOTS:
        print(f"   - {config.OUTPUT_DIR}/extended_data_analysis.png                   (æ•°æ®åˆ†æå›¾)")
        print(f"   - {config.OUTPUT_DIR}/core_performance_comparison.png              (æ€§èƒ½å¯¹æ¯”å›¾)")
        print(f"   - {config.OUTPUT_DIR}/extended_experiment_summary.md               (å®éªŒæ€»ç»“æŠ¥å‘Š)")
        if config.RUN_ROBUSTNESS_TEST:
            print(f"   - {config.OUTPUT_DIR}/extended_robustness_analysis.png             (é²æ£’æ€§æµ‹è¯•å›¾)")
    
    print("\nğŸ’¡ æç¤ºï¼šåœ¨è„šæœ¬é¡¶éƒ¨çš„TutorialConfigç±»ä¸­ä¿®æ”¹å‚æ•°æ¥è‡ªå®šä¹‰å®éªŒï¼")


if __name__ == "__main__":
    main()