#!/usr/bin/env python3
"""
æµ‹è¯•b_noise_trainableå‚æ•°åŠŸèƒ½
éªŒè¯å½“b_noise_trainable=Falseæ—¶ï¼Œb_noiseå‚æ•°ç¡®å®ä¸å‚ä¸æ¢¯åº¦æ›´æ–°
"""

import torch
import numpy as np
import sys
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')

from quick_test_causal_engine import quick_regression_test

def test_b_noise_trainable():
    """æµ‹è¯•b_noise_trainableå‚æ•°çš„å®é™…æ•ˆæœ"""
    print("ğŸ”§ æµ‹è¯•b_noise_trainableå‚æ•°åŠŸèƒ½")
    print("=" * 60)
    
    # æµ‹è¯•1: b_noise_trainable=True (é»˜è®¤è¡Œä¸º)
    print("\n1ï¸âƒ£ æµ‹è¯• b_noise_trainable=True (å¯è®­ç»ƒ):")
    results_trainable = quick_regression_test(
        n_samples=300,
        n_features=5,
        hidden_layer_sizes=(32, 16),
        gamma_init=10.0,
        b_noise_init=0.1,
        b_noise_trainable=True,  # å¯è®­ç»ƒ
        max_iter=200,
        verbose=False
    )
    
    print(f"   deterministic RÂ²: {results_trainable['deterministic']['RÂ²']:.4f}")
    print(f"   standard RÂ²:      {results_trainable['standard']['RÂ²']:.4f}")
    
    # æµ‹è¯•2: b_noise_trainable=False (å›ºå®šå€¼)
    print("\n2ï¸âƒ£ æµ‹è¯• b_noise_trainable=False (å›ºå®šå€¼):")
    results_fixed = quick_regression_test(
        n_samples=300,
        n_features=5,
        hidden_layer_sizes=(32, 16),
        gamma_init=10.0,
        b_noise_init=0.1,
        b_noise_trainable=False,  # ä¸å¯è®­ç»ƒ
        max_iter=200,
        verbose=False
    )
    
    print(f"   deterministic RÂ²: {results_fixed['deterministic']['RÂ²']:.4f}")
    print(f"   standard RÂ²:      {results_fixed['standard']['RÂ²']:.4f}")
    
    # æ¯”è¾ƒç»“æœ
    print("\nğŸ“Š ç»“æœå¯¹æ¯”:")
    print(f"   å¯è®­ç»ƒvså›ºå®š (deterministic): {results_trainable['deterministic']['RÂ²']:.4f} vs {results_fixed['deterministic']['RÂ²']:.4f}")
    print(f"   å¯è®­ç»ƒvså›ºå®š (standard):      {results_trainable['standard']['RÂ²']:.4f} vs {results_fixed['standard']['RÂ²']:.4f}")
    
    # åˆ†æé¢„æœŸè¡Œä¸º
    print("\nğŸ” é¢„æœŸè¡Œä¸ºåˆ†æ:")
    print("   - deterministicæ¨¡å¼: ä¸¤è€…åº”è¯¥ç›¸è¿‘ (ä¸ä½¿ç”¨b_noise)")
    print("   - standardæ¨¡å¼: å¯èƒ½æœ‰å·®å¼‚ (ä½¿ç”¨b_noiseï¼Œå›ºå®šå€¼é™åˆ¶äº†é€‚åº”èƒ½åŠ›)")
    
    return results_trainable, results_fixed

def test_parameter_inspection():
    """ç›´æ¥æ£€æŸ¥æ¨¡å‹å‚æ•°æ˜¯å¦æŒ‰é¢„æœŸè®¾ç½®"""
    print("\nğŸ”¬ ç›´æ¥å‚æ•°æ£€æŸ¥æµ‹è¯•")
    print("=" * 60)
    
    from causal_engine.sklearn import MLPCausalRegressor
    
    # åˆ›å»ºä¸¤ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”
    model_trainable = MLPCausalRegressor(
        hidden_layer_sizes=(16,),
        b_noise_init=0.5,
        b_noise_trainable=True,
        max_iter=1,
        verbose=False
    )
    
    model_fixed = MLPCausalRegressor(
        hidden_layer_sizes=(16,),
        b_noise_init=0.5,
        b_noise_trainable=False,
        max_iter=1,
        verbose=False
    )
    
    # åˆ›å»ºç®€å•æ•°æ®è§¦å‘æ¨¡å‹æ„å»º
    X = np.random.randn(10, 3)
    y = np.random.randn(10)
    
    model_trainable.fit(X, y)
    model_fixed.fit(X, y)
    
    # æ£€æŸ¥å‚æ•°ç±»å‹
    b_noise_trainable = model_trainable.model['causal_engine'].action.b_noise
    b_noise_fixed = model_fixed.model['causal_engine'].action.b_noise
    
    print(f"\nğŸ“‹ å‚æ•°æ£€æŸ¥ç»“æœ:")
    print(f"   å¯è®­ç»ƒæ¨¡å‹ b_noiseç±»å‹: {type(b_noise_trainable)}")
    print(f"   å›ºå®šæ¨¡å‹ b_noiseç±»å‹:   {type(b_noise_fixed)}")
    print(f"   å¯è®­ç»ƒæ¨¡å‹ requires_grad: {b_noise_trainable.requires_grad}")
    print(f"   å›ºå®šæ¨¡å‹ requires_grad:   {b_noise_fixed.requires_grad}")
    print(f"   å¯è®­ç»ƒæ¨¡å‹ å€¼: {b_noise_trainable.data}")
    print(f"   å›ºå®šæ¨¡å‹ å€¼:   {b_noise_fixed.data}")
    
    # éªŒè¯é¢„æœŸè¡Œä¸º
    print(f"\nâœ… éªŒè¯ç»“æœ:")
    if isinstance(b_noise_trainable, torch.nn.Parameter) and b_noise_trainable.requires_grad:
        print("   âœ“ å¯è®­ç»ƒæ¨¡å‹: b_noiseæ˜¯Parameterä¸”requires_grad=True")
    else:
        print("   âœ— å¯è®­ç»ƒæ¨¡å‹: b_noiseè®¾ç½®å¼‚å¸¸")
    
    if isinstance(b_noise_fixed, torch.Tensor) and not b_noise_fixed.requires_grad:
        print("   âœ“ å›ºå®šæ¨¡å‹: b_noiseæ˜¯bufferä¸”requires_grad=False")
    else:
        print("   âœ— å›ºå®šæ¨¡å‹: b_noiseè®¾ç½®å¼‚å¸¸")
    
    return model_trainable, model_fixed

def test_gradient_update():
    """æµ‹è¯•æ¢¯åº¦æ›´æ–°è¡Œä¸º"""
    print("\nğŸ¯ æ¢¯åº¦æ›´æ–°æµ‹è¯•")
    print("=" * 60)
    
    from causal_engine.sklearn import MLPCausalRegressor
    import torch.nn.functional as F
    
    # åˆ›å»ºæ¨¡å‹
    model = MLPCausalRegressor(
        hidden_layer_sizes=(8,),
        mode='standard',  # ä½¿ç”¨b_noiseçš„æ¨¡å¼
        b_noise_init=0.3,
        b_noise_trainable=False,  # æµ‹è¯•ä¸å¯è®­ç»ƒ
        max_iter=1,
        verbose=False
    )
    
    # ç®€å•æ•°æ®
    X = np.random.randn(20, 4)
    y = np.random.randn(20)
    
    model.fit(X, y)
    
    # è·å–b_noise
    causal_engine = model.model['causal_engine']
    b_noise_before = causal_engine.action.b_noise.clone()
    
    print(f"è®­ç»ƒå‰ b_noise: {b_noise_before}")
    print(f"b_noise.requires_grad: {causal_engine.action.b_noise.requires_grad}")
    
    # æ‰‹åŠ¨è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
    X_tensor = torch.tensor(X, dtype=torch.double)
    y_tensor = torch.tensor(y, dtype=torch.double)
    
    causal_engine.train()
    # ä½¿ç”¨æ­£ç¡®çš„å‰å‘ä¼ æ’­æ–¹å¼
    hidden_features = X_tensor.unsqueeze(1)  # [batch, seq, features]
    result = model._forward_with_mode(hidden_features, mode='standard')
    output = result['output']
    loss = F.mse_loss(output.squeeze(), y_tensor)
    
    print(f"æŸå¤±å€¼: {loss.item():.6f}")
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ£€æŸ¥b_noiseæ˜¯å¦å˜åŒ–
    b_noise_after = causal_engine.action.b_noise
    print(f"è®­ç»ƒå b_noise: {b_noise_after}")
    print(f"b_noiseæ˜¯å¦å˜åŒ–: {not torch.equal(b_noise_before, b_noise_after)}")
    
    if torch.equal(b_noise_before, b_noise_after):
        print("âœ… éªŒè¯æˆåŠŸ: b_noise_trainable=Falseæ—¶å‚æ•°æœªå˜åŒ–")
    else:
        print("âŒ éªŒè¯å¤±è´¥: b_noise_trainable=Falseæ—¶å‚æ•°ä»ç„¶å˜åŒ–")

if __name__ == "__main__":
    print("ğŸ§ª b_noise_trainable åŠŸèƒ½éªŒè¯æµ‹è¯•")
    print("=" * 70)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_parameter_inspection()
    test_gradient_update()
    test_b_noise_trainable()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("   - b_noise_trainable=True: è®©æ¨¡å‹è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜å™ªå£°å¼ºåº¦")
    print("   - b_noise_trainable=False: å›ºå®šå™ªå£°å¼ºåº¦ï¼Œç”¨äºæ¶ˆèå®éªŒæˆ–ç‰¹å®šéœ€æ±‚")