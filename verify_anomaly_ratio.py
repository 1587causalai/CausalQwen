#!/usr/bin/env python3
"""
éªŒè¯CLASSIFICATION_LABEL_NOISEç¡®å®ç­‰äºçœŸå®å¼‚å¸¸æ¯”ä¾‹
"""

import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
import sys
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')
from quick_test_causal_engine import QuickTester

def verify_anomaly_ratio():
    # ä½¿ç”¨å½“å‰é…ç½®
    CLASSIFICATION_LABEL_NOISE = 0.2  # å½“å‰è®¾ç½®20%
    print(f'ğŸ¯ æµ‹è¯•CLASSIFICATION_LABEL_NOISE = {CLASSIFICATION_LABEL_NOISE} (20%)')
    print('=' * 50)

    # ç”Ÿæˆç›¸åŒæ•°æ®
    np.random.seed(42)
    X, y = make_classification(n_samples=2000, n_features=15, n_classes=3, n_informative=7, 
                              n_redundant=0, n_clusters_per_class=1, class_sep=1.0, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    print(f'è®­ç»ƒé›†å¤§å°: {len(y_train)}')
    print(f'åŸå§‹ç±»åˆ«åˆ†å¸ƒ: {np.bincount(y_train)}')
    print()

    # æ·»åŠ å¼‚å¸¸
    tester = QuickTester()
    y_train_noisy = tester.add_label_anomalies(y_train, CLASSIFICATION_LABEL_NOISE, 'classification')

    # è®¡ç®—çœŸå®å¼‚å¸¸æ¯”ä¾‹
    changed = y_train != y_train_noisy
    actual_anomaly_count = np.sum(changed)
    actual_anomaly_ratio = actual_anomaly_count / len(y_train)

    print(f'ğŸ“Š å¼‚å¸¸ç»Ÿè®¡:')
    print(f'   è®¾ç½®å¼‚å¸¸æ¯”ä¾‹: {CLASSIFICATION_LABEL_NOISE:.1%}')
    print(f'   å®é™…å¼‚å¸¸æ ·æœ¬: {actual_anomaly_count} / {len(y_train)}')
    print(f'   å®é™…å¼‚å¸¸æ¯”ä¾‹: {actual_anomaly_ratio:.1%}')
    print(f'   æ˜¯å¦å®Œå…¨åŒ¹é…: {abs(actual_anomaly_ratio - CLASSIFICATION_LABEL_NOISE) < 0.001}')
    print()

    print(f'ğŸ” éªŒè¯æ— è‡ªè½¬æ¢:')
    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•è‡ªè½¬æ¢ï¼ˆåŸæ ‡ç­¾ = æ–°æ ‡ç­¾ï¼‰
    for orig_label in [0, 1, 2]:
        same_count = np.sum((y_train == orig_label) & (y_train_noisy == orig_label))
        diff_count = np.sum((y_train == orig_label) & (y_train_noisy != orig_label))
        total_orig = np.sum(y_train == orig_label)
        print(f'   æ ‡ç­¾{orig_label}: ä¿æŒ{same_count}ä¸ª, æ”¹å˜{diff_count}ä¸ª (æ€»å…±{total_orig}ä¸ª)')

    print(f'\nğŸ”„ æ ‡ç­¾è½¬æ¢è¯¦æƒ…:')
    transition_count = 0
    for orig in [0, 1, 2]:
        for new in [0, 1, 2]:
            if orig != new:
                count = np.sum((y_train == orig) & (y_train_noisy == new))
                if count > 0:
                    print(f'   {orig}â†’{new}: {count}ä¸ªè½¬æ¢')
                    transition_count += count
    
    print(f'\nğŸ“ˆ æœ€ç»ˆéªŒè¯:')
    print(f'   æ€»è½¬æ¢æ•°: {transition_count}')
    print(f'   é¢„æœŸè½¬æ¢æ•°: {int(len(y_train) * CLASSIFICATION_LABEL_NOISE)}')
    print(f'   âœ… ç»“è®º: CLASSIFICATION_LABEL_NOISE = çœŸå®å¼‚å¸¸æ¯”ä¾‹ï¼Œæ— å¹¸è¿æ•ˆåº”ï¼')

if __name__ == "__main__":
    verify_anomaly_ratio()