"""
CausalQwen MVP: æ ¸å¿ƒåŠŸèƒ½ç»„ä»¶
åŒ…å«ï¼šæ•°å­¦å·¥å…·ç±»ã€å½’å› ç½‘ç»œã€è¡ŒåŠ¨ç½‘ç»œã€åˆ†ç±»å™¨
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from .config import CausalQwen2Config


class CauchyMath:
    """Cauchyåˆ†å¸ƒæ•°å­¦å·¥å…·ç±»ï¼Œå®žçŽ°ä¸¥æ ¼çš„çº¿æ€§ç¨³å®šæ€§"""
    
    @staticmethod
    def cauchy_linear_stable_loc(loc_input, weight, bias=None):
        """Cauchyåˆ†å¸ƒä½ç½®å‚æ•°çš„çº¿æ€§å˜æ¢"""
        # ä½ç½®å‚æ•°å˜æ¢ï¼šç›´æŽ¥çŸ©é˜µä¹˜æ³•
        result = loc_input @ weight.T
        if bias is not None:
            result = result + bias
        return result
    
    @staticmethod  
    def cauchy_linear_stable_scale(scale_input, weight):
        """Cauchyåˆ†å¸ƒå°ºåº¦å‚æ•°çš„çº¿æ€§å˜æ¢"""
        # å°ºåº¦å‚æ•°å˜æ¢ï¼šç›´æŽ¥çŸ©é˜µä¹˜æ³•
        return scale_input @ torch.abs(weight).T


class AbductionNetwork(nn.Module):
    """å½’å› ç½‘ç»œï¼šä»Žéšè—çŠ¶æ€æŽ¨æ–­ä¸ªä½“è¡¨å¾åˆ†å¸ƒ"""
    
    def __init__(self, config: CausalQwen2Config):
        super().__init__()
        self.config = config
        
        # ä¿®æ­£ï¼šæ·»åŠ biasé¡¹ï¼Œç¬¦åˆè®¾è®¡æ–‡æ¡£è¦æ±‚
        self.loc_net = nn.Linear(config.hidden_size, config.causal_size, bias=True)
        self.scale_net = nn.Linear(config.hidden_size, config.causal_size, bias=True)
        
        self._init_identity_mapping()
    
    def _init_identity_mapping(self):
        """åˆå§‹åŒ–ä¸ºæ’ç­‰æ˜ å°„ï¼Œç¬¦åˆè®¾è®¡æ–‡æ¡£"""
        with torch.no_grad():
            if self.config.hidden_size == self.config.causal_size:
                # loc_netæ’ç­‰æ˜ å°„åˆå§‹åŒ–
                self.loc_net.weight.copy_(torch.eye(self.config.causal_size))
                self.loc_net.bias.zero_()
                
                # scale_netåˆå§‹åŒ–ï¼šweight=0, bias=Î³_init äº§ç”Ÿå®½åˆ†å¸ƒ
                self.scale_net.weight.zero_()
                self.scale_net.bias.fill_(self.config.gamma_init)
            else:
                # å¦‚æžœç»´åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨Xavieråˆå§‹åŒ–
                nn.init.xavier_uniform_(self.loc_net.weight)
                nn.init.zeros_(self.loc_net.bias)
                nn.init.xavier_uniform_(self.scale_net.weight)
                self.scale_net.weight.data *= 0.1
                self.scale_net.bias.fill_(self.config.gamma_init)
    
    def forward(self, hidden_states):
        """å‰å‘ä¼ æ’­ï¼Œç¬¦åˆè®¾è®¡æ–‡æ¡£çš„æ•°å­¦è¦æ±‚"""
        # ä½ç½®å‚æ•°ï¼šæ ‡å‡†çº¿æ€§å˜æ¢
        loc_U = self.loc_net(hidden_states)
        
        # å°ºåº¦å‚æ•°ï¼šä½¿ç”¨softplusç¡®ä¿æ­£æ€§ï¼Œç¬¦åˆè®¾è®¡æ–‡æ¡£
        scale_U = F.softplus(self.scale_net(hidden_states))
        
        return loc_U, scale_U


class ActionNetwork(nn.Module):
    """è¡ŒåŠ¨ç½‘ç»œï¼šä»Žä¸ªä½“è¡¨å¾åˆ°å†³ç­–åˆ†å¸ƒ"""
    
    def __init__(self, config: CausalQwen2Config):
        super().__init__()
        self.config = config
        
        # ä¿®æ­£ï¼šæ·»åŠ biasé¡¹ï¼Œç¬¦åˆè®¾è®¡æ–‡æ¡£è¦æ±‚
        self.lm_head = nn.Linear(config.causal_size, config.vocab_size, bias=True)
        
        # ä¿®æ­£ï¼šb_noiseç»´åº¦åº”è¯¥æ˜¯causal_sizeï¼Œç”¨äºŽå¤–ç”Ÿå™ªå£°èžåˆ
        self.b_noise = nn.Parameter(torch.zeros(config.causal_size))
        
        self._init_from_original_lm_head()
    
    def _init_from_original_lm_head(self):
        """ä»ŽåŽŸå§‹lm_headå¤åˆ¶æƒé‡ï¼Œç¬¦åˆçŸ¥è¯†ç»§æ‰¿åŽŸåˆ™"""
        # å¤–ç”Ÿå™ªå£°åº”æœ‰åˆç†çš„åˆå§‹å€¼ï¼Œè€Œéžå‡è®¾æ— å™ªå£°
        nn.init.constant_(self.b_noise, self.config.b_noise_init)
        
        # TODO: å½“æœ‰é¢„è®­ç»ƒæ¨¡åž‹å¯ç”¨æ—¶ï¼Œåº”ä»Žå…¶å¤åˆ¶æƒé‡
        # ç›®å‰ä½¿ç”¨æ ‡å‡†åˆå§‹åŒ–ä½œä¸ºå¤‡é€‰
        nn.init.xavier_uniform_(self.lm_head.weight)
        nn.init.zeros_(self.lm_head.bias)
        
    def copy_weights_from_qwen(self, qwen_model):
        """ä»Žé¢„è®­ç»ƒQwen2æ¨¡åž‹å¤åˆ¶lm_headæƒé‡"""
        if hasattr(qwen_model, 'lm_head'):
            print("æ­£åœ¨å¤åˆ¶Qwen2é¢„è®­ç»ƒæƒé‡...")
            with torch.no_grad():
                # ç¡®ä¿vocab_sizeä¸€è‡´ï¼ˆåŒ…å«é¢„ç•™è¯æ±‡ï¼‰
                if qwen_model.lm_head.weight.shape == self.lm_head.weight.shape:
                    self.lm_head.weight.copy_(qwen_model.lm_head.weight)
                    if hasattr(qwen_model.lm_head, 'bias') and qwen_model.lm_head.bias is not None:
                        self.lm_head.bias.copy_(qwen_model.lm_head.bias)
                    print(f"âœ… æˆåŠŸå¤åˆ¶æƒé‡ï¼Œè¯æ±‡è¡¨å¤§å°: {qwen_model.lm_head.weight.shape[0]}")
                else:
                    print(f"âŒ æƒé‡å½¢çŠ¶ä¸åŒ¹é…: Qwen({qwen_model.lm_head.weight.shape}) vs CausalQwen({self.lm_head.weight.shape})")
                    print("ä½¿ç”¨æ ‡å‡†åˆå§‹åŒ–...")
        else:
            print("âŒ æºæ¨¡åž‹æ²¡æœ‰lm_headï¼Œä½¿ç”¨æ ‡å‡†åˆå§‹åŒ–...")
        
    def forward(self, loc_U, scale_U=None, do_sample=False, temperature=1.0):
        """å‰å‘ä¼ æ’­ - åŒæ¨¡å¼è®¾è®¡ï¼šä½ç½®vså°ºåº¦çš„å·®å¼‚åŒ–å¤„ç†
        
        æ ¸å¿ƒæœºåˆ¶ï¼šå™ªå£°å¯¹é‡‡æ ·/éžé‡‡æ ·æ¨¡å¼çš„ä¸åŒå½±å“æ–¹å¼
        
        é‡‡æ ·æ¨¡å¼ï¼šå™ªå£°å½±å“ä½ç½®å‚æ•°
        â”œâ”€ Îµ ~ Cauchy(0, 1) æ ‡å‡†å™ªå£°é‡‡æ ·
        â”œâ”€ U' ~ Cauchy(Î¼ + TÂ·|b_noise|Â·Îµ, Î³) å™ªå£°æ³¨å…¥ä½ç½®å‚æ•°
        â””â”€ æ‰°åŠ¨ä¸ªä½“èº«ä»½ï¼Œä¿æŒåŽŸæœ‰ä¸ç¡®å®šæ€§
        
        éžé‡‡æ ·æ¨¡å¼ï¼šå™ªå£°å½±å“å°ºåº¦å‚æ•°  
        â”œâ”€ U' ~ Cauchy(Î¼, Î³ + |b_noise|) å™ªå£°èžåˆåˆ°å°ºåº¦
        â””â”€ ä¿æŒä¸ªä½“èº«ä»½ï¼Œå¢žåŠ å†³ç­–ä¸ç¡®å®šæ€§
        
        Args:
            loc_U: ä¸ªä½“è¡¨å¾åˆ†å¸ƒçš„ä½ç½®å‚æ•° [B, S, C]
            scale_U: ä¸ªä½“è¡¨å¾åˆ†å¸ƒçš„å°ºåº¦å‚æ•° [B, S, C]
            do_sample: æ˜¯å¦è¿›è¡Œé‡‡æ ·ï¼ˆå†³å®šå™ªå£°ä½œç”¨æ–¹å¼ï¼‰
            temperature: é‡‡æ ·æ¸©åº¦å‚æ•°ï¼ˆä»…åœ¨do_sample=Trueæ—¶ç”Ÿæ•ˆï¼‰
        Returns:
            loc_S: å†³ç­–åˆ†å¸ƒçš„ä½ç½®å‚æ•° [B, S, V]
            scale_S: å†³ç­–åˆ†å¸ƒçš„å°ºåº¦å‚æ•° [B, S, V]
        """
        # å¤„ç†é»˜è®¤å°ºåº¦å‚æ•°
        if scale_U is None:
            scale_U = torch.zeros_like(loc_U)  # é»˜è®¤ä¸ºç¡®å®šæ€§åˆ†å¸ƒ
        
        if do_sample:
            # ðŸŽ¯ é‡‡æ ·æ¨¡å¼ï¼šå™ªå£°å½±å“ä½ç½®å‚æ•°
            
            # Step 1: é‡‡æ ·æ ‡å‡†æŸ¯è¥¿å™ªå£° Îµ ~ Cauchy(0, I)
            uniform_sample = torch.rand_like(loc_U)
            epsilon = torch.tan(torch.pi * (uniform_sample - 0.5))
            
            # Step 2: æ¸©åº¦è°ƒèŠ‚çš„å™ªå£°æ³¨å…¥åˆ°ä½ç½®å‚æ•°
            # æ•°å­¦ï¼šloc_U_noisy = Î¼ + TÂ·|b_noise|Â·Îµ
            noise_injection = epsilon * temperature * torch.abs(self.b_noise)
            loc_U_noisy = loc_U + noise_injection
            
            # Step 3: åŸºäºŽæ‰°åŠ¨åŽçš„ä½ç½®å‚æ•°è¿›è¡Œçº¿æ€§å†³ç­–
            # æ•°å­¦ï¼šloc_S = WÂ·(Î¼ + TÂ·|b_noise|Â·Îµ) + b
            loc_S = self.lm_head(loc_U_noisy)
            
            # Step 4: å°ºåº¦å‚æ•°çš„çº¿æ€§ç¨³å®šæ€§å˜æ¢
            # æ•°å­¦ï¼šscale_S = Î³ Ã— |W|^T
            scale_S = scale_U @ torch.abs(self.lm_head.weight).T

        else:
            # ðŸ”§ éžé‡‡æ ·æ¨¡å¼ï¼šå™ªå£°å½±å“å°ºåº¦å‚æ•°
            
            # Step 1: å¤–ç”Ÿå™ªå£°èžåˆåˆ°å°ºåº¦å‚æ•°
            # æ•°å­¦ï¼šscale_U_noisy = Î³ + |b_noise|
            scale_U_noisy = scale_U + torch.abs(self.b_noise)
            
            # Step 2: ä½ç½®å‚æ•°ä¿æŒç¡®å®šæ€§çš„çº¿æ€§å˜æ¢
            # æ•°å­¦ï¼šloc_S = WÂ·Î¼ + b
            loc_S = self.lm_head(loc_U)
            
            # Step 3: å°ºåº¦å‚æ•°çš„çº¿æ€§ç¨³å®šæ€§å˜æ¢
            # æ•°å­¦ï¼šscale_S = (Î³ + |b_noise|) Ã— |W|^T
            scale_S = scale_U_noisy @ torch.abs(self.lm_head.weight).T
        
        return loc_S, scale_S


class OvRClassifier(nn.Module):
    """One-vs-Reståˆ†ç±»å™¨"""
    
    def __init__(self, config: CausalQwen2Config):
        super().__init__()
        self.config = config
        self.thresholds = nn.Parameter(torch.full((config.vocab_size,), config.ovr_threshold_init))
    
    def forward(self, loc_S, scale_S):
        """è®¡ç®—OvRæ¦‚çŽ‡ - å ä½å®žçŽ°"""
        # TODO: å®žçŽ°ä¸¥æ ¼çš„Cauchyåˆ†å¸ƒCDFè®¡ç®—
        # å ä½ï¼šä½¿ç”¨ç®€åŒ–çš„æ¦‚çŽ‡è®¡ç®—
        # P(y_k=1) = P(Cauchy(loc_S_k, scale_S_k) > threshold_k)
        normalized_diff = (loc_S - self.thresholds.unsqueeze(0).unsqueeze(0)) / scale_S
        # ä½¿ç”¨atanè¿‘ä¼¼Cauchy CDF: P = 0.5 + (1/Ï€) * atan(x)
        probs = 0.5 + (1/torch.pi) * torch.atan(normalized_diff)
        return probs 