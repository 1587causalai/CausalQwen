"""
CausalEngine Sklearn Interface Demo

æ¼”ç¤ºMLPCausalRegressorå’ŒMLPCausalClassifierçš„åŸºç¡€åŠŸèƒ½
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression, make_classification
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.metrics import r2_score, accuracy_score, mean_squared_error
import sys
import os
import torch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')

# å¯¼å…¥CausalEngine sklearnæ¥å£
try:
    from causal_engine.sklearn import MLPCausalRegressor, MLPCausalClassifier
    print("âœ… CausalEngine sklearnæ¥å£å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


def freeze_abduction_to_identity(model):
    """
    å†»ç»“æ¨¡å‹çš„AbductionNetworkä¸ºæ’ç­‰æ˜ å°„
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸå†»ç»“
    """
    abduction = model.causal_engine.abduction
    
    if hasattr(abduction, '_loc_is_identity_candidate') and abduction._loc_is_identity_candidate:
        with torch.no_grad():
            causal_size = abduction.causal_size
            abduction.loc_net.weight.copy_(torch.eye(causal_size))
            abduction.loc_net.bias.zero_()
            
        abduction.loc_net.weight.requires_grad = False
        abduction.loc_net.bias.requires_grad = False
        return True
    return False

def enable_traditional_loss_mode(model, task_type='regression'):
    """
    ä¸ºå†»ç»“çš„æ¨¡å‹å¯ç”¨ä¼ ç»ŸæŸå¤±å‡½æ•°æ¨¡å¼
    
    Args:
        model: CausalRegressor æˆ– CausalClassifier
        task_type: 'regression' æˆ– 'classification'
    """
    if task_type == 'regression':
        # ä¸ºå›å½’ä»»åŠ¡æ›¿æ¢æŸå¤±å‡½æ•°ä¸ºMSE
        def mse_loss(predictions, targets):
            # æå–ä½ç½®å‚æ•°ä½œä¸ºé¢„æµ‹å€¼
            if isinstance(predictions, dict):
                if 'activation_output' in predictions and 'regression_values' in predictions['activation_output']:
                    pred_values = predictions['activation_output']['regression_values'].squeeze()
                elif 'loc_S' in predictions:
                    pred_values = predictions['loc_S'].squeeze()
                else:
                    raise ValueError("Cannot extract predictions for MSE loss")
            else:
                pred_values = predictions.squeeze()
            
            targets = targets.squeeze()
            return torch.nn.functional.mse_loss(pred_values, targets)
        
        model._traditional_loss = mse_loss
        model._use_traditional_loss = True
        
    elif task_type == 'classification':
        # ä¸ºåˆ†ç±»ä»»åŠ¡æ›¿æ¢æŸå¤±å‡½æ•°ä¸ºCrossEntropy
        def crossentropy_loss(predictions, targets):
            # æå–logits
            if isinstance(predictions, dict) and 'loc_S' in predictions:
                logits = predictions['loc_S']  # [batch_size, seq_len, n_classes]
                if logits.dim() == 3:
                    logits = logits.squeeze(1)  # [batch_size, n_classes]
            else:
                raise ValueError("Cannot extract logits for CrossEntropy loss")
                
            targets = targets.long().squeeze()
            return torch.nn.functional.cross_entropy(logits, targets)
        
        model._traditional_loss = crossentropy_loss  
        model._use_traditional_loss = True


def demo_regression():
    """æ¼”ç¤ºå› æœå›å½’åŠŸèƒ½"""
    print("\\n" + "="*50)
    print("ğŸ”§ å› æœå›å½’æ¼”ç¤º")
    print("="*50)
    
    # ç”Ÿæˆå›å½’æ•°æ®
    X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    print(f"æ•°æ®ç»´åº¦: X_train {X_train.shape}, y_train {y_train.shape}")
    
    # ä¼ ç»ŸMLPRegressor
    print("\\nè®­ç»ƒä¼ ç»ŸMLPRegressor...")
    traditional_reg = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)
    traditional_reg.fit(X_train, y_train)
    trad_pred = traditional_reg.predict(X_test)
    trad_r2 = r2_score(y_test, trad_pred)
    trad_mse = mean_squared_error(y_test, trad_pred)
    
    print(f"ä¼ ç»Ÿæ–¹æ³• - RÂ²: {trad_r2:.4f}, MSE: {trad_mse:.4f}")
    
    # CausalEngineå›å½’å™¨(å®Œæ•´)
    print("\\nè®­ç»ƒMLPCausalRegressor(å®Œæ•´)...")
    causal_reg = MLPCausalRegressor(
        hidden_layer_sizes=(64, 32), 
        max_iter=500, 
        random_state=42,
        verbose=True
    )
    causal_reg.fit(X_train, y_train)
    
    # å…¼å®¹æ¨¡å¼é¢„æµ‹
    causal_pred = causal_reg.predict(X_test, mode='compatible')
    causal_r2 = r2_score(y_test, causal_pred) 
    causal_mse = mean_squared_error(y_test, causal_pred)
    
    print(f"å› æœæ–¹æ³•(å®Œæ•´) - RÂ²: {causal_r2:.4f}, MSE: {causal_mse:.4f}")
    
    # CausalEngineå›å½’å™¨(å†»ç»“+ä¼ ç»ŸæŸå¤±) - æ­£ç¡®çš„æ•°å­¦ç­‰ä»·æ€§éªŒè¯
    print("\\nè®­ç»ƒMLPCausalRegressor(å†»ç»“+ä¼ ç»ŸæŸå¤±)...")
    frozen_reg = MLPCausalRegressor(
        hidden_layer_sizes=(64, 32),
        causal_size=32,  # ç­‰äºæœ€åéšè—å±‚å¤§å°ï¼Œä¾¿äºå†»ç»“
        max_iter=500,
        random_state=42,
        verbose=False
    )
    
    # å…ˆåˆå§‹åŒ–å†å†»ç»“å’Œåˆ‡æ¢æŸå¤±å‡½æ•°
    frozen_reg.fit(X_train[:50], y_train[:50])  # å°æ‰¹é‡åˆå§‹åŒ–
    freeze_success = freeze_abduction_to_identity(frozen_reg)
    
    if freeze_success:
        print("âœ… æˆåŠŸå†»ç»“AbductionNetworkä¸ºæ’ç­‰æ˜ å°„")
        
        # å…³é”®ï¼šå¯ç”¨ä¼ ç»ŸMSEæŸå¤±å‡½æ•°
        enable_traditional_loss_mode(frozen_reg, 'regression')
        
        # æ›¿æ¢æŸå¤±å‡½æ•°
        original_compute_loss = frozen_reg._compute_loss
        frozen_reg._compute_loss = lambda predictions, targets: frozen_reg._traditional_loss(predictions, targets)
        
        print("âœ… å·²åˆ‡æ¢åˆ°ä¼ ç»ŸMSEæŸå¤±å‡½æ•°")
        
        # é‡æ–°è®­ç»ƒï¼ˆä½¿ç”¨MSEæŸå¤±ï¼‰
        frozen_reg.fit(X_train, y_train)
        frozen_pred = frozen_reg.predict(X_test, mode='compatible')
        frozen_r2 = r2_score(y_test, frozen_pred)
        frozen_mse = mean_squared_error(y_test, frozen_pred)
        print(f"å› æœæ–¹æ³•(å†»ç»“+MSE) - RÂ²: {frozen_r2:.4f}, MSE: {frozen_mse:.4f}")
        
        # æ¢å¤åŸæŸå¤±å‡½æ•°
        frozen_reg._compute_loss = original_compute_loss
    else:
        print("âŒ æ— æ³•å†»ç»“AbductionNetwork")
        frozen_r2 = frozen_mse = 0
    
    # é«˜çº§é¢„æµ‹æ¨¡å¼
    print("\\nğŸš€ é«˜çº§é¢„æµ‹æ¨¡å¼æ¼”ç¤º:")
    
    # æ ‡å‡†æ¨¡å¼ï¼šåŒ…å«ä¸ç¡®å®šæ€§
    advanced_pred = causal_reg.predict(X_test[:5], mode='standard')
    print(f"æ ‡å‡†æ¨¡å¼è¾“å‡ºç±»å‹: {type(advanced_pred)}")
    if isinstance(advanced_pred, dict):
        print(f"  - é¢„æµ‹å€¼: {advanced_pred['predictions'][:3]}")
        print(f"  - åˆ†å¸ƒä¿¡æ¯: {list(advanced_pred['distributions'].keys())}")
    
    # å› æœæ¨¡å¼
    causal_pure = causal_reg.predict(X_test[:5], mode='causal')
    print(f"å› æœæ¨¡å¼è¾“å‡º: å·²è®¡ç®—")
    
    print(f"\\nâœ… å›å½’æ¼”ç¤ºå®Œæˆï¼")
    return {
        'traditional_r2': trad_r2,
        'causal_r2': causal_r2,
        'frozen_r2': frozen_r2 if freeze_success else 0,
        'improvement': causal_r2 - trad_r2,
        'frozen_improvement': frozen_r2 - trad_r2 if freeze_success else 0,
        'freeze_success': freeze_success
    }


def demo_classification():
    """æ¼”ç¤ºå› æœåˆ†ç±»åŠŸèƒ½"""
    print("\\n" + "="*50)
    print("ğŸ¯ å› æœåˆ†ç±»æ¼”ç¤º")
    print("="*50)
    
    # ç”Ÿæˆåˆ†ç±»æ•°æ®
    X, y = make_classification(n_samples=1000, n_features=10, n_classes=3, 
                              n_redundant=0, n_informative=8, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    print(f"æ•°æ®ç»´åº¦: X_train {X_train.shape}, y_train {y_train.shape}")
    print(f"ç±»åˆ«æ•°: {len(np.unique(y))}")
    
    # ä¼ ç»ŸMLPClassifier
    print("\\nè®­ç»ƒä¼ ç»ŸMLPClassifier...")
    traditional_clf = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)
    traditional_clf.fit(X_train, y_train)
    trad_pred = traditional_clf.predict(X_test)
    trad_acc = accuracy_score(y_test, trad_pred)
    trad_proba = traditional_clf.predict_proba(X_test)
    
    print(f"ä¼ ç»Ÿæ–¹æ³• - å‡†ç¡®ç‡: {trad_acc:.4f}")
    
    # CausalEngineåˆ†ç±»å™¨(å®Œæ•´)
    print("\\nè®­ç»ƒMLPCausalClassifier(å®Œæ•´)...")
    causal_clf = MLPCausalClassifier(
        hidden_layer_sizes=(64, 32),
        max_iter=500,
        random_state=42,
        verbose=True
    )
    causal_clf.fit(X_train, y_train)
    
    # å…¼å®¹æ¨¡å¼é¢„æµ‹
    causal_pred = causal_clf.predict(X_test, mode='compatible')
    causal_acc = accuracy_score(y_test, causal_pred)
    
    print(f"å› æœæ–¹æ³•(å®Œæ•´) - å‡†ç¡®ç‡: {causal_acc:.4f}")
    
    # CausalEngineåˆ†ç±»å™¨(å†»ç»“+ä¼ ç»ŸæŸå¤±) - æ­£ç¡®çš„æ•°å­¦ç­‰ä»·æ€§éªŒè¯
    print("\\nè®­ç»ƒMLPCausalClassifier(å†»ç»“+ä¼ ç»ŸæŸå¤±)...")
    frozen_clf = MLPCausalClassifier(
        hidden_layer_sizes=(64, 32),
        causal_size=32,  # ç­‰äºæœ€åéšè—å±‚å¤§å°ï¼Œä¾¿äºå†»ç»“
        max_iter=500,
        random_state=42,
        verbose=False
    )
    
    # å…ˆåˆå§‹åŒ–å†å†»ç»“å’Œåˆ‡æ¢æŸå¤±å‡½æ•°
    frozen_clf.fit(X_train[:50], y_train[:50])  # å°æ‰¹é‡åˆå§‹åŒ–
    freeze_success_clf = freeze_abduction_to_identity(frozen_clf)
    
    if freeze_success_clf:
        print("âœ… æˆåŠŸå†»ç»“AbductionNetworkä¸ºæ’ç­‰æ˜ å°„")
        
        # å…³é”®ï¼šå¯ç”¨ä¼ ç»ŸCrossEntropyæŸå¤±å‡½æ•°
        enable_traditional_loss_mode(frozen_clf, 'classification')
        
        # æ›¿æ¢æŸå¤±å‡½æ•°
        original_compute_loss_clf = frozen_clf._compute_loss
        frozen_clf._compute_loss = lambda predictions, targets: frozen_clf._traditional_loss(predictions, targets)
        
        print("âœ… å·²åˆ‡æ¢åˆ°ä¼ ç»ŸCrossEntropyæŸå¤±å‡½æ•°")
        
        # é‡æ–°è®­ç»ƒï¼ˆä½¿ç”¨CrossEntropyæŸå¤±ï¼‰
        frozen_clf.fit(X_train, y_train)
        frozen_pred = frozen_clf.predict(X_test, mode='compatible')
        frozen_acc = accuracy_score(y_test, frozen_pred)
        print(f"å› æœæ–¹æ³•(å†»ç»“+CrossEntropy) - å‡†ç¡®ç‡: {frozen_acc:.4f}")
        
        # æ¢å¤åŸæŸå¤±å‡½æ•°
        frozen_clf._compute_loss = original_compute_loss_clf
    else:
        print("âŒ æ— æ³•å†»ç»“AbductionNetwork")
        frozen_acc = 0
    
    # æ¦‚ç‡é¢„æµ‹å¯¹æ¯”
    print("\\nğŸ² æ¦‚ç‡é¢„æµ‹æ¼”ç¤º:")
    
    # Softmaxå…¼å®¹æ¦‚ç‡
    causal_proba_compat = causal_clf.predict_proba(X_test[:3], mode='compatible')
    print(f"Softmaxå…¼å®¹æ¦‚ç‡ (å‰3æ ·æœ¬):")
    for i, prob in enumerate(causal_proba_compat):
        print(f"  æ ·æœ¬{i}: {prob}")
        
    # OvRåŸç”Ÿæ¦‚ç‡
    causal_proba_ovr = causal_clf.predict_proba(X_test[:3], mode='standard')
    print(f"\\nOvRåŸç”Ÿæ¦‚ç‡ (å‰3æ ·æœ¬):")
    for i, prob in enumerate(causal_proba_ovr):
        print(f"  æ ·æœ¬{i}: {prob}")
    
    # é«˜çº§é¢„æµ‹æ¨¡å¼
    print("\\nğŸš€ é«˜çº§é¢„æµ‹æ¨¡å¼æ¼”ç¤º:")
    advanced_pred = causal_clf.predict(X_test[:5], mode='standard')
    print(f"æ ‡å‡†æ¨¡å¼è¾“å‡ºç±»å‹: {type(advanced_pred)}")
    if isinstance(advanced_pred, dict):
        print(f"  - é¢„æµ‹ç±»åˆ«: {advanced_pred['predictions']}")
        print(f"  - æ¿€æ´»æ¦‚ç‡å½¢çŠ¶: {advanced_pred['probabilities'].shape}")
    
    print(f"\\nâœ… åˆ†ç±»æ¼”ç¤ºå®Œæˆï¼")
    return {
        'traditional_acc': trad_acc,
        'causal_acc': causal_acc,
        'frozen_acc': frozen_acc if freeze_success_clf else 0,
        'improvement': causal_acc - trad_acc,
        'frozen_improvement': frozen_acc - trad_acc if freeze_success_clf else 0,
        'freeze_success': freeze_success_clf
    }


def demo_noise_robustness():
    """æ¼”ç¤ºæ ‡ç­¾å™ªå£°é²æ£’æ€§"""
    print("\\n" + "="*50)
    print("ğŸ›¡ï¸ æ ‡ç­¾å™ªå£°é²æ£’æ€§æ¼”ç¤º")
    print("="*50)
    
    results = {}
    
    # === å›å½’ä»»åŠ¡å™ªå£°é²æ£’æ€§ ===
    print("\\nğŸ“Š å›å½’ä»»åŠ¡å™ªå£°é²æ£’æ€§:")
    X_reg, y_reg_clean = make_regression(n_samples=800, n_features=10, noise=0.1, random_state=42)
    X_train_reg, X_test_reg, y_train_reg_clean, y_test_reg = train_test_split(
        X_reg, y_reg_clean, test_size=0.2, random_state=42
    )
    
    # æ·»åŠ å›å½’å™ªå£° (15%å¼‚å¸¸å€¼ - 5å€æ ‡å‡†å·®çš„éšæœºåç§»)
    y_train_reg_noisy = y_train_reg_clean.copy()
    noise_std = np.std(y_train_reg_clean)
    n_noise_reg = int(0.15 * len(y_train_reg_noisy))
    noise_indices_reg = np.random.choice(len(y_train_reg_noisy), n_noise_reg, replace=False)
    
    for idx in noise_indices_reg:
        noise_magnitude = np.random.choice([-5, -3, 3, 5]) * noise_std
        y_train_reg_noisy[idx] += noise_magnitude
    
    print(f"å›å½’æ•°æ®: {len(y_train_reg_clean)} æ ·æœ¬")
    print(f"å™ªå£°æ ·æœ¬: {n_noise_reg} æ ·æœ¬ ({n_noise_reg/len(y_train_reg_clean)*100:.1f}%)")
    
    # ä¸‰ç§æ–¹æ³•åœ¨å™ªå£°å›å½’æ•°æ®ä¸Šçš„è¡¨ç°å¯¹æ¯”
    print("\\nå›å½’å™ªå£°æµ‹è¯•:")
    
    # ä¼ ç»Ÿå›å½’æ–¹æ³•
    trad_reg_noisy = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)
    trad_reg_noisy.fit(X_train_reg, y_train_reg_noisy)
    trad_pred_noisy = trad_reg_noisy.predict(X_test_reg)
    trad_r2_noisy = r2_score(y_test_reg, trad_pred_noisy)
    
    # å®Œæ•´å› æœå›å½’æ–¹æ³•
    causal_reg_noisy = MLPCausalRegressor(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)
    causal_reg_noisy.fit(X_train_reg, y_train_reg_noisy)
    causal_pred_noisy = causal_reg_noisy.predict(X_test_reg, mode='compatible')
    causal_r2_noisy = r2_score(y_test_reg, causal_pred_noisy)
    
    # å†»ç»“å› æœå›å½’æ–¹æ³•(æ•°å­¦ç­‰ä»·æ€§éªŒè¯)
    frozen_reg_noisy = MLPCausalRegressor(
        hidden_layer_sizes=(64, 32),
        causal_size=32,
        max_iter=300,
        random_state=42
    )
    
    frozen_reg_noisy.fit(X_train_reg[:50], y_train_reg_noisy[:50])
    freeze_success_reg = freeze_abduction_to_identity(frozen_reg_noisy)
    
    if freeze_success_reg:
        enable_traditional_loss_mode(frozen_reg_noisy, 'regression')
        original_compute_loss_reg = frozen_reg_noisy._compute_loss
        frozen_reg_noisy._compute_loss = lambda predictions, targets: frozen_reg_noisy._traditional_loss(predictions, targets)
        
        frozen_reg_noisy.fit(X_train_reg, y_train_reg_noisy)
        frozen_pred_noisy = frozen_reg_noisy.predict(X_test_reg, mode='compatible')
        frozen_r2_noisy = r2_score(y_test_reg, frozen_pred_noisy)
        
        frozen_reg_noisy._compute_loss = original_compute_loss_reg
    else:
        frozen_r2_noisy = 0
    
    print(f"  ä¼ ç»ŸMLP (MSE): {trad_r2_noisy:.4f}")
    print(f"  å› æœå®Œæ•´ (Cauchy): {causal_r2_noisy:.4f}")
    if freeze_success_reg:
        print(f"  å› æœå†»ç»“ (MSE): {frozen_r2_noisy:.4f}")
        print(f"  å®Œæ•´å› æœä¼˜åŠ¿: +{(causal_r2_noisy - trad_r2_noisy)*100:.1f}%")
        print(f"  å†»ç»“å› æœä¼˜åŠ¿: +{(frozen_r2_noisy - trad_r2_noisy)*100:.1f}%")
    else:
        print(f"  å› æœä¼˜åŠ¿: +{(causal_r2_noisy - trad_r2_noisy)*100:.1f}%")
    
    results['regression'] = {
        'traditional_noisy': trad_r2_noisy,
        'causal_noisy': causal_r2_noisy,
        'frozen_noisy': frozen_r2_noisy if freeze_success_reg else 0,
        'robustness_advantage': causal_r2_noisy - trad_r2_noisy,
        'frozen_advantage': frozen_r2_noisy - trad_r2_noisy if freeze_success_reg else 0,
        'freeze_success': freeze_success_reg
    }
    
    # === åˆ†ç±»ä»»åŠ¡å™ªå£°é²æ£’æ€§ ===  
    print("\\nğŸ¯ åˆ†ç±»ä»»åŠ¡å™ªå£°é²æ£’æ€§:")
    X, y = make_classification(n_samples=800, n_features=10, n_classes=3, 
                              n_redundant=0, n_informative=8, random_state=42)
    X_train, X_test, y_train_clean, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # æ·»åŠ æ ‡ç­¾å™ªå£° (20%éšæœºç¿»è½¬)
    y_train_noisy = y_train_clean.copy()
    n_noise = int(0.2 * len(y_train_noisy))
    noise_indices = np.random.choice(len(y_train_noisy), n_noise, replace=False)
    
    for idx in noise_indices:
        available_labels = [l for l in np.unique(y) if l != y_train_noisy[idx]]
        y_train_noisy[idx] = np.random.choice(available_labels)
    
    print(f"åˆ†ç±»æ•°æ®: {len(y_train_clean)} æ ·æœ¬")
    print(f"å™ªå£°æ ‡ç­¾: {n_noise} æ ·æœ¬ ({n_noise/len(y_train_clean)*100:.1f}%)")
    
    # ä¸‰ç§æ–¹æ³•åœ¨å™ªå£°æ•°æ®ä¸Šçš„è¡¨ç°å¯¹æ¯”
    print("\\nåˆ†ç±»å™ªå£°æµ‹è¯•:")
    
    # ä¼ ç»Ÿæ–¹æ³•
    trad_clf_noisy = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)
    trad_clf_noisy.fit(X_train, y_train_noisy)
    trad_acc_noisy = accuracy_score(y_test, trad_clf_noisy.predict(X_test))
    
    # å› æœæ–¹æ³•(å®Œæ•´)
    causal_clf_noisy = MLPCausalClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)
    causal_clf_noisy.fit(X_train, y_train_noisy)
    causal_acc_noisy = accuracy_score(y_test, causal_clf_noisy.predict(X_test))
    
    # å› æœæ–¹æ³•(å†»ç»“+ä¼ ç»ŸæŸå¤±) - çœŸæ­£çš„æ•°å­¦ç­‰ä»·æ€§å¯¹æ¯”
    frozen_clf_noisy = MLPCausalClassifier(
        hidden_layer_sizes=(64, 32), 
        causal_size=32,
        max_iter=300, 
        random_state=42
    )
    
    # å…ˆåˆå§‹åŒ–å†å†»ç»“å’Œåˆ‡æ¢æŸå¤±å‡½æ•°
    frozen_clf_noisy.fit(X_train[:50], y_train_noisy[:50])
    freeze_success_noise = freeze_abduction_to_identity(frozen_clf_noisy)
    
    if freeze_success_noise:
        # å¯ç”¨ä¼ ç»ŸCrossEntropyæŸå¤±å‡½æ•°
        enable_traditional_loss_mode(frozen_clf_noisy, 'classification')
        original_compute_loss_noise = frozen_clf_noisy._compute_loss
        frozen_clf_noisy._compute_loss = lambda predictions, targets: frozen_clf_noisy._traditional_loss(predictions, targets)
        
        frozen_clf_noisy.fit(X_train, y_train_noisy)
        frozen_acc_noisy = accuracy_score(y_test, frozen_clf_noisy.predict(X_test))
        
        # æ¢å¤åŸæŸå¤±å‡½æ•°
        frozen_clf_noisy._compute_loss = original_compute_loss_noise
    else:
        frozen_acc_noisy = 0
    
    print(f"  ä¼ ç»ŸMLP (CrossEntropy): {trad_acc_noisy:.4f}")
    print(f"  å› æœå®Œæ•´ (OvR-BCE): {causal_acc_noisy:.4f}")
    if freeze_success_noise:
        print(f"  å› æœå†»ç»“ (CrossEntropy): {frozen_acc_noisy:.4f}")
        print(f"  å®Œæ•´å› æœä¼˜åŠ¿: +{(causal_acc_noisy - trad_acc_noisy)*100:.1f}%")
        print(f"  å†»ç»“å› æœä¼˜åŠ¿: +{(frozen_acc_noisy - trad_acc_noisy)*100:.1f}%")
    else:
        print(f"  å› æœä¼˜åŠ¿: +{(causal_acc_noisy - trad_acc_noisy)*100:.1f}%")
    
    results['classification'] = {
        'traditional_noisy': trad_acc_noisy,
        'causal_noisy': causal_acc_noisy,
        'frozen_noisy': frozen_acc_noisy if freeze_success_noise else 0,
        'robustness_advantage': causal_acc_noisy - trad_acc_noisy,
        'frozen_advantage': frozen_acc_noisy - trad_acc_noisy if freeze_success_noise else 0,
        'freeze_success': freeze_success_noise
    }
    
    # æ€»ç»“å™ªå£°é²æ£’æ€§
    print(f"\\nğŸ“Š å™ªå£°é²æ£’æ€§æ€»ç»“:")
    print(f"å›å½’ä»»åŠ¡: å®Œæ•´å› æœä¼˜åŠ¿ +{results['regression']['robustness_advantage']*100:.1f}%, å†»ç»“å› æœä¼˜åŠ¿ +{results['regression']['frozen_advantage']*100:.1f}%")
    print(f"åˆ†ç±»ä»»åŠ¡: å®Œæ•´å› æœä¼˜åŠ¿ +{results['classification']['robustness_advantage']*100:.1f}%, å†»ç»“å› æœä¼˜åŠ¿ +{results['classification']['frozen_advantage']*100:.1f}%")
    
    return results


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ CausalEngine Sklearnæ¥å£æ¼”ç¤º")
    print("="*60)
    
    results = {}
    
    try:
        # å›å½’æ¼”ç¤º
        results['regression'] = demo_regression()
        
        # åˆ†ç±»æ¼”ç¤º  
        results['classification'] = demo_classification()
        
        # å™ªå£°é²æ£’æ€§æ¼”ç¤º
        results['noise_robustness'] = demo_noise_robustness()
        
        # æ€»ç»“
        print("\\n" + "="*60)
        print("ğŸ“Š æ¼”ç¤ºæ€»ç»“")
        print("="*60)
        
        print(f"ğŸ”§ å›å½’ä»»åŠ¡:")
        print(f"  ä¼ ç»ŸMLP (MSE): {results['regression']['traditional_r2']:.4f}")
        print(f"  å› æœå®Œæ•´ (Cauchy): {results['regression']['causal_r2']:.4f}")
        if results['regression']['freeze_success']:
            print(f"  å› æœå†»ç»“ (MSE): {results['regression']['frozen_r2']:.4f}")
            print(f"  å®Œæ•´ vs ä¼ ç»Ÿ: {results['regression']['improvement']:+.4f}")
            print(f"  å†»ç»“ vs ä¼ ç»Ÿ: {results['regression']['frozen_improvement']:+.4f} (æ•°å­¦ç­‰ä»·æ€§)")
        else:
            print(f"  æ”¹è¿›: {results['regression']['improvement']:+.4f}")
        
        print(f"\\nğŸ¯ åˆ†ç±»ä»»åŠ¡:")
        print(f"  ä¼ ç»ŸMLP (CrossEntropy): {results['classification']['traditional_acc']:.4f}")
        print(f"  å› æœå®Œæ•´ (OvR-BCE): {results['classification']['causal_acc']:.4f}")
        if results['classification']['freeze_success']:
            print(f"  å› æœå†»ç»“ (CrossEntropy): {results['classification']['frozen_acc']:.4f}")
            print(f"  å®Œæ•´ vs ä¼ ç»Ÿ: {results['classification']['improvement']:+.4f}")
            print(f"  å†»ç»“ vs ä¼ ç»Ÿ: {results['classification']['frozen_improvement']:+.4f} (æ•°å­¦ç­‰ä»·æ€§)")
        else:
            print(f"  æ”¹è¿›: {results['classification']['improvement']:+.4f}")
        
        print(f"\\nğŸ›¡ï¸ å™ªå£°é²æ£’æ€§:")
        print(f"  å›å½’ä»»åŠ¡:")
        print(f"    ä¼ ç»ŸMLP (MSE): {results['noise_robustness']['regression']['traditional_noisy']:.4f}")
        print(f"    å› æœå®Œæ•´ (Cauchy): {results['noise_robustness']['regression']['causal_noisy']:.4f}")
        if results['noise_robustness']['regression']['freeze_success']:
            print(f"    å› æœå†»ç»“ (MSE): {results['noise_robustness']['regression']['frozen_noisy']:.4f}")
            print(f"    å®Œæ•´å› æœä¼˜åŠ¿: +{results['noise_robustness']['regression']['robustness_advantage']*100:.1f}%")
            print(f"    å†»ç»“å› æœä¼˜åŠ¿: +{results['noise_robustness']['regression']['frozen_advantage']*100:.1f}%")
        else:
            print(f"    å› æœä¼˜åŠ¿: +{results['noise_robustness']['regression']['robustness_advantage']*100:.1f}%")
        
        print(f"  åˆ†ç±»ä»»åŠ¡:")
        print(f"    ä¼ ç»ŸMLP (CrossEntropy): {results['noise_robustness']['classification']['traditional_noisy']:.4f}")
        print(f"    å› æœå®Œæ•´ (OvR-BCE): {results['noise_robustness']['classification']['causal_noisy']:.4f}")
        if results['noise_robustness']['classification']['freeze_success']:
            print(f"    å› æœå†»ç»“ (CrossEntropy): {results['noise_robustness']['classification']['frozen_noisy']:.4f}")
            print(f"    å®Œæ•´å› æœä¼˜åŠ¿: +{results['noise_robustness']['classification']['robustness_advantage']*100:.1f}%")
            print(f"    å†»ç»“å› æœä¼˜åŠ¿: +{results['noise_robustness']['classification']['frozen_advantage']*100:.1f}%")
        else:
            print(f"    å› æœä¼˜åŠ¿: +{results['noise_robustness']['classification']['robustness_advantage']*100:.1f}%")
        
        print("\\nâœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼CausalEngine sklearnæ¥å£æ­£å¸¸å·¥ä½œã€‚")
        
    except Exception as e:
        print(f"\\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)