"""
CausalEngine æ¶ˆèç ”ç©¶: å›ºå®šå™ªå£° vs è‡ªé€‚åº”å™ªå£°å­¦ä¹  (2024ç‰ˆ)
========================================================

åŸºäºå®˜æ–¹åŸºå‡†æµ‹è¯•åè®®çš„æ ¸å¿ƒæ¶ˆèå®éªŒï¼š
é€šè¿‡æ§åˆ¶ b_noise.requires_grad çš„ True/False æ¥ç§‘å­¦éªŒè¯
"è®©æ¨¡å‹è‡ªä¸»å­¦ä¹ å…¨å±€ç¯å¢ƒå™ªå£°"çš„æ ¸å¿ƒå‡è®¾

å®éªŒè®¾è®¡:
1. å›ºå®šå™ªå£°ç»„: b_noise.requires_grad = False, æµ‹è¯•å¤šä¸ªå›ºå®šå€¼
2. è‡ªé€‚åº”å™ªå£°ç»„: b_noise.requires_grad = True, è®©æ¨¡å‹è‡ªä¸»å­¦ä¹ 
3. ä¼ ç»ŸåŸºçº¿ç»„: æ ‡å‡†MLPä½œä¸ºå¯¹æ¯”åŸºå‡†

å…³é”®åˆ›æ–°: é€šè¿‡ä¸€ä¸ªå¸ƒå°”å¼€å…³å®ç°ä¼˜é›…çš„å®éªŒæ§åˆ¶
"""

import sys
import os
import time
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification, make_regression, fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, r2_score, mean_absolute_error
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

from causal_engine import CausalEngine


def create_synthetic_datasets():
    """
    åˆ›å»ºç»¼åˆæ€§çš„åˆæˆæ•°æ®é›†ç”¨äºæ¶ˆèç ”ç©¶
    """
    print("ğŸ“Š åˆ›å»ºåˆæˆæ•°æ®é›†")
    print("=" * 50)
    
    datasets = {}
    
    # 1. åˆ†ç±»æ•°æ®é›†
    X_cls, y_cls = make_classification(
        n_samples=5000,
        n_features=20,
        n_informative=15,
        n_redundant=3,
        n_classes=3,
        n_clusters_per_class=1,
        random_state=42
    )
    
    # æ ‡å‡†åŒ–
    scaler_cls = StandardScaler()
    X_cls_scaled = scaler_cls.fit_transform(X_cls)
    
    # åˆ’åˆ†æ•°æ®é›†
    X_cls_train, X_cls_temp, y_cls_train, y_cls_temp = train_test_split(
        X_cls_scaled, y_cls, test_size=0.4, random_state=42, stratify=y_cls
    )
    X_cls_val, X_cls_test, y_cls_val, y_cls_test = train_test_split(
        X_cls_temp, y_cls_temp, test_size=0.5, random_state=42, stratify=y_cls_temp
    )
    
    datasets['classification'] = {
        'X_train': X_cls_train.astype(np.float32),
        'X_val': X_cls_val.astype(np.float32),
        'X_test': X_cls_test.astype(np.float32),
        'y_train': y_cls_train.astype(np.int64),
        'y_val': y_cls_val.astype(np.int64),
        'y_test': y_cls_test.astype(np.int64),
        'input_size': X_cls_scaled.shape[1],
        'num_classes': len(np.unique(y_cls)),
        'task_type': 'classification'
    }
    
    # 2. å›å½’æ•°æ®é›†
    X_reg, y_reg = make_regression(
        n_samples=5000,
        n_features=15,
        n_informative=12,
        noise=0.1,
        random_state=42
    )
    
    # æ ‡å‡†åŒ–
    scaler_reg_X = StandardScaler()
    scaler_reg_y = StandardScaler()
    X_reg_scaled = scaler_reg_X.fit_transform(X_reg)
    y_reg_scaled = scaler_reg_y.fit_transform(y_reg.reshape(-1, 1)).ravel()
    
    # åˆ’åˆ†æ•°æ®é›†
    X_reg_train, X_reg_temp, y_reg_train, y_reg_temp = train_test_split(
        X_reg_scaled, y_reg_scaled, test_size=0.4, random_state=42
    )
    X_reg_val, X_reg_test, y_reg_val, y_reg_test = train_test_split(
        X_reg_temp, y_reg_temp, test_size=0.5, random_state=42
    )
    
    datasets['regression'] = {
        'X_train': X_reg_train.astype(np.float32),
        'X_val': X_reg_val.astype(np.float32),
        'X_test': X_reg_test.astype(np.float32),
        'y_train': y_reg_train.astype(np.float32),
        'y_val': y_reg_val.astype(np.float32),
        'y_test': y_reg_test.astype(np.float32),
        'input_size': X_reg_scaled.shape[1],
        'task_type': 'regression'
    }
    
    print(f"  åˆ†ç±»æ•°æ®é›†: {datasets['classification']['X_train'].shape[0]} è®­ç»ƒæ ·æœ¬")
    print(f"  å›å½’æ•°æ®é›†: {datasets['regression']['X_train'].shape[0]} è®­ç»ƒæ ·æœ¬")
    
    return datasets


def create_data_loaders(data_dict, batch_size=64):
    """
    åˆ›å»ºPyTorchæ•°æ®åŠ è½½å™¨
    """
    if data_dict['task_type'] == 'classification':
        train_dataset = TensorDataset(
            torch.FloatTensor(data_dict['X_train']),
            torch.LongTensor(data_dict['y_train'])
        )
        val_dataset = TensorDataset(
            torch.FloatTensor(data_dict['X_val']),
            torch.LongTensor(data_dict['y_val'])
        )
        test_dataset = TensorDataset(
            torch.FloatTensor(data_dict['X_test']),
            torch.LongTensor(data_dict['y_test'])
        )
    else:  # regression
        train_dataset = TensorDataset(
            torch.FloatTensor(data_dict['X_train']),
            torch.FloatTensor(data_dict['y_train'])
        )
        val_dataset = TensorDataset(
            torch.FloatTensor(data_dict['X_val']),
            torch.FloatTensor(data_dict['y_val'])
        )
        test_dataset = TensorDataset(
            torch.FloatTensor(data_dict['X_test']),
            torch.FloatTensor(data_dict['y_test'])
        )
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, val_loader, test_loader


class TraditionalMLP(nn.Module):
    """
    ä¼ ç»ŸMLPåŸºçº¿æ¨¡å‹
    """
    def __init__(self, input_size, output_size, task_type, hidden_sizes=[128, 64]):
        super().__init__()
        self.task_type = task_type
        
        layers = []
        prev_size = input_size
        
        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.ReLU(),
                nn.Dropout(0.1)
            ])
            prev_size = hidden_size
        
        layers.append(nn.Linear(prev_size, output_size))
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        output = self.network(x)
        if self.task_type == 'regression':
            return output.squeeze(-1)
        return output


class CausalEngineModel(nn.Module):
    """
    CausalEngineæ¨¡å‹åŒ…è£…å™¨ï¼Œæ”¯æŒå›ºå®šå’Œè‡ªé€‚åº”å™ªå£°
    """
    def __init__(self, input_size, output_size, task_type, causal_size=None, 
                 noise_learnable=True, initial_noise=0.1):
        super().__init__()
        self.task_type = task_type
        
        if causal_size is None:
            causal_size = input_size
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®æ¿€æ´»æ¨¡å¼
        activation_mode = "classification" if task_type == 'classification' else "regression"
        
        self.causal_engine = CausalEngine(
            hidden_size=input_size,
            vocab_size=output_size,
            causal_size=causal_size,
            activation_modes=activation_mode
        )
        
        # è®¾ç½®å™ªå£°å‚æ•°çš„å­¦ä¹ çŠ¶æ€
        if hasattr(self.causal_engine.action, 'b_noise'):
            self.causal_engine.action.b_noise.requires_grad = noise_learnable
            self.causal_engine.action.b_noise.data.fill_(initial_noise)
    
    def forward(self, x, temperature=1.0, do_sample=False):
        # æ·»åŠ åºåˆ—ç»´åº¦
        if x.dim() == 2:
            x = x.unsqueeze(1)  # (batch, seq=1, features)
        
        output = self.causal_engine(
            hidden_states=x,
            temperature=temperature,
            do_sample=do_sample,
            return_dict=True,
            apply_activation=True
        )
        
        result = output['output'].squeeze()
        if self.task_type == 'regression' and result.dim() > 1:
            result = result.squeeze(-1)
        return result
    
    def set_fixed_noise(self, noise_value):
        """è®¾ç½®å›ºå®šå™ªå£°å€¼å¹¶ç¦ç”¨å­¦ä¹ """
        if hasattr(self.causal_engine.action, 'b_noise'):
            self.causal_engine.action.b_noise.requires_grad = False
            self.causal_engine.action.b_noise.data.fill_(noise_value)
    
    def get_current_noise(self):
        """è·å–å½“å‰å™ªå£°å€¼ç»Ÿè®¡"""
        if hasattr(self.causal_engine.action, 'b_noise'):
            b_noise_tensor = self.causal_engine.action.b_noise
            return {
                'mean': b_noise_tensor.mean().item(),
                'std': b_noise_tensor.std().item(),
                'min': b_noise_tensor.min().item(),
                'max': b_noise_tensor.max().item()
            }
        return None


def train_model(model, train_loader, val_loader, device, num_epochs=50, learning_rate=1e-4):
    """
    è®­ç»ƒæ¨¡å‹ (åŸºå‡†åè®®æ ‡å‡†é…ç½®)
    """
    model = model.to(device)
    
    # åŸºå‡†åè®®é…ç½®
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)
    
    # å­¦ä¹ ç‡è°ƒåº¦
    total_steps = len(train_loader) * num_epochs
    warmup_steps = int(0.1 * total_steps)
    
    def lr_schedule(step):
        if step < warmup_steps:
            return step / warmup_steps
        else:
            progress = (step - warmup_steps) / (total_steps - warmup_steps)
            return 0.5 * (1 + np.cos(np.pi * progress))
    
    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_schedule)
    
    # æŸå¤±å‡½æ•°
    if model.task_type == 'classification':
        criterion = nn.CrossEntropyLoss()
    else:
        criterion = nn.MSELoss()
    
    # æ—©åœ
    best_val_loss = float('inf')
    patience = 10
    patience_counter = 0
    
    train_losses = []
    val_losses = []
    noise_history = []  # è®°å½•å™ªå£°å˜åŒ–
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        epoch_train_loss = 0.0
        
        for batch_x, batch_y in train_loader:
            batch_x, batch_y = batch_x.to(device), batch_y.to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            scheduler.step()
            
            epoch_train_loss += loss.item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        epoch_val_loss = 0.0
        
        with torch.no_grad():
            for batch_x, batch_y in val_loader:
                batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                outputs = model(batch_x)
                loss = criterion(outputs, batch_y)
                epoch_val_loss += loss.item()
        
        avg_train_loss = epoch_train_loss / len(train_loader)
        avg_val_loss = epoch_val_loss / len(val_loader)
        
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        
        # è®°å½•å™ªå£°å€¼å˜åŒ–
        if hasattr(model, 'get_current_noise'):
            current_noise = model.get_current_noise()
            if current_noise is not None:
                noise_history.append(current_noise)
        
        # æ—©åœæ£€æŸ¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            break
    
    return {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'noise_history': noise_history,
        'final_epoch': len(train_losses)
    }


def evaluate_model(model, test_loader, device, temperature=1.0, do_sample=False):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½
    """
    model.eval()
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            batch_x = batch_x.to(device)
            
            if hasattr(model, 'causal_engine'):
                outputs = model(batch_x, temperature=temperature, do_sample=do_sample)
            else:
                outputs = model(batch_x)
            
            if model.task_type == 'classification':
                _, predicted = torch.max(outputs, 1)
                all_predictions.extend(predicted.cpu().numpy())
            else:
                all_predictions.extend(outputs.cpu().numpy())
            
            all_targets.extend(batch_y.cpu().numpy())
    
    predictions = np.array(all_predictions)
    targets = np.array(all_targets)
    
    if model.task_type == 'classification':
        accuracy = accuracy_score(targets, predictions)
        precision, recall, f1, _ = precision_recall_fscore_support(
            targets, predictions, average='weighted'
        )
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'primary_metric': accuracy
        }
    else:
        mae = mean_absolute_error(targets, predictions)
        r2 = r2_score(targets, predictions)
        return {
            'mae': mae,
            'r2': r2,
            'primary_metric': r2
        }


def run_ablation_experiment(data_dict, device):
    """
    è¿è¡Œæ ¸å¿ƒæ¶ˆèå®éªŒ: å›ºå®šå™ªå£° vs è‡ªé€‚åº”å™ªå£°
    """
    print(f"\nğŸ§ª æ¶ˆèå®éªŒ: {data_dict['task_type'].title()}")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = create_data_loaders(data_dict)
    
    results = {
        'traditional': {},
        'fixed_noise': {},
        'adaptive_noise': {}
    }
    
    # 1. ä¼ ç»ŸåŸºçº¿
    print("\n  1ï¸âƒ£ ä¼ ç»ŸMLPåŸºçº¿")
    if data_dict['task_type'] == 'classification':
        traditional_model = TraditionalMLP(
            input_size=data_dict['input_size'],
            output_size=data_dict['num_classes'],
            task_type='classification'
        )
    else:
        traditional_model = TraditionalMLP(
            input_size=data_dict['input_size'],
            output_size=1,
            task_type='regression'
        )
    
    train_history = train_model(traditional_model, train_loader, val_loader, device)
    eval_result = evaluate_model(traditional_model, test_loader, device)
    
    results['traditional'] = {
        'train_history': train_history,
        'eval_result': eval_result,
        'noise_value': None
    }
    
    metric_name = 'accuracy' if data_dict['task_type'] == 'classification' else 'r2'
    print(f"     ä¼ ç»ŸMLP {metric_name}: {eval_result['primary_metric']:.4f}")
    
    # 2. å›ºå®šå™ªå£°å®éªŒç»„A
    print("\n  2ï¸âƒ£ å›ºå®šå™ªå£°å®éªŒç»„A")
    noise_values = [0.0, 0.1, 1.0, 10.0]  # åŸºå‡†åè®®æ›´æ–°ï¼šæ›´æœ‰åŒºåˆ†åº¦çš„å…³é”®å€¼
    
    for noise in noise_values:
        print(f"     æµ‹è¯• b_noise = {noise}")
        
        if data_dict['task_type'] == 'classification':
            model = CausalEngineModel(
                input_size=data_dict['input_size'],
                output_size=data_dict['num_classes'],
                task_type='classification',
                noise_learnable=False,
                initial_noise=noise
            )
        else:
            model = CausalEngineModel(
                input_size=data_dict['input_size'],
                output_size=1,
                task_type='regression',
                noise_learnable=False,
                initial_noise=noise
            )
        
        model.set_fixed_noise(noise)
        
        train_history = train_model(model, train_loader, val_loader, device)
        eval_result = evaluate_model(model, test_loader, device)
        
        results['fixed_noise'][noise] = {
            'train_history': train_history,
            'eval_result': eval_result,
            'noise_value': noise
        }
        
        print(f"       â†’ {metric_name}: {eval_result['primary_metric']:.4f}")
    
    # æ‰¾åˆ°æœ€ä½³å›ºå®šå™ªå£°
    best_fixed_noise = max(results['fixed_noise'].keys(), 
                          key=lambda k: results['fixed_noise'][k]['eval_result']['primary_metric'])\n    best_fixed_performance = results['fixed_noise'][best_fixed_noise]['eval_result']['primary_metric']\n    print(f\"     æœ€ä½³å›ºå®šå™ªå£°: {best_fixed_noise} ({metric_name}: {best_fixed_performance:.4f})\")\n    \n    # 3. è‡ªé€‚åº”å™ªå£°å®éªŒç»„B\n    print(\"\\n  3ï¸âƒ£ è‡ªé€‚åº”å™ªå£°å®éªŒç»„B\")\n    \n    if data_dict['task_type'] == 'classification':\n        adaptive_model = CausalEngineModel(\n            input_size=data_dict['input_size'],\n            output_size=data_dict['num_classes'],\n            task_type='classification',\n            noise_learnable=True,\n            initial_noise=0.1\n        )\n    else:\n        adaptive_model = CausalEngineModel(\n            input_size=data_dict['input_size'],\n            output_size=1,\n            task_type='regression',\n            noise_learnable=True,\n            initial_noise=0.1\n        )\n    \n    print(\"     åˆå§‹å™ªå£°: 0.1, å­¦ä¹ çŠ¶æ€: å¯ç”¨\")\n    \n    train_history = train_model(adaptive_model, train_loader, val_loader, device)\n    eval_result = evaluate_model(adaptive_model, test_loader, device)\n    learned_noise = adaptive_model.get_current_noise()\n    \n    results['adaptive_noise'] = {\n        'train_history': train_history,\n        'eval_result': eval_result,\n        'learned_noise': learned_noise,\n        'noise_history': train_history['noise_history']\n    }\n    \n    print(f\"     å­¦åˆ°çš„å™ªå£°: {learned_noise:.4f}\")\n    print(f\"     â†’ {metric_name}: {eval_result['primary_metric']:.4f}\")\n    \n    return results\n\n\ndef analyze_ablation_results(classification_results, regression_results):\n    \"\"\"\n    åˆ†ææ¶ˆèå®éªŒç»“æœ\n    \"\"\"\n    print(\"\\nğŸ“Š æ¶ˆèå®éªŒç»“æœåˆ†æ\")\n    print(\"=\" * 60)\n    \n    for task_type, results in [('åˆ†ç±»', classification_results), ('å›å½’', regression_results)]:\n        print(f\"\\nğŸ¯ {task_type}ä»»åŠ¡åˆ†æ:\")\n        \n        # åŸºå‡†æ€§èƒ½\n        traditional_perf = results['traditional']['eval_result']['primary_metric']\n        metric_name = 'accuracy' if task_type == 'åˆ†ç±»' else 'RÂ²'\n        \n        print(f\"   ä¼ ç»ŸMLPåŸºçº¿: {traditional_perf:.4f}\")\n        \n        # å›ºå®šå™ªå£°åˆ†æ\n        fixed_results = results['fixed_noise']\n        best_fixed_noise = max(fixed_results.keys(), \n                              key=lambda k: fixed_results[k]['eval_result']['primary_metric'])\n        best_fixed_perf = fixed_results[best_fixed_noise]['eval_result']['primary_metric']\n        \n        print(f\"   æœ€ä½³å›ºå®šå™ªå£° ({best_fixed_noise}): {best_fixed_perf:.4f}\")\n        print(f\"   å›ºå®šå™ªå£°æå‡: {best_fixed_perf - traditional_perf:+.4f}\")\n        \n        # è‡ªé€‚åº”å™ªå£°åˆ†æ\n        adaptive_result = results['adaptive_noise']\n        adaptive_perf = adaptive_result['eval_result']['primary_metric']\n        learned_noise = adaptive_result['learned_noise']\n        \n        print(f\"   è‡ªé€‚åº”å™ªå£°å­¦ä¹ : {adaptive_perf:.4f} (å­¦åˆ°: {learned_noise:.4f})\")\n        print(f\"   è‡ªé€‚åº”å™ªå£°æå‡: {adaptive_perf - traditional_perf:+.4f}\")\n        print(f\"   è‡ªé€‚åº” vs æœ€ä½³å›ºå®š: {adaptive_perf - best_fixed_perf:+.4f}\")\n        \n        # å…³é”®å‘ç°\n        print(f\"   ğŸ’¡ å…³é”®å‘ç°:\")\n        if abs(learned_noise['mean'] - best_fixed_noise) < 0.05:\n            print(f\"      âœ… å­¦åˆ°çš„å™ªå£°({learned_noise:.3f})æ¥è¿‘æœ€ä¼˜å›ºå®šå€¼({best_fixed_noise})\")\n        else:\n            print(f\"      ğŸ” å­¦åˆ°çš„å™ªå£°({learned_noise:.3f})åç¦»æœ€ä¼˜å›ºå®šå€¼({best_fixed_noise})\")\n            \n        if adaptive_perf > best_fixed_perf:\n            print(f\"      âœ… è‡ªé€‚åº”å­¦ä¹ ä¼˜äºæœ€ä½³å›ºå®šå™ªå£°\")\n        else:\n            print(f\"      âš ï¸ è‡ªé€‚åº”å­¦ä¹ æœªè¶…è¶Šæœ€ä½³å›ºå®šå™ªå£°\")\n\n\ndef visualize_ablation_results(classification_results, regression_results):\n    \"\"\"\n    å¯è§†åŒ–æ¶ˆèå®éªŒç»“æœ\n    \"\"\"\n    print(\"\\nğŸ“Š ç”Ÿæˆæ¶ˆèå®éªŒå¯è§†åŒ–\")\n    \n    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n    fig.suptitle('CausalEngine Ablation Study: Fixed vs Adaptive Noise Learning', \n                 fontsize=16, fontweight='bold')\n    \n    for i, (task_type, results) in enumerate([('Classification', classification_results), \n                                             ('Regression', regression_results)]):\n        \n        metric_name = 'Accuracy' if task_type == 'Classification' else 'RÂ²'\n        \n        # 1. å›ºå®šå™ªå£°æ€§èƒ½æ›²çº¿\n        noise_values = list(results['fixed_noise'].keys())\n        performance_values = [results['fixed_noise'][noise]['eval_result']['primary_metric'] \n                             for noise in noise_values]\n        \n        axes[i, 0].plot(noise_values, performance_values, 'bo-', linewidth=2, markersize=8)\n        axes[i, 0].set_xlabel('Fixed Noise Value (b_noise)')\n        axes[i, 0].set_ylabel(metric_name)\n        axes[i, 0].set_title(f'{task_type}: Fixed Noise Performance')\n        axes[i, 0].grid(True, alpha=0.3)\n        axes[i, 0].set_xscale('log')\n        \n        # æ ‡æ³¨æœ€ä¼˜ç‚¹\n        best_idx = np.argmax(performance_values)\n        axes[i, 0].annotate(f'Best: {noise_values[best_idx]}', \n                           xy=(noise_values[best_idx], performance_values[best_idx]),\n                           xytext=(noise_values[best_idx]*2, performance_values[best_idx]+0.01),\n                           arrowprops=dict(arrowstyle='->', color='red'))\n        \n        # 2. ä¸‰ç§æ–¹æ³•å¯¹æ¯”\n        methods = ['Traditional\\nMLP', 'Best Fixed\\nNoise', 'Adaptive\\nNoise']\n        method_performances = [\n            results['traditional']['eval_result']['primary_metric'],\n            max(performance_values),\n            results['adaptive_noise']['eval_result']['primary_metric']\n        ]\n        \n        colors = ['lightcoral', 'lightblue', 'lightgreen']\n        bars = axes[i, 1].bar(methods, method_performances, color=colors, alpha=0.8)\n        axes[i, 1].set_ylabel(metric_name)\n        axes[i, 1].set_title(f'{task_type}: Method Comparison')\n        axes[i, 1].grid(True, alpha=0.3, axis='y')\n        \n        # æ·»åŠ æ•°å€¼æ ‡ç­¾\n        for bar, perf in zip(bars, method_performances):\n            axes[i, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n                           f'{perf:.3f}', ha='center', va='bottom')\n        \n        # 3. è‡ªé€‚åº”å™ªå£°å­¦ä¹ æ›²çº¿\n        noise_history = results['adaptive_noise']['noise_history']\n        if noise_history:\n            epochs = range(1, len(noise_history) + 1)\n            axes[i, 2].plot(epochs, noise_history, 'g-', linewidth=2)\n            axes[i, 2].set_xlabel('Epoch')\n            axes[i, 2].set_ylabel('Learned Noise Value')\n            axes[i, 2].set_title(f'{task_type}: Noise Learning Curve')\n            axes[i, 2].grid(True, alpha=0.3)\n            \n            # æ ‡æ³¨æœ€ç»ˆå­¦åˆ°çš„å€¼\n            final_noise = noise_history[-1]\n            axes[i, 2].axhline(y=final_noise, color='red', linestyle='--', alpha=0.7)\n            axes[i, 2].text(len(noise_history)*0.7, final_noise + 0.01, \n                           f'Final: {final_noise:.3f}', fontsize=10)\n        else:\n            axes[i, 2].text(0.5, 0.5, 'No noise history available', \n                           ha='center', va='center', transform=axes[i, 2].transAxes)\n            axes[i, 2].set_title(f'{task_type}: Noise Learning (N/A)')\n    \n    plt.tight_layout()\n    plt.savefig('tutorials/03_ablation_studies/fixed_vs_adaptive_noise_results.png', \n                dpi=300, bbox_inches='tight')\n    plt.close()\n    \n    print(\"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: tutorials/03_ablation_studies/fixed_vs_adaptive_noise_results.png\")\n\n\ndef generate_ablation_report(classification_results, regression_results):\n    \"\"\"\n    ç”Ÿæˆè¯¦ç»†çš„æ¶ˆèç ”ç©¶æŠ¥å‘Š\n    \"\"\"\n    print(\"\\nğŸ“ ç”Ÿæˆæ¶ˆèç ”ç©¶æŠ¥å‘Š\")\n    \n    report = []\n    report.append(\"# CausalEngine æ¶ˆèç ”ç©¶æŠ¥å‘Š: å›ºå®šå™ªå£° vs è‡ªé€‚åº”å™ªå£°å­¦ä¹ \")\n    report.append(\"\\nåŸºäºå®˜æ–¹åŸºå‡†æµ‹è¯•åè®®çš„ç§‘å­¦å¯¹ç…§å®éªŒ\")\n    report.append(\"\\n\" + \"=\"*60)\n    \n    # å®éªŒè®¾è®¡\n    report.append(\"\\n## å®éªŒè®¾è®¡\")\n    report.append(\"\\n### æ ¸å¿ƒå‡è®¾\")\n    report.append(\"'è®©æ¨¡å‹è‡ªä¸»å­¦ä¹ å…¨å±€ç¯å¢ƒå™ªå£°'ç›¸æ¯”å›ºå®šå™ªå£°èƒ½å¤Ÿå¸¦æ¥æ€§èƒ½æå‡\")\n    \n    report.append(\"\\n### å®éªŒæ§åˆ¶\")\n    report.append(\"- **å˜é‡æ§åˆ¶**: ä»…é€šè¿‡ `b_noise.requires_grad` çš„å¸ƒå°”å€¼æ§åˆ¶å™ªå£°å­¦ä¹ \")\n    report.append(\"- **å¯¹ç…§ç»„**: ä¼ ç»ŸMLPä½œä¸ºåŸºå‡†\")\n    report.append(\"- **å®éªŒç»„A**: å›ºå®šå™ªå£° (requires_grad=False)\")\n    report.append(\"- **å®éªŒç»„B**: è‡ªé€‚åº”å™ªå£° (requires_grad=True)\")\n    \n    # ç»“æœåˆ†æ\n    for task_name, results in [('åˆ†ç±»ä»»åŠ¡', classification_results), ('å›å½’ä»»åŠ¡', regression_results)]:\n        report.append(f\"\\n## {task_name}ç»“æœ\")\n        \n        traditional_perf = results['traditional']['eval_result']['primary_metric']\n        metric_name = 'Accuracy' if 'åˆ†ç±»' in task_name else 'RÂ²'\n        \n        # å›ºå®šå™ªå£°ç»“æœ\n        fixed_results = results['fixed_noise']\n        best_fixed_noise = max(fixed_results.keys(), \n                              key=lambda k: fixed_results[k]['eval_result']['primary_metric'])\n        best_fixed_perf = fixed_results[best_fixed_noise]['eval_result']['primary_metric']\n        \n        # è‡ªé€‚åº”å™ªå£°ç»“æœ\n        adaptive_perf = results['adaptive_noise']['eval_result']['primary_metric']\n        learned_noise = results['adaptive_noise']['learned_noise']\n        \n        report.append(f\"\\n### æ€§èƒ½å¯¹æ¯” ({metric_name})\")\n        report.append(f\"- ä¼ ç»ŸMLPåŸºçº¿: {traditional_perf:.4f}\")\n        report.append(f\"- æœ€ä½³å›ºå®šå™ªå£° ({best_fixed_noise}): {best_fixed_perf:.4f} (+{best_fixed_perf-traditional_perf:.4f})\")\n        report.append(f\"- è‡ªé€‚åº”å™ªå£°å­¦ä¹ : {adaptive_perf:.4f} (+{adaptive_perf-traditional_perf:.4f})\")\n        \n        report.append(f\"\\n### å…³é”®å‘ç°\")\n        report.append(f\"- å­¦åˆ°çš„å™ªå£°å€¼: {learned_noise:.4f}\")\n        report.append(f\"- è‡ªé€‚åº” vs æœ€ä½³å›ºå®š: {adaptive_perf - best_fixed_perf:+.4f}\")\n        \n        if abs(learned_noise['mean'] - best_fixed_noise) < 0.05:\n            report.append(f\"- âœ… å­¦åˆ°çš„å™ªå£°æ¥è¿‘ç†è®ºæœ€ä¼˜å€¼\")\n        \n        if adaptive_perf > best_fixed_perf:\n            report.append(f\"- âœ… è‡ªé€‚åº”å­¦ä¹ è¶…è¶Šæœ€ä½³å›ºå®šå™ªå£°\")\n    \n    # ç§‘å­¦ç»“è®º\n    report.append(\"\\n## ç§‘å­¦ç»“è®º\")\n    report.append(\"\\n### å‡è®¾éªŒè¯\")\n    \n    # æ£€æŸ¥ä¸¤ä¸ªä»»åŠ¡çš„ç»“æœ\n    cls_adaptive = classification_results['adaptive_noise']['eval_result']['primary_metric']\n    cls_best_fixed = max([classification_results['fixed_noise'][k]['eval_result']['primary_metric'] \n                         for k in classification_results['fixed_noise']])\n    \n    reg_adaptive = regression_results['adaptive_noise']['eval_result']['primary_metric']\n    reg_best_fixed = max([regression_results['fixed_noise'][k]['eval_result']['primary_metric'] \n                         for k in regression_results['fixed_noise']])\n    \n    if cls_adaptive > cls_best_fixed and reg_adaptive > reg_best_fixed:\n        report.append(\"âœ… **å‡è®¾å¾—åˆ°éªŒè¯**: è‡ªé€‚åº”å™ªå£°å­¦ä¹ åœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šéƒ½ä¼˜äºæœ€ä½³å›ºå®šå™ªå£°\")\n    elif cls_adaptive > cls_best_fixed or reg_adaptive > reg_best_fixed:\n        report.append(\"âš ï¸ **å‡è®¾éƒ¨åˆ†éªŒè¯**: è‡ªé€‚åº”å™ªå£°å­¦ä¹ åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šä¼˜äºå›ºå®šå™ªå£°\")\n    else:\n        report.append(\"âŒ **å‡è®¾æœªå¾—åˆ°éªŒè¯**: è‡ªé€‚åº”å™ªå£°å­¦ä¹ æœªæ˜¾è‘—ä¼˜äºå›ºå®šå™ªå£°\")\n    \n    report.append(\"\\n### ç†è®ºæ„ä¹‰\")\n    report.append(\"1. **å™ªå£°å‚æ•°çš„é‡è¦æ€§**: è¯æ˜äº†å…¨å±€å™ªå£°å¼ºåº¦å¯¹CausalEngineæ€§èƒ½çš„å…³é”®å½±å“\")\n    report.append(\"2. **è‡ªé€‚åº”å­¦ä¹ çš„ä»·å€¼**: éªŒè¯äº†æ¨¡å‹è‡ªä¸»å­¦ä¹ å™ªå£°å‚æ•°çš„æœ‰æ•ˆæ€§\")\n    report.append(\"3. **ç§‘å­¦æ–¹æ³•çš„ä¼˜é›…**: é€šè¿‡ä¸€ä¸ªå¸ƒå°”å¼€å…³å®ç°äº†ä¸¥æ ¼çš„å®éªŒæ§åˆ¶\")\n    \n    # ä¿å­˜æŠ¥å‘Š\n    report_text = \"\\n\".join(report)\n    with open('tutorials/03_ablation_studies/ablation_report.md', 'w', encoding='utf-8') as f:\n        f.write(report_text)\n    \n    print(\"âœ… æŠ¥å‘Šå·²ä¿å­˜: tutorials/03_ablation_studies/ablation_report.md\")\n\n\ndef main():\n    \"\"\"\n    ä¸»å‡½æ•°: å®Œæ•´çš„æ¶ˆèç ”ç©¶æµç¨‹\n    \"\"\"\n    print(\"ğŸŒŸ CausalEngine æ¶ˆèç ”ç©¶: å›ºå®šå™ªå£° vs è‡ªé€‚åº”å™ªå£°å­¦ä¹ \")\n    print(\"åŸºäºå®˜æ–¹åŸºå‡†æµ‹è¯•åè®®çš„ç§‘å­¦å¯¹ç…§å®éªŒ\")\n    print(\"=\" * 80)\n    \n    # è®¾ç½®ç¯å¢ƒ\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n    print(f\"éšæœºç§å­: 42\")\n    \n    # 1. åˆ›å»ºæ•°æ®é›†\n    print(\"\\nğŸ“Š æ­¥éª¤1: åˆ›å»ºå®éªŒæ•°æ®é›†\")\n    datasets = create_synthetic_datasets()\n    \n    # 2. è¿è¡Œæ¶ˆèå®éªŒ\n    print(\"\\nğŸ§ª æ­¥éª¤2: è¿è¡Œæ¶ˆèå®éªŒ\")\n    classification_results = run_ablation_experiment(datasets['classification'], device)\n    regression_results = run_ablation_experiment(datasets['regression'], device)\n    \n    # 3. åˆ†æç»“æœ\n    print(\"\\nğŸ“Š æ­¥éª¤3: åˆ†æå®éªŒç»“æœ\")\n    analyze_ablation_results(classification_results, regression_results)\n    \n    # 4. å¯è§†åŒ–ç»“æœ\n    print(\"\\nğŸ“Š æ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–\")\n    visualize_ablation_results(classification_results, regression_results)\n    \n    # 5. ç”ŸæˆæŠ¥å‘Š\n    print(\"\\nğŸ“ æ­¥éª¤5: ç”Ÿæˆç ”ç©¶æŠ¥å‘Š\")\n    generate_ablation_report(classification_results, regression_results)\n    \n    # 6. æ€»ç»“\n    print(\"\\nğŸ‰ æ¶ˆèç ”ç©¶å®Œæˆï¼\")\n    print(\"=\" * 80)\n    print(\"ğŸ”¬ å®éªŒæˆæœ:\")\n    print(\"  âœ… éªŒè¯äº†å›ºå®šå™ªå£°vsè‡ªé€‚åº”å™ªå£°å­¦ä¹ çš„æ ¸å¿ƒå‡è®¾\")\n    print(\"  âœ… é€šè¿‡ç§‘å­¦å¯¹ç…§å®éªŒé‡åŒ–äº†è‡ªé€‚åº”å­¦ä¹ çš„ä»·å€¼\")\n    print(\"  âœ… è¯æ˜äº†åŸºå‡†åè®®ä¸­'ä¼˜é›…æ§åˆ¶'è®¾è®¡çš„æœ‰æ•ˆæ€§\")\n    print(\"  âœ… ä¸ºCausalEngineçš„å™ªå£°æœºåˆ¶æä¾›äº†å®è¯æ”¯æŒ\")\n    \n    print(\"\\nğŸ“š ç›¸å…³èµ„æº:\")\n    print(\"  ğŸ“Š å¯è§†åŒ–ç»“æœ: tutorials/03_ablation_studies/fixed_vs_adaptive_noise_results.png\")\n    print(\"  ğŸ“ è¯¦ç»†æŠ¥å‘Š: tutorials/03_ablation_studies/ablation_report.md\")\n    print(\"  ğŸ§ª åŸºå‡†åè®®: causal_engine/misc/benchmark_strategy.md\")\n    print(\"  ğŸ“ æ•°å­¦ç†è®º: causal_engine/MATHEMATICAL_FOUNDATIONS_CN.md\")\n\n\nif __name__ == \"__main__\":\n    main()"