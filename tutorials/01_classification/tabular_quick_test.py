#!/usr/bin/env python3
"""
CausalEngine è¡¨æ ¼æ•°æ®å¿«é€Ÿæµ‹è¯•

ä½¿ç”¨å‡ ä¸ªç»å…¸çš„å°å‹æ•°æ®é›†å¿«é€Ÿæµ‹è¯• CausalEngine çš„æ€§èƒ½
æ•°æ®é›†ï¼šIrisã€Wineã€Breast Cancer
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ CausalEngine
import sys
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')
from causal_engine import CausalEngine, ActivationMode


class SimpleDataset(Dataset):
    def __init__(self, features, labels):
        self.features = torch.FloatTensor(features)
        self.labels = torch.LongTensor(labels)
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


class CausalClassifier(nn.Module):
    """CausalEngine åˆ†ç±»å™¨"""
    
    def __init__(self, input_size, num_classes):
        super().__init__()
        
        # ç®€å•çš„ç‰¹å¾ç¼–ç 
        self.encoder = nn.Sequential(
            nn.Linear(input_size, 64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 32)
        )
        
        self.causal_engine = CausalEngine(
            hidden_size=32,
            vocab_size=num_classes,
            activation_modes="classification",
            b_noise_init=0.1,
            gamma_init=1.0
        )
    
    def forward(self, x, temperature=1.0):
        features = self.encoder(x)
        output = self.causal_engine(
            features.unsqueeze(1),
            temperature=temperature,
            do_sample=False,
            return_dict=True
        )
        return output['output'].squeeze(1)


def load_datasets():
    """åŠ è½½å¤šä¸ªç»å…¸æ•°æ®é›†"""
    
    datasets_info = []
    
    # 1. Irisï¼ˆé¸¢å°¾èŠ±ï¼‰- 150æ ·æœ¬ï¼Œ4ç‰¹å¾ï¼Œ3ç±»
    print("\nğŸŒ¸ åŠ è½½ Iris æ•°æ®é›†...")
    iris = datasets.load_iris()
    datasets_info.append({
        'name': 'Iris',
        'X': iris.data,
        'y': iris.target,
        'num_classes': 3,
        'num_features': 4,
        'num_samples': len(iris.data)
    })
    
    # 2. Wineï¼ˆè‘¡è„é…’ï¼‰- 178æ ·æœ¬ï¼Œ13ç‰¹å¾ï¼Œ3ç±»
    print("ğŸ· åŠ è½½ Wine æ•°æ®é›†...")
    wine = datasets.load_wine()
    datasets_info.append({
        'name': 'Wine',
        'X': wine.data,
        'y': wine.target,
        'num_classes': 3,
        'num_features': 13,
        'num_samples': len(wine.data)
    })
    
    # 3. Breast Cancerï¼ˆä¹³è…ºç™Œï¼‰- 569æ ·æœ¬ï¼Œ30ç‰¹å¾ï¼Œ2ç±»
    print("ğŸ¥ åŠ è½½ Breast Cancer æ•°æ®é›†...")
    cancer = datasets.load_breast_cancer()
    datasets_info.append({
        'name': 'Breast Cancer',
        'X': cancer.data,
        'y': cancer.target,
        'num_classes': 2,
        'num_features': 30,
        'num_samples': len(cancer.data)
    })
    
    # 4. Digitsï¼ˆæ‰‹å†™æ•°å­—ç®€åŒ–ç‰ˆï¼‰- 1797æ ·æœ¬ï¼Œ64ç‰¹å¾ï¼Œ10ç±»
    print("ğŸ”¢ åŠ è½½ Digits æ•°æ®é›†...")
    digits = datasets.load_digits()
    # é‡‡æ ·500ä¸ªæ ·æœ¬ä»¥åŠ å¿«é€Ÿåº¦
    indices = np.random.choice(len(digits.data), 500, replace=False)
    datasets_info.append({
        'name': 'Digits (500)',
        'X': digits.data[indices],
        'y': digits.target[indices],
        'num_classes': 10,
        'num_features': 64,
        'num_samples': 500
    })
    
    # 5. ç”Ÿæˆä¸€ä¸ªåˆæˆæ•°æ®é›† - 1000æ ·æœ¬ï¼Œ20ç‰¹å¾ï¼Œ4ç±»
    print("ğŸ² ç”Ÿæˆåˆæˆæ•°æ®é›†...")
    X_synthetic, y_synthetic = datasets.make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=15,
        n_redundant=5,
        n_classes=4,
        n_clusters_per_class=2,
        random_state=42
    )
    datasets_info.append({
        'name': 'Synthetic',
        'X': X_synthetic,
        'y': y_synthetic,
        'num_classes': 4,
        'num_features': 20,
        'num_samples': 1000
    })
    
    return datasets_info


def quick_train_causal(model, train_loader, val_loader, epochs=20):
    """å¿«é€Ÿè®­ç»ƒ CausalEngine"""
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    best_val_acc = 0
    
    for epoch in range(epochs):
        # è®­ç»ƒ
        model.train()
        for features, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        
        # éªŒè¯
        if epoch % 5 == 0:
            model.eval()
            correct = 0
            total = 0
            with torch.no_grad():
                for features, labels in val_loader:
                    outputs = model(features, temperature=0.0)
                    _, predicted = torch.max(outputs, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
            
            val_acc = correct / total
            best_val_acc = max(best_val_acc, val_acc)
    
    return best_val_acc


def evaluate_on_dataset(dataset_info):
    """åœ¨å•ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°"""
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š è¯„ä¼°æ•°æ®é›†: {dataset_info['name']}")
    print(f"   æ ·æœ¬æ•°: {dataset_info['num_samples']}")
    print(f"   ç‰¹å¾æ•°: {dataset_info['num_features']}")
    print(f"   ç±»åˆ«æ•°: {dataset_info['num_classes']}")
    print(f"{'='*50}")
    
    X = dataset_info['X']
    y = dataset_info['y']
    
    # æ•°æ®é¢„å¤„ç†
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # åˆ’åˆ†æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.3, random_state=42, stratify=y
    )
    
    # å¦‚æœè®­ç»ƒé›†å¤ªå°ï¼Œä½¿ç”¨æ›´å¤šæ•°æ®
    if len(X_train) < 100:
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
    
    results = {}
    
    # 1. CausalEngine
    print("\nğŸ”§ è®­ç»ƒ CausalEngine...")
    train_dataset = SimpleDataset(X_train, y_train)
    test_dataset = SimpleDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    causal_model = CausalClassifier(X_train.shape[1], dataset_info['num_classes'])
    val_acc = quick_train_causal(causal_model, train_loader, train_loader, epochs=30)
    
    # æµ‹è¯•
    causal_model.eval()
    predictions = []
    with torch.no_grad():
        for features, _ in test_loader:
            outputs = causal_model(features, temperature=0.0)
            _, predicted = torch.max(outputs, 1)
            predictions.extend(predicted.numpy())
    
    causal_acc = accuracy_score(y_test, predictions)
    results['CausalEngine'] = causal_acc
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {causal_acc:.4f}")
    
    # 2. é€»è¾‘å›å½’
    print("\nğŸ“Š è®­ç»ƒé€»è¾‘å›å½’...")
    lr = LogisticRegression(random_state=42, max_iter=1000)
    lr.fit(X_train, y_train)
    lr_acc = lr.score(X_test, y_test)
    results['Logistic Regression'] = lr_acc
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {lr_acc:.4f}")
    
    # 3. éšæœºæ£®æ—
    print("\nğŸŒ² è®­ç»ƒéšæœºæ£®æ—...")
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)
    rf_acc = rf.score(X_test, y_test)
    results['Random Forest'] = rf_acc
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {rf_acc:.4f}")
    
    # 4. SVM
    print("\nğŸ¯ è®­ç»ƒ SVM...")
    svm = SVC(random_state=42)
    svm.fit(X_train, y_train)
    svm_acc = svm.score(X_test, y_test)
    results['SVM'] = svm_acc
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {svm_acc:.4f}")
    
    return results


def visualize_results(all_results):
    """å¯è§†åŒ–æ‰€æœ‰ç»“æœ"""
    
    print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–...")
    
    plt.rcParams['font.family'] = 'DejaVu Sans'
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.ravel()
    
    # 1. å‡†ç¡®ç‡å¯¹æ¯”æ¡å½¢å›¾
    ax = axes[0]
    datasets = list(all_results.keys())
    methods = ['CausalEngine', 'Logistic Regression', 'Random Forest', 'SVM']
    
    x = np.arange(len(datasets))
    width = 0.2
    
    for i, method in enumerate(methods):
        accuracies = [all_results[d][method] for d in datasets]
        offset = (i - 1.5) * width
        bars = ax.bar(x + offset, accuracies, width, label=method, alpha=0.8)
        
        # çªå‡ºCausalEngine
        if method == 'CausalEngine':
            for bar in bars:
                bar.set_color('red')
    
    ax.set_xlabel('Dataset')
    ax.set_ylabel('Accuracy')
    ax.set_title('Accuracy Comparison Across Datasets')
    ax.set_xticks(x)
    ax.set_xticklabels(datasets, rotation=45)
    ax.legend()
    ax.grid(True, axis='y', alpha=0.3)
    
    # 2. æ–¹æ³•å¹³å‡æ€§èƒ½
    ax = axes[1]
    method_avg = {method: np.mean([all_results[d][method] for d in datasets]) 
                  for method in methods}
    
    bars = ax.bar(methods, method_avg.values(), alpha=0.7)
    bars[0].set_color('red')  # CausalEngine
    
    ax.set_ylabel('Average Accuracy')
    ax.set_title('Average Performance Across All Datasets')
    ax.tick_params(axis='x', rotation=45)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, (method, acc) in zip(bars, method_avg.items()):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{acc:.3f}', ha='center', va='bottom')
    
    # 3. CausalEngineç›¸å¯¹æ€§èƒ½
    ax = axes[2]
    relative_perfs = []
    labels = []
    
    for dataset in datasets:
        causal_acc = all_results[dataset]['CausalEngine']
        best_other = max(all_results[dataset][m] for m in methods[1:])
        relative_perf = (causal_acc - best_other) / best_other * 100
        relative_perfs.append(relative_perf)
        labels.append(dataset)
    
    colors = ['green' if rp > 0 else 'red' for rp in relative_perfs]
    bars = ax.bar(range(len(labels)), relative_perfs, color=colors, alpha=0.7)
    ax.set_xticks(range(len(labels)))
    ax.set_xticklabels(labels, rotation=45)
    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
    ax.set_ylabel('Relative Performance (%)')
    ax.set_title('CausalEngine vs Best Traditional Method')
    
    # 4. æ•°æ®é›†ç‰¹å¾ vs CausalEngineæ€§èƒ½
    ax = axes[3]
    
    # æå–æ•°æ®é›†ç‰¹å¾
    num_samples = []
    num_features = []
    causal_accs = []
    dataset_names = []
    
    for dataset_name in datasets:
        # ä»å…¨å±€å˜é‡ä¸­è·å–æ•°æ®é›†ä¿¡æ¯ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        if 'Iris' in dataset_name:
            num_samples.append(150)
            num_features.append(4)
        elif 'Wine' in dataset_name:
            num_samples.append(178)
            num_features.append(13)
        elif 'Breast' in dataset_name:
            num_samples.append(569)
            num_features.append(30)
        elif 'Digits' in dataset_name:
            num_samples.append(500)
            num_features.append(64)
        elif 'Synthetic' in dataset_name:
            num_samples.append(1000)
            num_features.append(20)
        
        causal_accs.append(all_results[dataset_name]['CausalEngine'])
        dataset_names.append(dataset_name)
    
    # ç”¨ç‰¹å¾æ•°ä½œä¸ºxè½´ï¼Œå‡†ç¡®ç‡ä½œä¸ºyè½´ï¼Œç‚¹å¤§å°è¡¨ç¤ºæ ·æœ¬æ•°
    scatter = ax.scatter(num_features, causal_accs, 
                        s=[n/5 for n in num_samples],  # ç¼©æ”¾ç‚¹å¤§å°
                        alpha=0.6, c=range(len(dataset_names)), cmap='viridis')
    
    # æ·»åŠ æ ‡ç­¾
    for i, name in enumerate(dataset_names):
        ax.annotate(name, (num_features[i], causal_accs[i]), 
                   xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    ax.set_xlabel('Number of Features')
    ax.set_ylabel('CausalEngine Accuracy')
    ax.set_title('Dataset Complexity vs CausalEngine Performance')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('tabular_quick_test_results.png', dpi=150, bbox_inches='tight')
    print("   ç»“æœå·²ä¿å­˜åˆ° tabular_quick_test_results.png")
    plt.close()


def print_summary(all_results):
    """æ‰“å°æ€»ç»“"""
    
    print("\n" + "="*60)
    print("ğŸ“Š å¿«é€Ÿæµ‹è¯•æ€»ç»“")
    print("="*60)
    
    # è®¡ç®—ç»Ÿè®¡
    methods = ['CausalEngine', 'Logistic Regression', 'Random Forest', 'SVM']
    method_wins = {m: 0 for m in methods}
    
    for dataset, results in all_results.items():
        best_method = max(results.items(), key=lambda x: x[1])[0]
        method_wins[best_method] += 1
        
        print(f"\n{dataset}:")
        sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
        for i, (method, acc) in enumerate(sorted_results):
            marker = "ğŸ†" if i == 0 else "  "
            print(f"  {marker} {method:20s}: {acc:.4f}")
    
    print("\nğŸ† è·èƒœç»Ÿè®¡:")
    for method, wins in sorted(method_wins.items(), key=lambda x: x[1], reverse=True):
        print(f"   {method}: {wins} æ¬¡")
    
    # CausalEngine åˆ†æ
    print("\nğŸ” CausalEngine åˆ†æ:")
    causal_ranks = []
    for dataset, results in all_results.items():
        sorted_methods = sorted(results.items(), key=lambda x: x[1], reverse=True)
        rank = next(i for i, (m, _) in enumerate(sorted_methods) if m == 'CausalEngine') + 1
        causal_ranks.append(rank)
    
    print(f"   å¹³å‡æ’å: {np.mean(causal_ranks):.1f}/4")
    print(f"   æœ€å¥½æ’å: {min(causal_ranks)}")
    print(f"   æœ€å·®æ’å: {max(causal_ranks)}")


def main():
    """ä¸»å‡½æ•°"""
    
    print("="*60)
    print("ğŸš€ CausalEngine è¡¨æ ¼æ•°æ®å¿«é€Ÿæµ‹è¯•")
    print("   ä½¿ç”¨ç»å…¸å°æ•°æ®é›†è¿›è¡Œå¿«é€Ÿå¯¹æ¯”")
    print("="*60)
    
    # åŠ è½½æ•°æ®é›†
    datasets_info = load_datasets()
    
    # åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°
    all_results = {}
    
    for dataset_info in datasets_info:
        results = evaluate_on_dataset(dataset_info)
        all_results[dataset_info['name']] = results
    
    # å¯è§†åŒ–
    visualize_results(all_results)
    
    # æ‰“å°æ€»ç»“
    print_summary(all_results)
    
    print("\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
    print("ğŸ“Š è¯·æŸ¥çœ‹ tabular_quick_test_results.png")


if __name__ == "__main__":
    main() 