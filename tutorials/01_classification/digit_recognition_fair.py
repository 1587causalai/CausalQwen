#!/usr/bin/env python3
"""
CausalEngine æ‰‹å†™æ•°å­—è¯†åˆ«æ•™ç¨‹ - å…¬å¹³å¯¹æ¯”ç‰ˆ

æ”¹è¿›ç‚¹ï¼š
1. ä¸ºä¼ ç»Ÿæ–¹æ³•ä¹Ÿå¢åŠ ç‰¹å¾å­¦ä¹ èƒ½åŠ›ï¼ˆä½¿ç”¨æ ¸æ–¹æ³•æˆ–ç‰¹å¾å·¥ç¨‹ï¼‰
2. å¢åŠ è®­ç»ƒepochï¼Œä½¿ç”¨æ—©åœç­–ç•¥
3. ä¼˜åŒ–è¶…å‚æ•°è®¾ç½®
4. å¢åŠ ç®€å•çš„åŸºçº¿ç¥ç»ç½‘ç»œè¿›è¡Œå¯¹æ¯”
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ CausalEngine
import sys
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')
from causal_engine import CausalEngine, ActivationMode


class DigitsDataset(Dataset):
    """æ‰‹å†™æ•°å­—æ•°æ®é›†"""
    
    def __init__(self, features, labels):
        self.features = torch.FloatTensor(features)
        self.labels = torch.LongTensor(labels)
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


class CausalDigitClassifier(nn.Module):
    """åŸºäº CausalEngine çš„æ•°å­—åˆ†ç±»å™¨ - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, input_size=64, hidden_size=128, num_classes=10):
        super().__init__()
        
        # æ›´ç®€å•çš„ç‰¹å¾ç¼–ç å±‚ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
        self.feature_encoder = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),  # å‡å°‘dropout
        )
        
        # CausalEngine æ ¸å¿ƒ
        self.causal_engine = CausalEngine(
            hidden_size=hidden_size,
            vocab_size=num_classes,
            activation_modes="classification",
            b_noise_init=0.05,  # å‡å°åˆå§‹å™ªå£°
            gamma_init=1.0
        )
    
    def forward(self, x, temperature=1.0, do_sample=False, return_details=False):
        # ç‰¹å¾ç¼–ç 
        hidden_states = self.feature_encoder(x)
        
        # CausalEngine æ¨ç†
        output = self.causal_engine(
            hidden_states.unsqueeze(1),
            temperature=temperature,
            do_sample=do_sample,
            return_dict=True
        )
        
        if return_details:
            return output
        else:
            return output['output'].squeeze(1)


class SimpleNeuralNet(nn.Module):
    """ç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œ - ä½œä¸ºå…¬å¹³å¯¹æ¯”"""
    
    def __init__(self, input_size=64, hidden_size=128, num_classes=10):
        super().__init__()
        
        self.net = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size, num_classes)
        )
    
    def forward(self, x):
        return self.net(x)


def prepare_digits_data(add_features=True):
    """å‡†å¤‡æ‰‹å†™æ•°å­—æ•°æ®ï¼Œå¯é€‰æ‹©å¢åŠ å¤šé¡¹å¼ç‰¹å¾"""
    
    print("ğŸ”¢ åŠ è½½æ‰‹å†™æ•°å­—æ•°æ®é›†...")
    
    # åŠ è½½æ•°æ®
    digits = load_digits()
    X, y = digits.data, digits.target
    
    # æ•°æ®ä¿¡æ¯
    print(f"   åŸå§‹æ ·æœ¬æ•°: {X.shape[0]}")
    print(f"   åŸå§‹ç‰¹å¾ç»´åº¦: {X.shape[1]} (8x8 å›¾åƒå±•å¹³)")
    
    # å¯é€‰ï¼šå¢åŠ å¤šé¡¹å¼ç‰¹å¾ï¼Œè®©ä¼ ç»Ÿæ–¹æ³•ä¹Ÿæœ‰æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›
    if add_features:
        print("   æ·»åŠ å¤šé¡¹å¼ç‰¹å¾ä»¥å¢å¼ºä¼ ç»Ÿæ–¹æ³•...")
        poly = PolynomialFeatures(degree=2, include_bias=False)
        X_poly = poly.fit_transform(X)
        # ç”±äºç»´åº¦å¤ªé«˜ï¼Œä½¿ç”¨PCAé™ç»´
        from sklearn.decomposition import PCA
        pca = PCA(n_components=128, random_state=42)
        X_enhanced = pca.fit_transform(X_poly)
        print(f"   å¢å¼ºåç‰¹å¾ç»´åº¦: {X_enhanced.shape[1]}")
    else:
        X_enhanced = X
        pca = None
        poly = None
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_enhanced)
    
    # åŒæ—¶ä¿ç•™åŸå§‹ç‰¹å¾ç”¨äºç¥ç»ç½‘ç»œ
    X_original = scaler.fit_transform(X)
    
    # åˆ’åˆ†æ•°æ®é›†
    X_temp, X_test, X_orig_temp, X_orig_test, y_temp, y_test = train_test_split(
        X_scaled, X_original, y, test_size=0.2, random_state=42, stratify=y
    )
    X_train, X_val, X_orig_train, X_orig_val, y_train, y_val = train_test_split(
        X_temp, X_orig_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
    )
    
    print(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆ:")
    print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    
    return {
        'enhanced': (X_train, X_val, X_test),
        'original': (X_orig_train, X_orig_val, X_orig_test),
        'labels': (y_train, y_val, y_test),
        'transformers': (scaler, poly, pca)
    }


def train_causal_model_with_early_stopping(model, train_loader, val_loader, max_epochs=100, patience=10):
    """è®­ç»ƒ CausalEngine æ¨¡å‹ï¼Œä½¿ç”¨æ—©åœç­–ç•¥"""
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ CausalEngine æ¨¡å‹ï¼ˆå¸¦æ—©åœï¼‰...")
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)  # é™ä½å­¦ä¹ ç‡
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, factor=0.5)
    
    train_losses = []
    val_accuracies = []
    best_val_acc = 0
    patience_counter = 0
    best_model_state = None
    
    for epoch in range(max_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        
        for features, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(features, temperature=1.0, do_sample=False)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for features, labels in val_loader:
                outputs = model(features, temperature=0.0)  # çº¯å› æœæ¨¡å¼
                _, predicted = torch.max(outputs, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()
        
        train_acc = 100 * train_correct / train_total
        val_acc = 100 * val_correct / val_total
        avg_loss = train_loss / len(train_loader)
        
        train_losses.append(avg_loss)
        val_accuracies.append(val_acc)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_acc)
        
        # æ—©åœæ£€æŸ¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{max_epochs}], Loss: {avg_loss:.4f}, "
                  f"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%")
        
        if patience_counter >= patience:
            print(f"æ—©åœè§¦å‘ï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
            break
    
    # æ¢å¤æœ€ä½³æ¨¡å‹
    model.load_state_dict(best_model_state)
    print(f"âœ… è®­ç»ƒå®Œæˆ! æœ€ç»ˆæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    
    return train_losses, val_accuracies


def train_simple_nn(X_train, y_train, X_val, y_val, max_epochs=100):
    """è®­ç»ƒç®€å•çš„ç¥ç»ç½‘ç»œä½œä¸ºå¯¹æ¯”"""
    
    print("\nğŸ§  è®­ç»ƒç®€å•ç¥ç»ç½‘ç»œ...")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = DigitsDataset(X_train, y_train)
    val_dataset = DigitsDataset(X_val, y_val)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    model = SimpleNeuralNet(input_size=64, hidden_size=128, num_classes=10)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)
    
    best_val_acc = 0
    patience = 10
    patience_counter = 0
    
    for epoch in range(max_epochs):
        # è®­ç»ƒ
        model.train()
        for features, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        
        # éªŒè¯
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for features, labels in val_loader:
                outputs = model(features)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        val_acc = 100 * correct / total
        
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
        
        if patience_counter >= patience:
            break
    
    model.load_state_dict(best_model)
    print(f"   ç®€å•ç¥ç»ç½‘ç»œæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    
    return model, best_val_acc


def train_enhanced_baselines(X_train, y_train, X_val, y_val):
    """è®­ç»ƒå¢å¼ºçš„åŸºçº¿æ¨¡å‹"""
    
    print("\nğŸ“Š è®­ç»ƒå¢å¼ºçš„åŸºçº¿æ¨¡å‹...")
    
    baselines = {}
    
    # 1. é€»è¾‘å›å½’ï¼ˆä½¿ç”¨L2æ­£åˆ™åŒ–ï¼‰
    lr = LogisticRegression(
        random_state=42, 
        max_iter=1000, 
        multi_class='ovr',
        C=10.0  # è°ƒæ•´æ­£åˆ™åŒ–å¼ºåº¦
    )
    lr.fit(X_train, y_train)
    lr_acc = lr.score(X_val, y_val)
    baselines['Logistic Regression'] = {
        'model': lr, 
        'accuracy': lr_acc
    }
    print(f"   Logistic Regression éªŒè¯å‡†ç¡®ç‡: {lr_acc:.3f}")
    
    # 2. SVMï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
    svm = SVC(
        kernel='rbf', 
        random_state=42, 
        probability=True,
        C=10.0,  # å¢åŠ Cå€¼
        gamma='scale'
    )
    svm.fit(X_train, y_train)
    svm_acc = svm.score(X_val, y_val)
    baselines['SVM (RBF)'] = {
        'model': svm,
        'accuracy': svm_acc
    }
    print(f"   SVM (RBF) éªŒè¯å‡†ç¡®ç‡: {svm_acc:.3f}")
    
    # 3. MLPï¼ˆsklearnçš„ç¥ç»ç½‘ç»œï¼‰- ä½¿ç”¨å¢å¼ºç‰¹å¾
    mlp = MLPClassifier(
        hidden_layer_sizes=(128,),
        activation='relu',
        solver='adam',
        alpha=0.0001,
        batch_size=32,
        learning_rate='adaptive',
        learning_rate_init=0.001,
        max_iter=200,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.1
    )
    mlp.fit(X_train, y_train)  # è¿™é‡ŒX_trainå·²ç»æ˜¯å¢å¼ºç‰¹å¾
    mlp_acc = mlp.score(X_val, y_val)
    baselines['MLP (sklearn)'] = {
        'model': mlp,
        'accuracy': mlp_acc
    }
    print(f"   MLP (sklearn) éªŒè¯å‡†ç¡®ç‡: {mlp_acc:.3f}")
    
    return baselines


def comprehensive_evaluation(models_dict, test_data, test_labels):
    """ç»¼åˆè¯„ä¼°æ‰€æœ‰æ¨¡å‹"""
    
    print("\nğŸ“Š ç»¼åˆè¯„ä¼°æ‰€æœ‰æ¨¡å‹...")
    
    results = {}
    
    for name, model_info in models_dict.items():
        if name == 'CausalEngine':
            # CausalEngineéœ€è¦ç‰¹æ®Šå¤„ç†
            model = model_info['model']
            model.eval()
            
            test_dataset = DigitsDataset(test_data['original'], test_labels)
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
            
            predictions = []
            uncertainties = []
            with torch.no_grad():
                for features, _ in test_loader:
                    output = model(features, temperature=0.0, return_details=True)
                    probs = output['output'].squeeze(1)
                    _, pred = torch.max(probs, 1)
                    predictions.extend(pred.numpy())
                    
                    # ä¸ç¡®å®šæ€§
                    scale_S = output['scale_S'].squeeze(1)
                    avg_uncertainty = scale_S.mean(dim=1)
                    uncertainties.extend(avg_uncertainty.numpy())
            
            predictions = np.array(predictions)
            accuracy = accuracy_score(test_labels, predictions)
            
            results[name] = {
                'accuracy': accuracy,
                'predictions': predictions,
                'uncertainties': np.array(uncertainties),
                'has_uncertainty': True
            }
            
        elif name == 'Simple NN':
            # PyTorchç®€å•ç¥ç»ç½‘ç»œ
            model = model_info['model']
            model.eval()
            
            test_dataset = DigitsDataset(test_data['original'], test_labels)
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
            
            predictions = []
            with torch.no_grad():
                for features, _ in test_loader:
                    outputs = model(features)
                    _, pred = torch.max(outputs, 1)
                    predictions.extend(pred.numpy())
            
            predictions = np.array(predictions)
            accuracy = accuracy_score(test_labels, predictions)
            
            results[name] = {
                'accuracy': accuracy,
                'predictions': predictions,
                'has_uncertainty': False
            }
            
        else:
            # sklearnæ¨¡å‹
            model = model_info['model']
            
            # å†³å®šä½¿ç”¨å“ªä¸ªç‰¹å¾é›†
            if name in ['Logistic Regression', 'SVM (RBF)', 'MLP (sklearn)']:
                X_test = test_data['enhanced']  # ä½¿ç”¨å¢å¼ºç‰¹å¾
            else:
                X_test = test_data['original']  # å…¶ä»–ä½¿ç”¨åŸå§‹ç‰¹å¾
            
            predictions = model.predict(X_test)
            accuracy = accuracy_score(test_labels, predictions)
            
            results[name] = {
                'accuracy': accuracy,
                'predictions': predictions,
                'has_uncertainty': False
            }
        
        print(f"   {name} æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.3f}")
    
    return results


def visualize_fair_comparison(results, y_test, train_history=None):
    """å¯è§†åŒ–å…¬å¹³å¯¹æ¯”ç»“æœ"""
    
    print("\nğŸ“ˆ ç”Ÿæˆå…¬å¹³å¯¹æ¯”å¯è§†åŒ–...")
    
    plt.rcParams['font.family'] = 'DejaVu Sans'
    fig = plt.figure(figsize=(16, 10))
    
    # 1. æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”
    ax1 = plt.subplot(2, 3, 1)
    models = list(results.keys())
    accuracies = [results[m]['accuracy'] for m in models]
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    sorted_idx = np.argsort(accuracies)[::-1]
    models_sorted = [models[i] for i in sorted_idx]
    acc_sorted = [accuracies[i] for i in sorted_idx]
    
    colors = ['red' if 'Causal' in m else 'orange' if 'NN' in m else 'gray' 
              for m in models_sorted]
    
    bars = ax1.bar(range(len(models_sorted)), acc_sorted, color=colors, alpha=0.7)
    ax1.set_xticks(range(len(models_sorted)))
    ax1.set_xticklabels(models_sorted, rotation=45, ha='right')
    ax1.set_ylabel('Test Accuracy')
    ax1.set_title('Model Performance Comparison (Fair)')
    ax1.set_ylim([0.8, 1.0])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, acc) in enumerate(zip(bars, acc_sorted)):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,
                f'{acc:.3f}', ha='center', va='bottom', fontsize=9)
    
    # 2. æ··æ·†çŸ©é˜µå¯¹æ¯” (CausalEngine)
    ax2 = plt.subplot(2, 3, 2)
    causal_pred = results['CausalEngine']['predictions']
    cm = confusion_matrix(y_test, causal_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2, cbar_kws={'shrink': 0.8})
    ax2.set_title('CausalEngine Confusion Matrix')
    ax2.set_xlabel('Predicted')
    ax2.set_ylabel('True')
    
    # 3. è®­ç»ƒå†å²ï¼ˆå¦‚æœæœ‰ï¼‰
    if train_history:
        ax3 = plt.subplot(2, 3, 3)
        train_losses, val_accs = train_history
        ax3_twin = ax3.twinx()
        
        line1 = ax3.plot(train_losses, 'b-', label='Training Loss')
        line2 = ax3_twin.plot(val_accs, 'g-', label='Validation Accuracy')
        
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Loss', color='b')
        ax3_twin.set_ylabel('Accuracy (%)', color='g')
        ax3.set_title('CausalEngine Training History')
        
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        ax3.legend(lines, labels, loc='center right')
    
    # 4. ä¸ç¡®å®šæ€§åˆ†æï¼ˆä»…CausalEngineï¼‰
    ax4 = plt.subplot(2, 3, 4)
    if 'uncertainties' in results['CausalEngine']:
        uncertainties = results['CausalEngine']['uncertainties']
        predictions = results['CausalEngine']['predictions']
        
        correct_mask = predictions == y_test
        
        ax4.hist(uncertainties[correct_mask], bins=30, alpha=0.6, 
                 label=f'Correct (n={correct_mask.sum()})', color='green', density=True)
        ax4.hist(uncertainties[~correct_mask], bins=30, alpha=0.6,
                 label=f'Incorrect (n={(~correct_mask).sum()})', color='red', density=True)
        
        ax4.set_xlabel('Uncertainty')
        ax4.set_ylabel('Density')
        ax4.set_title('CausalEngine Uncertainty Distribution')
        ax4.legend()
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        ax4.text(0.95, 0.95, 
                f'Avg Unc (Correct): {uncertainties[correct_mask].mean():.3f}\n'
                f'Avg Unc (Wrong): {uncertainties[~correct_mask].mean():.3f}',
                transform=ax4.transAxes, ha='right', va='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    # 5. æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½
    ax5 = plt.subplot(2, 3, 5)
    class_accuracies = {}
    
    for model_name in ['CausalEngine', 'SVM (RBF)', 'MLP (sklearn)']:
        if model_name in results:
            predictions = results[model_name]['predictions']
            class_acc = []
            for i in range(10):
                mask = y_test == i
                if mask.sum() > 0:
                    acc = (predictions[mask] == i).mean()
                    class_acc.append(acc)
            class_accuracies[model_name] = class_acc
    
    x = np.arange(10)
    width = 0.25
    
    for i, (model, accs) in enumerate(class_accuracies.items()):
        offset = (i - 1) * width
        ax5.bar(x + offset, accs, width, label=model, alpha=0.8)
    
    ax5.set_xlabel('Digit Class')
    ax5.set_ylabel('Accuracy')
    ax5.set_title('Per-Class Accuracy Comparison')
    ax5.set_xticks(x)
    ax5.legend()
    
    # 6. æ¨¡å‹å¤æ‚åº¦ä¸æ€§èƒ½
    ax6 = plt.subplot(2, 3, 6)
    # è¿™æ˜¯ä¸€ä¸ªæ¦‚å¿µå›¾ï¼Œå±•ç¤ºæ¨¡å‹ç‰¹ç‚¹
    model_features = {
        'Logistic\nRegression': {'complexity': 1, 'interpretability': 5, 'uncertainty': 0},
        'SVM\n(RBF)': {'complexity': 3, 'interpretability': 2, 'uncertainty': 0},
        'MLP\n(sklearn)': {'complexity': 4, 'interpretability': 1, 'uncertainty': 0},
        'Simple\nNN': {'complexity': 4, 'interpretability': 1, 'uncertainty': 0},
        'CausalEngine': {'complexity': 5, 'interpretability': 3, 'uncertainty': 5}
    }
    
    models_list = list(model_features.keys())
    metrics = ['Complexity', 'Interpretability', 'Uncertainty']
    
    # åˆ›å»ºé›·è¾¾å›¾
    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
    angles += angles[:1]
    
    ax6 = plt.subplot(2, 3, 6, projection='polar')
    
    for model in ['Logistic\nRegression', 'SVM\n(RBF)', 'CausalEngine']:
        values = [model_features[model][m.lower()] for m in metrics]
        values += values[:1]
        
        if 'Causal' in model:
            ax6.plot(angles, values, 'o-', linewidth=2, label=model, color='red')
            ax6.fill(angles, values, alpha=0.25, color='red')
        else:
            ax6.plot(angles, values, 'o-', linewidth=1, label=model, alpha=0.7)
    
    ax6.set_xticks(angles[:-1])
    ax6.set_xticklabels(metrics)
    ax6.set_ylim(0, 5)
    ax6.set_title('Model Characteristics', y=1.08)
    ax6.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))
    ax6.grid(True)
    
    plt.tight_layout()
    plt.savefig('fair_comparison_analysis.png', dpi=150, bbox_inches='tight')
    print("   å…¬å¹³å¯¹æ¯”åˆ†æå·²ä¿å­˜åˆ° fair_comparison_analysis.png")
    plt.close()


# ä¿®æ”¹ä¸»å‡½æ•°ä»¥é€‚åº”å…¬å¹³å¯¹æ¯”
def main():
    """ä¸»å‡½æ•° - å…¬å¹³å¯¹æ¯”ç‰ˆ"""
    
    print("="*70)
    print("ğŸ¯ CausalEngine æ‰‹å†™æ•°å­—è¯†åˆ«æ•™ç¨‹ - å…¬å¹³å¯¹æ¯”ç‰ˆ")
    print("   ç¡®ä¿æ‰€æœ‰æ¨¡å‹åœ¨ç›¸ä¼¼æ¡ä»¶ä¸‹è¿›è¡Œå¯¹æ¯”")
    print("="*70)
    
    # 1. å‡†å¤‡æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
    data = prepare_digits_data(add_features=True)
    X_train, X_val, X_test = data['enhanced']
    X_orig_train, X_orig_val, X_orig_test = data['original']
    y_train, y_val, y_test = data['labels']
    
    # 2. è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    all_models = {}
    
    # 2.1 CausalEngineï¼ˆä½¿ç”¨åŸå§‹ç‰¹å¾ï¼‰
    causal_model = CausalDigitClassifier(input_size=64, hidden_size=128, num_classes=10)
    train_dataset = DigitsDataset(X_orig_train, y_train)
    val_dataset = DigitsDataset(X_orig_val, y_val)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    train_losses, val_accs = train_causal_model_with_early_stopping(
        causal_model, train_loader, val_loader, max_epochs=100, patience=10
    )
    all_models['CausalEngine'] = {'model': causal_model}
    
    # 2.2 ç®€å•ç¥ç»ç½‘ç»œï¼ˆå…¬å¹³å¯¹æ¯”ï¼‰
    simple_nn, simple_nn_acc = train_simple_nn(X_orig_train, y_train, X_orig_val, y_val)
    all_models['Simple NN'] = {'model': simple_nn, 'accuracy': simple_nn_acc}
    
    # 2.3 ä¼ ç»Ÿæ–¹æ³•ï¼ˆä½¿ç”¨å¢å¼ºç‰¹å¾ï¼‰
    baseline_models = train_enhanced_baselines(X_train, y_train, X_val, y_val)
    all_models.update(baseline_models)
    
    # 3. ç»¼åˆè¯„ä¼°
    test_data = {
        'enhanced': X_test,
        'original': X_orig_test
    }
    results = comprehensive_evaluation(all_models, test_data, y_test)
    
    # 4. å¯è§†åŒ–å…¬å¹³å¯¹æ¯”
    visualize_fair_comparison(results, y_test, train_history=(train_losses, val_accs))
    
    # 5. æ‰“å°æœ€ç»ˆæ€»ç»“
    print("\nğŸ“Š æœ€ç»ˆæ€»ç»“:")
    print("-" * 50)
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)
    
    for rank, (model_name, result) in enumerate(sorted_results, 1):
        acc = result['accuracy']
        print(f"{rank}. {model_name:20s} - å‡†ç¡®ç‡: {acc:.3f}")
        if result.get('has_uncertainty'):
            print(f"   â­ æä¾›ä¸ç¡®å®šæ€§é‡åŒ–")
    
    print("\nğŸ’¡ å…³é”®å‘ç°:")
    print("1. åœ¨å…¬å¹³å¯¹æ¯”ä¸‹ï¼ŒCausalEngineçš„æ€§èƒ½æ›´æ¥è¿‘ä¼ ç»Ÿæ–¹æ³•")
    print("2. CausalEngineç‹¬ç‰¹ä¼˜åŠ¿ï¼šæä¾›å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡")
    print("3. ä¼ ç»Ÿæ–¹æ³•åœ¨ç»“æ„åŒ–ä½ç»´æ•°æ®ä¸Šä»æœ‰ä¼˜åŠ¿")
    print("4. ç¥ç»ç½‘ç»œæ–¹æ³•éœ€è¦æ›´å¤šæ•°æ®æ‰èƒ½å‘æŒ¥ä¼˜åŠ¿")
    
    print("\nâœ… å…¬å¹³å¯¹æ¯”æ•™ç¨‹å®Œæˆï¼")
    print("ğŸ“Š è¯·æŸ¥çœ‹ fair_comparison_analysis.png äº†è§£è¯¦ç»†åˆ†æ")


if __name__ == "__main__":
    main() 