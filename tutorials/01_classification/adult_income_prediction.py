"""
Adult Income æ•°æ®é›†åˆ†ç±»æ•™ç¨‹ (å¸¦æ¶ˆèå®éªŒ)
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨CausalEngineè¿›è¡Œæ”¶å…¥é¢„æµ‹ï¼Œå¹¶ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”

è¿™æ˜¯æœ€é‡è¦çš„åˆ†ç±»æ¼”ç¤ºä¹‹ä¸€ï¼ŒåŒ…å«å®Œæ•´çš„æ¶ˆèå®éªŒï¼
"""

import sys
import os
import time
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

from tutorials.utils.data_loaders import load_dataset
from tutorials.utils.baseline_networks import BaselineMLPClassifier, BaselineTrainer
from tutorials.utils.ablation_networks import create_ablation_experiment, AblationTrainer
from tutorials.utils.evaluation_metrics import (
    calculate_classification_metrics, compare_model_performance,
    plot_confusion_matrix, generate_evaluation_report
)


def explore_adult_dataset():
    """
    æ¢ç´¢Adult Incomeæ•°æ®é›†
    """
    print("ğŸ“Š Adult Income æ•°æ®é›†æ¢ç´¢")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    data_dict = load_dataset('adult', batch_size=64)
    
    print(f"\nğŸ“ˆ æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
    print(f"   æ•°æ®é›†åç§°: {data_dict['name']}")
    print(f"   ä»»åŠ¡ç±»å‹: {data_dict['task_type']}")
    print(f"   è¾“å…¥ç‰¹å¾æ•°: {data_dict['input_size']}")
    print(f"   è¾“å‡ºç±»åˆ«æ•°: {data_dict['num_classes']}")
    print(f"   è®­ç»ƒæ ·æœ¬: {data_dict['train_size']}")
    print(f"   éªŒè¯æ ·æœ¬: {data_dict['val_size']}")
    print(f"   æµ‹è¯•æ ·æœ¬: {data_dict['test_size']}")
    
    # æ˜¾ç¤ºç‰¹å¾ä¿¡æ¯
    print(f"\nğŸ” ç‰¹å¾åˆ—è¡¨:")
    for i, feature in enumerate(data_dict['feature_names']):
        print(f"   {i+1:2d}. {feature}")
    
    # åˆ†æç›®æ ‡å˜é‡åˆ†å¸ƒ
    y_train = data_dict['y_train']
    unique, counts = np.unique(y_train, return_counts=True)
    
    print(f"\nğŸ“Š ç›®æ ‡å˜é‡åˆ†å¸ƒ:")
    for label, count in zip(unique, counts):
        label_name = "<=50K" if label == 0 else ">50K"
        percentage = count / len(y_train) * 100
        print(f"   {label_name}: {count} æ ·æœ¬ ({percentage:.1f}%)")
    
    return data_dict


def run_ablation_experiment(data_dict):
    """
    è¿è¡Œå®Œæ•´çš„æ¶ˆèå®éªŒ
    ä½¿ç”¨æ–°çš„æ¶ˆèè®¾è®¡ï¼šåŒä¸€ä¸ªç½‘ç»œï¼Œä»…æŸå¤±å‡½æ•°ä¸åŒ
    """
    print("\nğŸ”¬ Adult Income æ¶ˆèå®éªŒ")
    print("=" * 50)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    input_size = data_dict['input_size']
    num_classes = data_dict['num_classes']
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"è¾“å…¥ç»´åº¦: {input_size}")
    print(f"ç±»åˆ«æ•°: {num_classes}")
    
    results = {}
    
    # 1. è®­ç»ƒä¼ ç»Ÿç¥ç»ç½‘ç»œåŸºå‡†
    print(f"\nğŸ—ï¸  ç¬¬1æ­¥: è®­ç»ƒä¼ ç»Ÿç¥ç»ç½‘ç»œåŸºå‡†")
    start_time = time.time()
    
    baseline_model = BaselineMLPClassifier(
        input_dim=input_size,
        num_classes=num_classes,
        hidden_dims=[512, 256],
        dropout=0.1
    )
    
    baseline_trainer = BaselineTrainer(baseline_model, device=device)
    
    baseline_trainer.train_classification(
        train_loader=data_dict['train_loader'],
        val_loader=data_dict['val_loader'],
        num_epochs=50
    )
    
    baseline_time = time.time() - start_time
    
    # è¯„ä¼°åŸºå‡†æ¨¡å‹
    baseline_metrics = evaluate_baseline_model(
        baseline_model, data_dict['test_loader'], device, "ä¼ ç»Ÿç¥ç»ç½‘ç»œ"
    )
    baseline_metrics['training_time'] = baseline_time
    results['baseline'] = baseline_metrics
    
    print(f"âœ… ä¼ ç»Ÿç¥ç»ç½‘ç»œè®­ç»ƒå®Œæˆ ({baseline_time:.2f}s)")
    
    # 2. åˆ›å»ºCausalEngineï¼ˆç”¨äºæ¶ˆèå’Œå®Œæ•´ç‰ˆæœ¬ï¼‰
    print(f"\nâš¡ åˆ›å»ºCausalEngine...")
    
    # æ¶ˆèç‰ˆæœ¬ - ä½¿ç”¨ç›¸åŒç½‘ç»œä½†ä»…locæŸå¤±
    engine_ablation, wrapper_ablation = create_ablation_experiment(
        input_dim=input_size,
        hidden_dim=512,
        num_layers=4,
        num_heads=8,
        task_type='classification',
        num_classes=num_classes,
        dropout=0.1,
        device=device
    )
    
    trainer_ablation = AblationTrainer(engine_ablation, wrapper_ablation)
    
    # 3. è®­ç»ƒCausalEngineæ¶ˆèç‰ˆæœ¬ï¼ˆä»…ä½¿ç”¨locæŸå¤±ï¼‰
    print(f"\nâš—ï¸  ç¬¬2æ­¥: è®­ç»ƒCausalEngineæ¶ˆèç‰ˆæœ¬ (ä»…ä½¿ç”¨locæŸå¤±)")
    start_time = time.time()
    
    # å‡†å¤‡è¾“å…¥è½¬æ¢å‡½æ•° - çœŸå®CausalEngine API
    def prepare_causal_inputs(batch_x):
        # CausalEngineæœŸæœ›hidden_statesï¼Œä¸éœ€è¦input_ids
        return {
            'values': batch_x  # ä¿ç•™valueså­—æ®µä¾›ablation wrapperä½¿ç”¨
        }
    
    # è®­ç»ƒæ¶ˆèç‰ˆæœ¬
    best_val_loss = float('inf')
    for epoch in range(50):
        train_loss = 0
        train_acc = 0
        num_batches = 0
        
        for batch_x, batch_y in data_dict['train_loader']:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            inputs = prepare_causal_inputs(batch_x)
            hidden_states = inputs['values'] if isinstance(inputs, dict) else inputs
            metrics = trainer_ablation.train_step_ablation(hidden_states, batch_y)
            
            train_loss += metrics['loss']
            train_acc += metrics['accuracy']
            num_batches += 1
        
        # éªŒè¯
        val_loss = 0
        val_acc = 0
        val_batches = 0
        
        for batch_x, batch_y in data_dict['val_loader']:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            inputs = prepare_causal_inputs(batch_x)
            hidden_states = inputs['values'] if isinstance(inputs, dict) else inputs
            metrics = trainer_ablation.eval_step(hidden_states, batch_y, use_ablation=True)
            
            val_loss += metrics['loss']
            val_acc += metrics['accuracy']
            val_batches += 1
        
        avg_val_loss = val_loss / val_batches
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_ablation_state = engine_ablation.state_dict()
        
        if epoch % 10 == 0:
            print(f"   Epoch {epoch}: train_acc={train_acc/num_batches:.4f}, val_acc={val_acc/val_batches:.4f}")
    
    # æ¢å¤æœ€ä½³æ¨¡å‹
    engine_ablation.load_state_dict(best_ablation_state)
    
    ablation_time = time.time() - start_time
    
    # è¯„ä¼°æ¶ˆèæ¨¡å‹
    ablation_metrics = evaluate_causal_model(
        engine_ablation, wrapper_ablation, data_dict['test_loader'], 
        device, "CausalEngine(æ¶ˆè)", use_ablation=True, prepare_fn=prepare_causal_inputs
    )
    ablation_metrics['training_time'] = ablation_time
    results['ablation'] = ablation_metrics
    
    print(f"âœ… CausalEngineæ¶ˆèç‰ˆæœ¬è®­ç»ƒå®Œæˆ ({ablation_time:.2f}s)")
    
    # 4. è®­ç»ƒå®Œæ•´CausalEngineï¼ˆä½¿ç”¨å®Œæ•´å› æœæŸå¤±ï¼‰
    print(f"\nğŸŒŸ ç¬¬3æ­¥: è®­ç»ƒå®Œæ•´CausalEngine (ä½¿ç”¨å®Œæ•´å› æœæŸå¤±)")
    start_time = time.time()
    
    # åˆ›å»ºæ–°çš„CausalEngineå®ä¾‹ç”¨äºå®Œæ•´ç‰ˆæœ¬
    engine_full, wrapper_full = create_ablation_experiment(
        input_dim=input_size,
        hidden_dim=512,
        num_layers=4,
        num_heads=8,
        task_type='classification',
        num_classes=num_classes,
        dropout=0.1,
        device=device
    )
    
    trainer_full = AblationTrainer(engine_full, wrapper_full)
    
    # è®­ç»ƒå®Œæ•´ç‰ˆæœ¬
    best_val_loss = float('inf')
    for epoch in range(50):
        train_loss = 0
        train_acc = 0
        num_batches = 0
        
        for batch_x, batch_y in data_dict['train_loader']:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            inputs = prepare_causal_inputs(batch_x)
            hidden_states = inputs['values'] if isinstance(inputs, dict) else inputs
            metrics = trainer_full.train_step_full(hidden_states, batch_y)
            
            train_loss += metrics['loss']
            train_acc += metrics['accuracy']
            num_batches += 1
        
        # éªŒè¯
        val_loss = 0
        val_acc = 0
        val_batches = 0
        
        for batch_x, batch_y in data_dict['val_loader']:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            inputs = prepare_causal_inputs(batch_x)
            hidden_states = inputs['values'] if isinstance(inputs, dict) else inputs
            metrics = trainer_full.eval_step(hidden_states, batch_y, use_ablation=False)
            
            val_loss += metrics['loss']
            val_acc += metrics['accuracy']
            val_batches += 1
        
        avg_val_loss = val_loss / val_batches
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_full_state = engine_full.state_dict()
        
        if epoch % 10 == 0:
            print(f"   Epoch {epoch}: train_acc={train_acc/num_batches:.4f}, val_acc={val_acc/val_batches:.4f}")
    
    # æ¢å¤æœ€ä½³æ¨¡å‹
    engine_full.load_state_dict(best_full_state)
    
    full_time = time.time() - start_time
    
    # è¯„ä¼°å®Œæ•´æ¨¡å‹
    full_metrics = evaluate_causal_model(
        engine_full, wrapper_full, data_dict['test_loader'], 
        device, "CausalEngine(å®Œæ•´)", use_ablation=False, prepare_fn=prepare_causal_inputs
    )
    full_metrics['training_time'] = full_time
    results['full_causal'] = full_metrics
    
    print(f"âœ… å®Œæ•´CausalEngineè®­ç»ƒå®Œæˆ ({full_time:.2f}s)")
    
    return results


def evaluate_baseline_model(model, test_loader, device, model_name):
    """
    è¯„ä¼°ä¼ ç»ŸåŸºå‡†æ¨¡å‹
    """
    print(f"   è¯„ä¼° {model_name}...")
    
    model.eval()
    all_preds = []
    all_targets = []
    all_probs = []
    
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            outputs = model(batch_x)
            preds = torch.argmax(outputs, dim=-1)
            probs = torch.softmax(outputs, dim=-1)
            
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(batch_y.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_classification_metrics(
        y_true=np.array(all_targets),
        y_pred=np.array(all_preds),
        y_proba=np.array(all_probs)
    )
    
    print(f"     å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
    print(f"     F1åˆ†æ•°: {metrics['f1_score']:.4f}")
    
    return metrics


def evaluate_causal_model(engine, wrapper, test_loader, device, model_name, use_ablation, prepare_fn):
    """
    è¯„ä¼°CausalEngineæ¨¡å‹
    """
    print(f"   è¯„ä¼° {model_name}...")
    
    engine.eval()
    all_preds = []
    all_targets = []
    all_probs = []
    
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            inputs = prepare_fn(batch_x)
            
            # ä½¿ç”¨çœŸå®CausalEngine API  
            hidden_states = inputs.get('values')
            if hidden_states.dim() == 2:
                hidden_states = hidden_states.unsqueeze(1)
            
            outputs = engine(
                hidden_states=hidden_states,
                do_sample=False,
                temperature=1.0,
                return_dict=True,
                apply_activation=not use_ablation  # æ¶ˆèç‰ˆæœ¬ä¸ç”¨æ¿€æ´»å¤´ï¼Œå®Œæ•´ç‰ˆæœ¬ç”¨
            )
            
            if use_ablation:
                # æ¶ˆèç‰ˆæœ¬ï¼šä½¿ç”¨locè¿›è¡Œé¢„æµ‹
                loc = outputs['loc_S'][:, -1, :]  # [batch_size, vocab_size]
                logits = loc[:, :wrapper.num_classes]
                preds = torch.argmax(logits, dim=-1)
                probs = torch.softmax(logits, dim=-1)
            else:
                # å®Œæ•´ç‰ˆæœ¬ï¼šä½¿ç”¨æ¿€æ´»å¤´è¾“å‡º
                final_output = outputs['output'][:, -1, :]  # [batch_size, output_dim]
                preds = torch.argmax(final_output, dim=-1)
                probs = torch.softmax(final_output, dim=-1)
            
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(batch_y.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_classification_metrics(
        y_true=np.array(all_targets),
        y_pred=np.array(all_preds),
        y_proba=np.array(all_probs)
    )
    
    print(f"     å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
    print(f"     F1åˆ†æ•°: {metrics['f1_score']:.4f}")
    
    return metrics


def analyze_results(results):
    """
    åˆ†æå’Œå¯è§†åŒ–å®éªŒç»“æœ
    """
    print("\nğŸ“Š ç»“æœåˆ†æ")
    print("=" * 50)
    
    # 1. æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
    print("\nğŸ“‹ æ€§èƒ½å¯¹æ¯”è¡¨æ ¼:")
    print("   æ¨¡å‹                      | å‡†ç¡®ç‡    | ç²¾ç¡®ç‡    | å¬å›ç‡    | F1åˆ†æ•°    | AUC-ROC   | è®­ç»ƒæ—¶é—´")
    print("   ------------------------- | --------- | --------- | --------- | --------- | --------- | ---------")
    
    for model_name, metrics in results.items():
        display_name = {
            'baseline': 'ä¼ ç»Ÿç¥ç»ç½‘ç»œ',
            'ablation': 'CausalEngine(æ¶ˆè)',
            'full_causal': 'CausalEngine(å®Œæ•´)'
        }.get(model_name, model_name)
        
        acc = metrics.get('accuracy', 0)
        prec = metrics.get('precision', 0)
        rec = metrics.get('recall', 0)
        f1 = metrics.get('f1_score', 0)
        auc = metrics.get('auc_roc', 0) if metrics.get('auc_roc') is not None else 0
        time_val = metrics.get('training_time', 0)
        
        print(f"   {display_name:25} | {acc:.4f}    | {prec:.4f}    | {rec:.4f}    | {f1:.4f}    | {auc:.4f}    | {time_val:.1f}s")
    
    # 2. æ¶ˆèå®éªŒéªŒè¯
    print("\nğŸ”¬ æ¶ˆèå®éªŒéªŒè¯:")
    
    baseline_acc = results['baseline']['accuracy']
    ablation_acc = results['ablation']['accuracy']
    full_acc = results['full_causal']['accuracy']
    
    acc_diff = abs(baseline_acc - ablation_acc)
    print(f"   ä¼ ç»Ÿç¥ç»ç½‘ç»œå‡†ç¡®ç‡: {baseline_acc:.4f}")
    print(f"   CausalEngine(æ¶ˆè)å‡†ç¡®ç‡: {ablation_acc:.4f}")
    print(f"   CausalEngine(å®Œæ•´)å‡†ç¡®ç‡: {full_acc:.4f}")
    print(f"   æ¶ˆèvsåŸºå‡†å·®å¼‚: {acc_diff:.4f}")
    
    if acc_diff < 0.01:  # å·®å¼‚å°äº1%
        print("   âœ… æ¶ˆèå‡è®¾éªŒè¯æˆåŠŸï¼šä»…ä½¿ç”¨ä½ç½®è¾“å‡ºæ—¶æ€§èƒ½æ¥è¿‘ä¼ ç»Ÿç½‘ç»œ")
    else:
        print("   âš ï¸  æ³¨æ„ï¼šæ¶ˆèç‰ˆæœ¬ä¸ä¼ ç»Ÿç½‘ç»œå­˜åœ¨å·®å¼‚ï¼Œå¯èƒ½ç”±äºæ¶æ„å·®å¼‚")
    
    # 3. æ€§èƒ½æå‡åˆ†æ
    print("\nğŸ“ˆ æ€§èƒ½æå‡åˆ†æ:")
    improvement = ((full_acc - baseline_acc) / baseline_acc) * 100
    print(f"   å®Œæ•´CausalEngineç›¸å¯¹åŸºå‡†æå‡: {improvement:+.2f}%")
    
    causal_gain = ((full_acc - ablation_acc) / ablation_acc) * 100
    print(f"   å› æœæœºåˆ¶å¸¦æ¥çš„æå‡: {causal_gain:+.2f}%")
    
    # 4. å¯è§†åŒ–ç»“æœ
    visualize_results(results)


def visualize_results(results):
    """
    å¯è§†åŒ–å®éªŒç»“æœ
    """
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # Setup plotting style
    plt.style.use('default')
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. Accuracy comparison
    models = list(results.keys())
    model_names = ['Traditional NN', 'CausalEngine\n(Ablated)', 'CausalEngine\n(Full)']
    accuracies = [results[m]['accuracy'] for m in models]
    
    bars = axes[0, 0].bar(model_names, accuracies, color=['skyblue', 'lightgreen', 'gold'])
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].set_title('Model Accuracy Comparison')
    axes[0, 0].set_ylim(min(accuracies) - 0.05, max(accuracies) + 0.02)
    
    # Add value labels
    for bar, acc in zip(bars, accuracies):
        axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                       f'{acc:.4f}', ha='center', va='bottom')
    
    # 2. å¤šæŒ‡æ ‡å¯¹æ¯”
    metrics = ['accuracy', 'precision', 'recall', 'f1_score']
    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    
    x = np.arange(len(models))
    width = 0.2
    
    for i, metric in enumerate(metrics):
        values = [results[m].get(metric, 0) for m in models]
        axes[0, 1].bar(x + i*width, values, width, label=metric_names[i], alpha=0.8)
    
    axes[0, 1].set_xlabel('Model')
    axes[0, 1].set_ylabel('Score')
    axes[0, 1].set_title('Multi-metric Performance Comparison')
    axes[0, 1].set_xticks(x + width * 1.5)
    axes[0, 1].set_xticklabels(model_names, rotation=0)
    axes[0, 1].legend()
    
    # 3. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    training_times = [results[m].get('training_time', 0) for m in models]
    
    bars = axes[1, 0].bar(model_names, training_times, color=['lightsteelblue', 'lightcoral', 'lightsalmon'])
    axes[1, 0].set_ylabel('Training Time (seconds)')
    axes[1, 0].set_title('Training Time Comparison')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, time_val in zip(bars, training_times):
        axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                       f'{time_val:.1f}s', ha='center', va='bottom')
    
    # 4. æ¶ˆèå®éªŒåˆ†æ
    categories = ['Baseline', 'Loc Only\n(Ablation)', 'Loc + Scale\n(Full)']
    values = [
        results['baseline']['accuracy'],
        results['ablation']['accuracy'],
        results['full_causal']['accuracy']
    ]
    
    axes[1, 1].plot(categories, values, 'o-', linewidth=2, markersize=10, color='darkgreen')
    axes[1, 1].fill_between(range(len(categories)), values, alpha=0.3, color='lightgreen')
    axes[1, 1].set_ylabel('Accuracy')
    axes[1, 1].set_title('Ablation Study: Impact of Causal Mechanism')
    axes[1, 1].grid(True, alpha=0.3)
    
    # æ ‡æ³¨å…³é”®ç‚¹
    for i, (cat, val) in enumerate(zip(categories, values)):
        axes[1, 1].annotate(f'{val:.4f}', (i, val), textcoords="offset points", 
                           xytext=(0,10), ha='center')
    
    plt.tight_layout()
    plt.savefig('tutorials/01_classification/adult_income_results.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("   å›¾è¡¨å·²ä¿å­˜: tutorials/01_classification/adult_income_results.png")


def main():
    """
    ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„Adult Incomeé¢„æµ‹æ•™ç¨‹
    """
    print("ğŸ¯ Adult Income é¢„æµ‹ - CausalEngineæ¶ˆèå®éªŒæ•™ç¨‹")
    print("æœ¬æ•™ç¨‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨CausalEngineè¿›è¡Œæ”¶å…¥é¢„æµ‹ï¼Œå¹¶é€šè¿‡æ¶ˆèå®éªŒéªŒè¯å…¶ä¼˜åŠ¿")
    print("=" * 80)
    
    # 1. æ•°æ®æ¢ç´¢
    data_dict = explore_adult_dataset()
    
    # 2. è¿è¡Œæ¶ˆèå®éªŒ
    results = run_ablation_experiment(data_dict)
    
    # 3. åˆ†æç»“æœ
    analyze_results(results)
    
    # 4. æ€»ç»“
    print("\nğŸ‰ Adult Income æ¶ˆèå®éªŒå®Œæˆï¼")
    print("\nğŸ” å…³é”®å‘ç°:")
    
    baseline_acc = results['baseline']['accuracy']
    ablation_acc = results['ablation']['accuracy']
    full_acc = results['full_causal']['accuracy']
    
    print(f"   1. ä¼ ç»Ÿç¥ç»ç½‘ç»œåŸºå‡†: {baseline_acc:.4f}")
    print(f"   2. CausalEngineä»…loc: {ablation_acc:.4f} (æ¶ˆèç‰ˆæœ¬)")
    print(f"   3. CausalEngineå®Œæ•´: {full_acc:.4f} (loc + scale)")
    
    if full_acc > baseline_acc:
        improvement = ((full_acc - baseline_acc) / baseline_acc) * 100
        print(f"\n   âœ… CausalEngineåœ¨Adultæ•°æ®é›†ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³• ({improvement:+.2f}%æå‡)")
        
        causal_gain = ((full_acc - ablation_acc) / ablation_acc) * 100
        print(f"   âœ… å› æœæœºåˆ¶(scale)è´¡çŒ®äº† {causal_gain:+.2f}% çš„æ€§èƒ½æå‡")
    else:
        print(f"\n   ğŸ“Š åœ¨æ­¤æ•°æ®é›†ä¸Šéœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
    
    print(f"\nğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ :")
    print(f"   1. å°è¯•å…¶ä»–åˆ†ç±»æ•°æ®é›†")
    print(f"   2. äº†è§£å›å½’ä»»åŠ¡ï¼štutorials/02_regression/")
    print(f"   3. è¿è¡Œå®Œæ•´è¯„ä¼°ï¼špython tutorials/03_ablation_studies/comprehensive_comparison.py")


if __name__ == "__main__":
    main() 