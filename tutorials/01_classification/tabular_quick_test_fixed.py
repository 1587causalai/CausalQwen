#!/usr/bin/env python3
"""
CausalEngine è¡¨æ ¼æ•°æ®å¿«é€Ÿæµ‹è¯• - ä¿®å¤ç‰ˆ

ä¿®å¤äº†å…³é”®é—®é¢˜ï¼šCausalEngine ä½¿ç”¨ OvR åˆ†ç±»ï¼Œéœ€è¦äºŒå…ƒäº¤å‰ç†µæŸå¤±ï¼
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ CausalEngine
import sys
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')
from causal_engine import CausalEngine, ActivationMode


class SimpleDataset(Dataset):
    def __init__(self, features, labels):
        self.features = torch.FloatTensor(features)
        self.labels = torch.LongTensor(labels)
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


class FixedCausalClassifier(nn.Module):
    """ä¿®å¤çš„ CausalEngine åˆ†ç±»å™¨ - æ­£ç¡®å¤„ç† OvR"""
    
    def __init__(self, input_size, num_classes):
        super().__init__()
        
        # æ ¹æ®è¾“å…¥å¤§å°è°ƒæ•´ç½‘ç»œæ·±åº¦
        if input_size <= 4:
            hidden_sizes = [32, 16]
        elif input_size <= 20:
            hidden_sizes = [64, 32]
        else:
            hidden_sizes = [128, 64, 32]
        
        # ç‰¹å¾ç¼–ç å™¨ - ç§»é™¤ BatchNorm é¿å…å°æ‰¹æ¬¡é—®é¢˜
        layers = []
        prev_size = input_size
        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.LayerNorm(hidden_size),  # ä½¿ç”¨ LayerNorm æ›¿ä»£ BatchNorm
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            prev_size = hidden_size
        
        self.encoder = nn.Sequential(*layers)
        
        # CausalEngine - æ³¨æ„è¿™é‡Œä½¿ç”¨ OvR åˆ†ç±»
        self.causal_engine = CausalEngine(
            hidden_size=prev_size,
            vocab_size=num_classes,
            activation_modes="classification",
            b_noise_init=0.1,
            gamma_init=1.0
        )
        
        self.num_classes = num_classes
    
    def forward(self, x, temperature=1.0):
        features = self.encoder(x)
        output = self.causal_engine(
            features.unsqueeze(1),
            temperature=temperature,
            do_sample=False,
            return_dict=True
        )
        # è¾“å‡ºå·²ç»æ˜¯æ¦‚ç‡äº†ï¼Œæ¯ä¸ªç±»åˆ«ç‹¬ç«‹çš„æ¦‚ç‡ [0, 1]
        return output['output'].squeeze(1)


def ovr_loss(probs, labels, num_classes):
    """
    One-vs-Rest æŸå¤±å‡½æ•°
    
    Args:
        probs: [batch_size, num_classes] æ¯ä¸ªç±»åˆ«çš„ç‹¬ç«‹æ¦‚ç‡
        labels: [batch_size] çœŸå®æ ‡ç­¾ (æ•´æ•°)
        num_classes: ç±»åˆ«æ•°
    
    Returns:
        loss: äºŒå…ƒäº¤å‰ç†µæŸå¤±
    """
    # å°†æ ‡ç­¾è½¬æ¢ä¸º one-hot ç¼–ç 
    targets = F.one_hot(labels, num_classes=num_classes).float()
    
    # è®¡ç®—äºŒå…ƒäº¤å‰ç†µæŸå¤±
    # æ³¨æ„ï¼šprobs å·²ç»æ˜¯æ¦‚ç‡ï¼Œä¸æ˜¯ logits
    loss = F.binary_cross_entropy(probs, targets, reduction='mean')
    
    return loss


def ovr_predict(probs):
    """
    OvR é¢„æµ‹ï¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«
    
    Args:
        probs: [batch_size, num_classes] æ¯ä¸ªç±»åˆ«çš„ç‹¬ç«‹æ¦‚ç‡
    
    Returns:
        predictions: [batch_size] é¢„æµ‹æ ‡ç­¾
    """
    return torch.argmax(probs, dim=1)


def load_datasets():
    """åŠ è½½å¤šä¸ªç»å…¸æ•°æ®é›†"""
    
    datasets_info = []
    
    # 1. Irisï¼ˆé¸¢å°¾èŠ±ï¼‰- 150æ ·æœ¬ï¼Œ4ç‰¹å¾ï¼Œ3ç±»
    print("\nğŸŒ¸ åŠ è½½ Iris æ•°æ®é›†...")
    iris = datasets.load_iris()
    datasets_info.append({
        'name': 'Iris',
        'X': iris.data,
        'y': iris.target,
        'num_classes': 3,
        'num_features': 4,
        'num_samples': len(iris.data)
    })
    
    # 2. Wineï¼ˆè‘¡è„é…’ï¼‰- 178æ ·æœ¬ï¼Œ13ç‰¹å¾ï¼Œ3ç±»
    print("ğŸ· åŠ è½½ Wine æ•°æ®é›†...")
    wine = datasets.load_wine()
    datasets_info.append({
        'name': 'Wine',
        'X': wine.data,
        'y': wine.target,
        'num_classes': 3,
        'num_features': 13,
        'num_samples': len(wine.data)
    })
    
    # 3. Breast Cancerï¼ˆä¹³è…ºç™Œï¼‰- 569æ ·æœ¬ï¼Œ30ç‰¹å¾ï¼Œ2ç±»
    print("ğŸ¥ åŠ è½½ Breast Cancer æ•°æ®é›†...")
    cancer = datasets.load_breast_cancer()
    datasets_info.append({
        'name': 'Breast Cancer',
        'X': cancer.data,
        'y': cancer.target,
        'num_classes': 2,
        'num_features': 30,
        'num_samples': len(cancer.data)
    })
    
    # 4. Digitsï¼ˆæ‰‹å†™æ•°å­—ç®€åŒ–ç‰ˆï¼‰- 1797æ ·æœ¬ï¼Œ64ç‰¹å¾ï¼Œ10ç±»
    print("ğŸ”¢ åŠ è½½ Digits æ•°æ®é›†...")
    digits = datasets.load_digits()
    # é‡‡æ ·500ä¸ªæ ·æœ¬ä»¥åŠ å¿«é€Ÿåº¦
    indices = np.random.choice(len(digits.data), 500, replace=False)
    datasets_info.append({
        'name': 'Digits (500)',
        'X': digits.data[indices],
        'y': digits.target[indices],
        'num_classes': 10,
        'num_features': 64,
        'num_samples': 500
    })
    
    # 5. ç”Ÿæˆä¸€ä¸ªåˆæˆæ•°æ®é›† - 1000æ ·æœ¬ï¼Œ20ç‰¹å¾ï¼Œ4ç±»
    print("ğŸ² ç”Ÿæˆåˆæˆæ•°æ®é›†...")
    X_synthetic, y_synthetic = datasets.make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=15,
        n_redundant=5,
        n_classes=4,
        n_clusters_per_class=2,
        random_state=42
    )
    datasets_info.append({
        'name': 'Synthetic',
        'X': X_synthetic,
        'y': y_synthetic,
        'num_classes': 4,
        'num_features': 20,
        'num_samples': 1000
    })
    
    return datasets_info


def train_causal_ovr(model, train_loader, val_loader, num_classes, epochs=50):
    """ä½¿ç”¨æ­£ç¡®çš„ OvR æŸå¤±è®­ç»ƒ CausalEngine"""
    
    # ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.5, patience=8
    )
    
    best_val_acc = 0
    patience = 15
    patience_counter = 0
    
    print(f"      ğŸ”§ ä½¿ç”¨ OvR äºŒå…ƒäº¤å‰ç†µæŸå¤±è®­ç»ƒ...")
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_loss = 0
        
        for features, labels in train_loader:
            optimizer.zero_grad()
            
            # åŠ¨æ€æ¸©åº¦è°ƒæ•´
            if epoch < epochs // 3:
                temperature = 1.2
            elif epoch < 2 * epochs // 3:
                temperature = 1.0
            else:
                temperature = 0.8
            
            # å‰å‘ä¼ æ’­
            probs = model(features, temperature=temperature)
            
            # å…³é”®ä¿®å¤ï¼šä½¿ç”¨ OvR æŸå¤±å‡½æ•°
            loss = ovr_loss(probs, labels, num_classes)
            
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            total_loss += loss.item()
        
        # éªŒè¯é˜¶æ®µ
        if epoch % 5 == 0 or epoch == epochs - 1:
            model.eval()
            correct = 0
            total = 0
            
            with torch.no_grad():
                for features, labels in val_loader:
                    probs = model(features, temperature=0.1)
                    predictions = ovr_predict(probs)  # ä½¿ç”¨ OvR é¢„æµ‹
                    total += labels.size(0)
                    correct += (predictions == labels).sum().item()
            
            val_acc = correct / total
            scheduler.step(val_acc)
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
            else:
                patience_counter += 1
            
            if epoch % 10 == 0:
                print(f"      Epoch {epoch:3d}: Loss={total_loss/len(train_loader):.4f}, Val_Acc={val_acc:.4f}")
            
            # æ—©åœ
            if patience_counter >= patience:
                print(f"      æå‰åœæ­¢åœ¨ç¬¬ {epoch} è½®ï¼Œæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
                break
    
    return best_val_acc


def evaluate_on_dataset(dataset_info):
    """åœ¨å•ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°"""
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š è¯„ä¼°æ•°æ®é›†: {dataset_info['name']}")
    print(f"   æ ·æœ¬æ•°: {dataset_info['num_samples']}")
    print(f"   ç‰¹å¾æ•°: {dataset_info['num_features']}")
    print(f"   ç±»åˆ«æ•°: {dataset_info['num_classes']}")
    print(f"{'='*50}")
    
    X = dataset_info['X']
    y = dataset_info['y']
    
    # æ•°æ®é¢„å¤„ç†
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # æ•°æ®åˆ’åˆ†
    X_temp, X_test, y_temp, y_test = train_test_split(
        X_scaled, y, test_size=0.25, random_state=42, stratify=y
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp
    )
    
    print(f"   è®­ç»ƒé›†: {len(X_train)}, éªŒè¯é›†: {len(X_val)}, æµ‹è¯•é›†: {len(X_test)}")
    
    results = {}
    
    # 1. ä¿®å¤åçš„ CausalEngine (OvR)
    print("\nğŸ”§ è®­ç»ƒä¿®å¤ç‰ˆ CausalEngine (OvR)...")
    
    # è°ƒæ•´æ‰¹æ¬¡å¤§å°
    batch_size = min(32, len(X_train) // 4) if len(X_train) > 32 else 8
    
    train_dataset = SimpleDataset(X_train, y_train)
    val_dataset = SimpleDataset(X_val, y_val)
    test_dataset = SimpleDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    causal_model = FixedCausalClassifier(X_train.shape[1], dataset_info['num_classes'])
    
    val_acc = train_causal_ovr(
        causal_model, train_loader, val_loader, 
        dataset_info['num_classes'], epochs=60
    )
    
    # æµ‹è¯•è¯„ä¼°
    causal_model.eval()
    predictions = []
    confidences = []
    
    with torch.no_grad():
        for features, _ in test_loader:
            probs = causal_model(features, temperature=0.1)
            preds = ovr_predict(probs)  # ä½¿ç”¨ OvR é¢„æµ‹
            max_probs = torch.max(probs, dim=1)[0]  # æœ€å¤§æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦
            
            predictions.extend(preds.numpy())
            confidences.extend(max_probs.numpy())
    
    causal_acc = accuracy_score(y_test, predictions)
    avg_confidence = np.mean(confidences)
    
    results['CausalEngine (OvR)'] = causal_acc
    print(f"   éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {causal_acc:.4f}")
    print(f"   å¹³å‡æœ€å¤§æ¦‚ç‡: {avg_confidence:.4f}")
    
    # 2. é€»è¾‘å›å½’
    print("\nğŸ“Š è®­ç»ƒé€»è¾‘å›å½’...")
    lr = LogisticRegression(random_state=42, max_iter=2000, C=1.0)
    lr.fit(X_train, y_train)
    lr_acc = lr.score(X_test, y_test)
    results['Logistic Regression'] = lr_acc
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {lr_acc:.4f}")
    
    # 3. éšæœºæ£®æ—
    print("\nğŸŒ² è®­ç»ƒéšæœºæ£®æ—...")
    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=1)
    rf.fit(X_train, y_train)
    rf_acc = rf.score(X_test, y_test)
    results['Random Forest'] = rf_acc
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {rf_acc:.4f}")
    
    # 4. SVM
    print("\nğŸ¯ è®­ç»ƒ SVM...")
    svm = SVC(random_state=42, C=1.0)
    svm.fit(X_train, y_train)
    svm_acc = svm.score(X_test, y_test)
    results['SVM'] = svm_acc
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {svm_acc:.4f}")
    
    return results


def visualize_results(all_results):
    """å¯è§†åŒ–ä¿®å¤åçš„ç»“æœ"""
    
    print("\nğŸ“ˆ ç”Ÿæˆä¿®å¤åç»“æœå¯è§†åŒ–...")
    
    plt.rcParams['font.family'] = 'DejaVu Sans'
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    axes = axes.ravel()
    
    datasets = list(all_results.keys())
    methods = ['CausalEngine (OvR)', 'Logistic Regression', 'Random Forest', 'SVM']
    
    # 1. å‡†ç¡®ç‡å¯¹æ¯”
    ax = axes[0]
    x = np.arange(len(datasets))
    width = 0.2
    
    for i, method in enumerate(methods):
        accuracies = [all_results[d][method] for d in datasets]
        offset = (i - 1.5) * width
        bars = ax.bar(x + offset, accuracies, width, label=method, alpha=0.8)
        
        if 'CausalEngine' in method:
            for bar in bars:
                bar.set_color('red')
                bar.set_alpha(0.9)
    
    ax.set_xlabel('Dataset')
    ax.set_ylabel('Accuracy')
    ax.set_title('Fixed CausalEngine (OvR) vs Traditional Methods')
    ax.set_xticks(x)
    ax.set_xticklabels(datasets, rotation=45)
    ax.legend()
    ax.grid(True, axis='y', alpha=0.3)
    
    # 2. ä¿®å¤å‰åå¯¹æ¯”
    ax = axes[1]
    
    # å‡è®¾çš„ä¿®å¤å‰æ€§èƒ½
    old_perfs = {
        'Iris': 0.8444,
        'Wine': 0.9630,
        'Breast Cancer': 0.9649,
        'Digits (500)': 0.8733,
        'Synthetic': 0.6967
    }
    
    improvements = []
    labels = []
    
    for dataset in datasets:
        if dataset in old_perfs:
            old = old_perfs[dataset]
            new = all_results[dataset]['CausalEngine (OvR)']
            improvement = (new - old) / old * 100
            improvements.append(improvement)
            labels.append(dataset)
    
    colors = ['green' if imp > 0 else 'red' for imp in improvements]
    bars = ax.bar(range(len(labels)), improvements, color=colors, alpha=0.7)
    ax.set_xticks(range(len(labels)))
    ax.set_xticklabels(labels, rotation=45)
    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
    ax.set_ylabel('Improvement (%)')
    ax.set_title('Performance Improvement After OvR Fix')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, imp in zip(bars, improvements):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, 
                height + (1 if height > 0 else -1),
                f'{imp:.1f}%', ha='center', 
                va='bottom' if height > 0 else 'top', weight='bold')
    
    # 3. æ–¹æ³•å¹³å‡æ€§èƒ½
    ax = axes[2]
    method_avg = {method: np.mean([all_results[d][method] for d in datasets]) 
                  for method in methods}
    
    bars = ax.bar(methods, method_avg.values(), alpha=0.7)
    bars[0].set_color('red')  # CausalEngine
    
    ax.set_ylabel('Average Accuracy')
    ax.set_title('Average Performance - Fixed Version')
    ax.tick_params(axis='x', rotation=45)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, (method, acc) in zip(bars, method_avg.items()):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{acc:.3f}', ha='center', va='bottom', weight='bold')
    
    # 4. æ’ååˆ†æ
    ax = axes[3]
    causal_ranks = []
    
    for dataset in datasets:
        results_list = [(method, acc) for method, acc in all_results[dataset].items()]
        results_list.sort(key=lambda x: x[1], reverse=True)
        rank = next(i for i, (m, _) in enumerate(results_list) if 'CausalEngine' in m) + 1
        causal_ranks.append(rank)
    
    bars = ax.bar(range(len(datasets)), causal_ranks, alpha=0.7)
    ax.set_xticks(range(len(datasets)))
    ax.set_xticklabels(datasets, rotation=45)
    ax.set_ylabel('Rank (1=Best)')
    ax.set_title('CausalEngine (OvR) Ranking per Dataset')
    ax.set_ylim(0.5, 4.5)
    ax.invert_yaxis()
    
    # æ·»åŠ é¢œè‰²ç¼–ç 
    for i, (bar, rank) in enumerate(zip(bars, causal_ranks)):
        ax.text(bar.get_x() + bar.get_width()/2, rank,
                str(rank), ha='center', va='center', weight='bold')
        
        if rank == 1:
            bar.set_color('gold')
        elif rank == 2:
            bar.set_color('silver')
        elif rank == 3:
            bar.set_color('#CD7F32')
        else:
            bar.set_color('gray')
    
    # 5. é—®é¢˜ä¿®å¤æ€»ç»“
    ax = axes[4]
    wins = sum(1 for rank in causal_ranks if rank == 1)
    top2 = sum(1 for rank in causal_ranks if rank <= 2)
    
    ax.text(0.5, 0.7, 'ğŸ”§ å…³é”®ä¿®å¤:', ha='center', fontsize=14, weight='bold')
    ax.text(0.5, 0.6, 'âœ… ä½¿ç”¨ OvR äºŒå…ƒäº¤å‰ç†µæŸå¤±', ha='center', fontsize=11)
    ax.text(0.5, 0.55, 'âœ… æ­£ç¡®çš„ OvR é¢„æµ‹æ–¹æ³•', ha='center', fontsize=11)
    ax.text(0.5, 0.5, 'âœ… ä¸å†ä½¿ç”¨é”™è¯¯çš„ softmax', ha='center', fontsize=11)
    
    ax.text(0.5, 0.35, f'ğŸ“Š ä¿®å¤åæ•ˆæœ:', ha='center', fontsize=14, weight='bold')
    ax.text(0.5, 0.25, f'è·èƒœæ¬¡æ•°: {wins}/{len(datasets)}', ha='center', fontsize=12)
    ax.text(0.5, 0.2, f'å‰äºŒåæ¬¡æ•°: {top2}/{len(datasets)}', ha='center', fontsize=12)
    ax.text(0.5, 0.15, f'å¹³å‡æ’å: {np.mean(causal_ranks):.1f}/4', ha='center', fontsize=12)
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')
    ax.set_title('OvR Fix Impact Summary')
    
    # 6. ä¿®å¤å‰åå¯¹æ¯”è¡¨
    ax = axes[5]
    ax.text(0.5, 0.9, 'Before vs After Fix', ha='center', fontsize=14, weight='bold')
    
    table_data = []
    headers = ['Dataset', 'Before', 'After', 'Î”%']
    
    for dataset in datasets:
        if dataset in old_perfs:
            old = old_perfs[dataset]
            new = all_results[dataset]['CausalEngine (OvR)']
            delta = (new - old) / old * 100
            table_data.append([dataset, f'{old:.3f}', f'{new:.3f}', f'{delta:+.1f}%'])
    
    table = ax.table(cellText=table_data, colLabels=headers,
                     cellLoc='center', loc='center', bbox=[0, 0.2, 1, 0.6])
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1, 1.5)
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')
    
    plt.tight_layout()
    plt.savefig('tabular_quick_test_fixed_results.png', dpi=150, bbox_inches='tight')
    print("   ä¿®å¤ç»“æœå·²ä¿å­˜åˆ° tabular_quick_test_fixed_results.png")
    plt.close()


def print_summary(all_results):
    """æ‰“å°ä¿®å¤åçš„æ€»ç»“"""
    
    print("\n" + "="*60)
    print("ğŸ“Š ä¿®å¤ç‰ˆæµ‹è¯•æ€»ç»“ - æ­£ç¡®çš„ OvR æŸå¤±å‡½æ•°")
    print("="*60)
    
    methods = ['CausalEngine (OvR)', 'Logistic Regression', 'Random Forest', 'SVM']
    method_wins = {m: 0 for m in methods}
    
    for dataset, results in all_results.items():
        best_method = max(results.items(), key=lambda x: x[1])[0]
        method_wins[best_method] += 1
        
        print(f"\n{dataset}:")
        sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
        for i, (method, acc) in enumerate(sorted_results):
            if i == 0:
                marker = "ğŸ¥‡"
            elif i == 1:
                marker = "ğŸ¥ˆ" 
            elif i == 2:
                marker = "ğŸ¥‰"
            else:
                marker = "  "
            
            if 'CausalEngine' in method:
                print(f"  {marker} {method:20s}: {acc:.4f} â­")
            else:
                print(f"  {marker} {method:20s}: {acc:.4f}")
    
    print("\nğŸ† è·èƒœç»Ÿè®¡:")
    for method, wins in sorted(method_wins.items(), key=lambda x: x[1], reverse=True):
        print(f"   {method}: {wins} æ¬¡")
    
    # CausalEngine è¯¦ç»†åˆ†æ
    print("\nğŸ” CausalEngine ä¿®å¤æ•ˆæœåˆ†æ:")
    causal_ranks = []
    causal_accs = []
    
    for dataset, results in all_results.items():
        sorted_methods = sorted(results.items(), key=lambda x: x[1], reverse=True)
        rank = next(i for i, (m, _) in enumerate(sorted_methods) if 'CausalEngine' in m) + 1
        causal_ranks.append(rank)
        causal_accs.append(results['CausalEngine (OvR)'])
    
    wins = sum(1 for rank in causal_ranks if rank == 1)
    top2 = sum(1 for rank in causal_ranks if rank <= 2)
    
    print(f"   å¹³å‡æ’å: {np.mean(causal_ranks):.1f}/4 (ä¿®å¤å‰: 3.6)")
    print(f"   è·èƒœæ¬¡æ•°: {wins}/{len(causal_ranks)} (ä¿®å¤å‰: 0)")
    print(f"   å‰äºŒåæ¬¡æ•°: {top2}/{len(causal_ranks)}")
    print(f"   å¹³å‡å‡†ç¡®ç‡: {np.mean(causal_accs):.4f}")
    
    print("\nğŸ”§ å…³é”®ä¿®å¤å†…å®¹:")
    print("   âœ… ä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤± (BCE) æ›¿ä»£äº¤å‰ç†µ")
    print("   âœ… æ­£ç¡®å¤„ç† OvR è¾“å‡ºæ ¼å¼")
    print("   âœ… ä½¿ç”¨ argmax è€Œé softmax")
    print("   âœ… å°†æ ‡ç­¾è½¬æ¢ä¸º one-hot ç¼–ç ")
    print("   âœ… ç†è§£æ¯ä¸ªç±»åˆ«ç‹¬ç«‹æ¦‚ç‡çš„å«ä¹‰")


def main():
    """ä¸»å‡½æ•°"""
    
    print("="*60)
    print("ğŸš€ CausalEngine è¡¨æ ¼æ•°æ®å¿«é€Ÿæµ‹è¯• - ä¿®å¤ç‰ˆ")
    print("   ä¿®å¤å…³é”®é—®é¢˜ï¼šä½¿ç”¨æ­£ç¡®çš„ OvR æŸå¤±å‡½æ•°ï¼")
    print("="*60)
    
    print("\nğŸ”§ å…³é”®ä¿®å¤:")
    print("   â€¢ CausalEngine ä½¿ç”¨ OvR (One-vs-Rest) åˆ†ç±»")
    print("   â€¢ æ¯ä¸ªç±»åˆ«è¾“å‡ºç‹¬ç«‹æ¦‚ç‡ï¼Œä¸ä½¿ç”¨ softmax")
    print("   â€¢ æŸå¤±å‡½æ•°ï¼šäºŒå…ƒäº¤å‰ç†µ (BCE) è€Œéäº¤å‰ç†µ")
    print("   â€¢ é¢„æµ‹æ–¹æ³•ï¼šargmax é€‰æ‹©æœ€å¤§æ¦‚ç‡ç±»åˆ«")
    
    # åŠ è½½æ•°æ®é›†
    datasets_info = load_datasets()
    
    # åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°
    all_results = {}
    
    for dataset_info in datasets_info:
        results = evaluate_on_dataset(dataset_info)
        all_results[dataset_info['name']] = results
    
    # å¯è§†åŒ–
    visualize_results(all_results)
    
    # æ‰“å°æ€»ç»“
    print_summary(all_results)
    
    print("\nâœ… ä¿®å¤ç‰ˆæµ‹è¯•å®Œæˆï¼")
    print("ğŸ“Š è¯·æŸ¥çœ‹ tabular_quick_test_fixed_results.png")
    print("\nğŸ’¡ å¦‚æœæ•ˆæœæ˜¾è‘—æ”¹å–„ï¼Œè¯´æ˜ä¹‹å‰çš„é—®é¢˜ç¡®å®æ˜¯æŸå¤±å‡½æ•°é”™è¯¯ï¼")


if __name__ == "__main__":
    main() 