#!/usr/bin/env python3
"""
Deep MLP + CausalEngine æ€§èƒ½åˆ†æ

ä¸“é—¨åˆ†æä¸ºä»€ä¹ˆ Deep MLP + CausalEngine ä»ç„¶ä¸å¦‚ Deep MLP + Softmax
å¯èƒ½çš„åŸå› å’Œæ”¹è¿›æ–¹æ³•
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ CausalEngine
import sys
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')
from causal_engine import CausalEngine, ActivationMode


class DigitsDataset(Dataset):
    def __init__(self, features, labels):
        self.features = torch.FloatTensor(features)
        self.labels = torch.LongTensor(labels)
    
    def __len__(self):
        return len(self.features)
    
    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


class DeepFeatureExtractor(nn.Module):
    """æ·±å±‚ç‰¹å¾æå–å™¨"""
    
    def __init__(self, input_size=64, hidden_size=128):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),
            
            nn.Linear(hidden_size, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1),
            
            nn.Linear(hidden_size, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
    
    def forward(self, x):
        return self.net(x)


class SoftmaxClassifier(nn.Module):
    """Deep MLP + Softmax"""
    
    def __init__(self, hidden_size=128, num_classes=10):
        super().__init__()
        self.feature_extractor = DeepFeatureExtractor(hidden_size=hidden_size)
        self.classifier = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        features = self.feature_extractor(x)
        return self.classifier(features)


class CausalEngineClassifier(nn.Module):
    """Deep MLP + CausalEngine"""
    
    def __init__(self, hidden_size=128, num_classes=10, b_noise_init=0.05, gamma_init=1.0):
        super().__init__()
        self.feature_extractor = DeepFeatureExtractor(hidden_size=hidden_size)
        self.causal_engine = CausalEngine(
            hidden_size=hidden_size,
            vocab_size=num_classes,
            activation_modes="classification",
            b_noise_init=b_noise_init,
            gamma_init=gamma_init
        )
    
    def forward(self, x, temperature=1.0, do_sample=False, return_details=False):
        features = self.feature_extractor(x)
        output = self.causal_engine(
            features.unsqueeze(1),
            temperature=temperature,
            do_sample=do_sample,
            return_dict=True
        )
        
        if return_details:
            return output
        else:
            return output['output'].squeeze(1)


def prepare_data():
    """å‡†å¤‡æ•°æ®"""
    digits = load_digits()
    X, y = digits.data, digits.target
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    X_temp, X_test, y_temp, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, stratify=y
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
    )
    
    train_dataset = DigitsDataset(X_train, y_train)
    val_dataset = DigitsDataset(X_val, y_val)
    test_dataset = DigitsDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    return train_loader, val_loader, test_loader


def train_softmax_model(model, train_loader, val_loader, max_epochs=100, lr=0.001):
    """è®­ç»ƒ Softmax æ¨¡å‹"""
    print("ğŸš€ è®­ç»ƒ Deep MLP + Softmax...")
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    
    train_losses = []
    val_accuracies = []
    best_val_acc = 0
    patience = 10
    patience_counter = 0
    best_model_state = None
    
    for epoch in range(max_epochs):
        # è®­ç»ƒ
        model.train()
        epoch_loss = 0
        for features, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        
        # éªŒè¯
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for features, labels in val_loader:
                outputs = model(features)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        val_acc = correct / total
        train_losses.append(epoch_loss / len(train_loader))
        val_accuracies.append(val_acc)
        
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
        
        if patience_counter >= patience:
            break
    
    model.load_state_dict(best_model_state)
    print(f"âœ… Softmaxè®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
    
    return train_losses, val_accuracies


def train_causal_model(model, train_loader, val_loader, max_epochs=100, lr=0.001):
    """è®­ç»ƒ CausalEngine æ¨¡å‹"""
    print("ğŸš€ è®­ç»ƒ Deep MLP + CausalEngine...")
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    
    train_losses = []
    val_accuracies = []
    best_val_acc = 0
    patience = 10
    patience_counter = 0
    best_model_state = None
    
    for epoch in range(max_epochs):
        # è®­ç»ƒ
        model.train()
        epoch_loss = 0
        for features, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(features, temperature=1.0, do_sample=False)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        
        # éªŒè¯
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for features, labels in val_loader:
                outputs = model(features, temperature=0.0)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        val_acc = correct / total
        train_losses.append(epoch_loss / len(train_loader))
        val_accuracies.append(val_acc)
        
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
        
        if patience_counter >= patience:
            break
    
    model.load_state_dict(best_model_state)
    print(f"âœ… CausalEngineè®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
    
    return train_losses, val_accuracies


def analyze_performance_gap(softmax_model, causal_model, test_loader):
    """åˆ†ææ€§èƒ½å·®è·çš„åŸå› """
    
    print("\nğŸ” åˆ†ææ€§èƒ½å·®è·...")
    
    # æµ‹è¯•ä¸¤ä¸ªæ¨¡å‹
    results = {}
    
    for name, model in [("Softmax", softmax_model), ("CausalEngine", causal_model)]:
        model.eval()
        predictions = []
        confidences = []
        uncertainties = []
        probabilities = []
        true_labels = []
        
        with torch.no_grad():
            for features, labels in test_loader:
                if name == "Softmax":
                    outputs = model(features)
                    probs = torch.softmax(outputs, dim=1)
                    max_probs, predicted = torch.max(probs, 1)
                    
                    predictions.extend(predicted.numpy())
                    confidences.extend(max_probs.numpy())
                    uncertainties.extend([0.0] * len(labels))  # Softmaxæ²¡æœ‰ä¸ç¡®å®šæ€§
                    probabilities.append(probs.numpy())
                    
                else:  # CausalEngine
                    output = model(features, temperature=0.0, return_details=True)
                    probs = output['output'].squeeze(1)
                    max_probs, predicted = torch.max(probs, 1)
                    
                    predictions.extend(predicted.numpy())
                    confidences.extend(max_probs.numpy())
                    
                    # CausalEngineçš„ä¸ç¡®å®šæ€§
                    scale_S = output['scale_S'].squeeze(1)
                    avg_uncertainty = scale_S.mean(dim=1)
                    uncertainties.extend(avg_uncertainty.numpy())
                    probabilities.append(probs.numpy())
                
                true_labels.extend(labels.numpy())
        
        predictions = np.array(predictions)
        true_labels = np.array(true_labels)
        confidences = np.array(confidences)
        uncertainties = np.array(uncertainties)
        probabilities = np.vstack(probabilities)
        
        accuracy = accuracy_score(true_labels, predictions)
        
        results[name] = {
            'accuracy': accuracy,
            'predictions': predictions,
            'true_labels': true_labels,
            'confidences': confidences,
            'uncertainties': uncertainties,
            'probabilities': probabilities
        }
        
        print(f"   {name} æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f}")
    
    return results


def detailed_error_analysis(results):
    """è¯¦ç»†çš„é”™è¯¯åˆ†æ"""
    
    print("\nğŸ“Š è¯¦ç»†é”™è¯¯åˆ†æ...")
    
    softmax_result = results['Softmax']
    causal_result = results['CausalEngine']
    
    # 1. æ‰¾å‡ºä¸¤è€…é¢„æµ‹ä¸åŒçš„æ ·æœ¬
    different_predictions = (softmax_result['predictions'] != causal_result['predictions'])
    
    print(f"   é¢„æµ‹ä¸åŒçš„æ ·æœ¬æ•°: {different_predictions.sum()}/{len(different_predictions)}")
    
    if different_predictions.sum() > 0:
        # åœ¨é¢„æµ‹ä¸åŒçš„æ ·æœ¬ä¸­ï¼Œè°æ›´å‡†ç¡®ï¼Ÿ
        true_labels = softmax_result['true_labels'][different_predictions]
        softmax_preds = softmax_result['predictions'][different_predictions]
        causal_preds = causal_result['predictions'][different_predictions]
        
        softmax_correct = (softmax_preds == true_labels).sum()
        causal_correct = (causal_preds == true_labels).sum()
        
        print(f"   åœ¨åˆ†æ­§æ ·æœ¬ä¸­:")
        print(f"      Softmaxæ­£ç¡®: {softmax_correct}/{len(true_labels)} ({softmax_correct/len(true_labels):.3f})")
        print(f"      CausalEngineæ­£ç¡®: {causal_correct}/{len(true_labels)} ({causal_correct/len(true_labels):.3f})")
    
    # 2. ç½®ä¿¡åº¦åˆ†æ
    softmax_correct = (softmax_result['predictions'] == softmax_result['true_labels'])
    causal_correct = (causal_result['predictions'] == causal_result['true_labels'])
    
    print(f"\n   ç½®ä¿¡åº¦åˆ†æ:")
    print(f"      Softmax - æ­£ç¡®é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {softmax_result['confidences'][softmax_correct].mean():.4f}")
    print(f"      Softmax - é”™è¯¯é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {softmax_result['confidences'][~softmax_correct].mean():.4f}")
    print(f"      CausalEngine - æ­£ç¡®é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {causal_result['confidences'][causal_correct].mean():.4f}")
    print(f"      CausalEngine - é”™è¯¯é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {causal_result['confidences'][~causal_correct].mean():.4f}")
    
    # 3. ä¸ç¡®å®šæ€§åˆ†æï¼ˆä»…CausalEngineï¼‰
    if causal_result['uncertainties'].max() > 0:
        print(f"\n   CausalEngineä¸ç¡®å®šæ€§åˆ†æ:")
        print(f"      æ­£ç¡®é¢„æµ‹å¹³å‡ä¸ç¡®å®šæ€§: {causal_result['uncertainties'][causal_correct].mean():.4f}")
        print(f"      é”™è¯¯é¢„æµ‹å¹³å‡ä¸ç¡®å®šæ€§: {causal_result['uncertainties'][~causal_correct].mean():.4f}")


def hyperparameter_tuning_experiment():
    """è¶…å‚æ•°è°ƒä¼˜å®éªŒ"""
    
    print("\nğŸ”§ è¶…å‚æ•°è°ƒä¼˜å®éªŒ...")
    
    train_loader, val_loader, test_loader = prepare_data()
    
    # æµ‹è¯•ä¸åŒçš„ b_noise_init å’Œ gamma_init
    noise_values = [0.01, 0.05, 0.1, 0.2]
    gamma_values = [0.5, 1.0, 2.0]
    learning_rates = [0.0005, 0.001, 0.002]
    
    best_accuracy = 0
    best_params = {}
    
    results_grid = []
    
    print("   æµ‹è¯•ä¸åŒå™ªå£°åˆå§‹åŒ–å€¼...")
    for b_noise in noise_values:
        model = CausalEngineClassifier(hidden_size=128, num_classes=10, 
                                     b_noise_init=b_noise, gamma_init=1.0)
        train_causal_model(model, train_loader, val_loader, max_epochs=60, lr=0.001)
        
        # æµ‹è¯•
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for features, labels in test_loader:
                outputs = model(features, temperature=0.0)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = correct / total
        results_grid.append({
            'b_noise': b_noise,
            'gamma': 1.0,
            'lr': 0.001,
            'accuracy': accuracy
        })
        
        print(f"      b_noise={b_noise}: {accuracy:.4f}")
        
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_params = {'b_noise': b_noise, 'gamma': 1.0, 'lr': 0.001}
    
    print(f"\n   æœ€ä½³å‚æ•°: {best_params}")
    print(f"   æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}")
    
    return results_grid, best_params


def visualize_analysis(results, softmax_history, causal_history):
    """å¯è§†åŒ–åˆ†æç»“æœ"""
    
    print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–åˆ†æ...")
    
    plt.rcParams['font.family'] = 'DejaVu Sans'
    fig = plt.figure(figsize=(16, 10))
    
    # 1. è®­ç»ƒæ›²çº¿å¯¹æ¯”
    ax1 = plt.subplot(2, 3, 1)
    softmax_losses, softmax_accs = softmax_history
    causal_losses, causal_accs = causal_history
    
    ax1.plot(softmax_losses, label='Softmax Loss', color='blue')
    ax1.plot(causal_losses, label='CausalEngine Loss', color='red')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Training Loss')
    ax1.set_title('Training Loss Comparison')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”
    ax2 = plt.subplot(2, 3, 2)
    ax2.plot(softmax_accs, label='Softmax', color='blue')
    ax2.plot(causal_accs, label='CausalEngine', color='red')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Validation Accuracy')
    ax2.set_title('Validation Accuracy Comparison')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. æ··æ·†çŸ©é˜µå¯¹æ¯”
    softmax_cm = confusion_matrix(results['Softmax']['true_labels'], 
                                  results['Softmax']['predictions'])
    causal_cm = confusion_matrix(results['CausalEngine']['true_labels'], 
                                results['CausalEngine']['predictions'])
    
    ax3 = plt.subplot(2, 3, 3)
    sns.heatmap(softmax_cm, annot=True, fmt='d', cmap='Blues', ax=ax3, cbar=False)
    ax3.set_title('Softmax Confusion Matrix')
    ax3.set_xlabel('Predicted')
    ax3.set_ylabel('True')
    
    ax4 = plt.subplot(2, 3, 4)
    sns.heatmap(causal_cm, annot=True, fmt='d', cmap='Reds', ax=ax4, cbar=False)
    ax4.set_title('CausalEngine Confusion Matrix')
    ax4.set_xlabel('Predicted')
    ax4.set_ylabel('True')
    
    # 4. ç½®ä¿¡åº¦åˆ†å¸ƒå¯¹æ¯”
    ax5 = plt.subplot(2, 3, 5)
    
    softmax_correct = (results['Softmax']['predictions'] == results['Softmax']['true_labels'])
    causal_correct = (results['CausalEngine']['predictions'] == results['CausalEngine']['true_labels'])
    
    ax5.hist(results['Softmax']['confidences'][softmax_correct], bins=30, alpha=0.6, 
             label='Softmax Correct', color='blue', density=True)
    ax5.hist(results['Softmax']['confidences'][~softmax_correct], bins=30, alpha=0.6, 
             label='Softmax Incorrect', color='lightblue', density=True)
    ax5.hist(results['CausalEngine']['confidences'][causal_correct], bins=30, alpha=0.6, 
             label='CausalEngine Correct', color='red', density=True)
    ax5.hist(results['CausalEngine']['confidences'][~causal_correct], bins=30, alpha=0.6, 
             label='CausalEngine Incorrect', color='pink', density=True)
    
    ax5.set_xlabel('Confidence')
    ax5.set_ylabel('Density')
    ax5.set_title('Confidence Distribution')
    ax5.legend()
    
    # 5. ä¸ç¡®å®šæ€§åˆ†æï¼ˆä»…CausalEngineï¼‰
    ax6 = plt.subplot(2, 3, 6)
    
    if results['CausalEngine']['uncertainties'].max() > 0:
        ax6.hist(results['CausalEngine']['uncertainties'][causal_correct], bins=30, alpha=0.6, 
                 label='Correct', color='green', density=True)
        ax6.hist(results['CausalEngine']['uncertainties'][~causal_correct], bins=30, alpha=0.6, 
                 label='Incorrect', color='red', density=True)
        ax6.set_xlabel('Uncertainty')
        ax6.set_ylabel('Density')
        ax6.set_title('CausalEngine Uncertainty Distribution')
        ax6.legend()
    else:
        ax6.text(0.5, 0.5, 'No Uncertainty\nData Available', 
                ha='center', va='center', transform=ax6.transAxes)
    
    plt.tight_layout()
    plt.savefig('deep_causal_analysis.png', dpi=150, bbox_inches='tight')
    print("   åˆ†æç»“æœå·²ä¿å­˜åˆ° deep_causal_analysis.png")
    plt.close()


def main():
    """ä¸»å‡½æ•°"""
    
    print("="*70)
    print("ğŸ” Deep MLP + CausalEngine æ€§èƒ½åˆ†æ")
    print("   ç³»ç»Ÿåˆ†æä¸ºä»€ä¹ˆCausalEngineä¸å¦‚Softmax")
    print("="*70)
    
    # 1. å‡†å¤‡æ•°æ®
    train_loader, val_loader, test_loader = prepare_data()
    
    # 2. è®­ç»ƒä¸¤ä¸ªæ¨¡å‹
    print("\nğŸ‹ï¸â€â™‚ï¸ è®­ç»ƒæ¨¡å‹å¯¹æ¯”...")
    
    # Softmaxæ¨¡å‹
    softmax_model = SoftmaxClassifier(hidden_size=128, num_classes=10)
    softmax_history = train_softmax_model(softmax_model, train_loader, val_loader)
    
    # CausalEngineæ¨¡å‹
    causal_model = CausalEngineClassifier(hidden_size=128, num_classes=10)
    causal_history = train_causal_model(causal_model, train_loader, val_loader)
    
    # 3. æ€§èƒ½åˆ†æ
    results = analyze_performance_gap(softmax_model, causal_model, test_loader)
    
    # 4. è¯¦ç»†é”™è¯¯åˆ†æ
    detailed_error_analysis(results)
    
    # 5. è¶…å‚æ•°è°ƒä¼˜
    tuning_results, best_params = hyperparameter_tuning_experiment()
    
    # 6. å¯è§†åŒ–
    visualize_analysis(results, softmax_history, causal_history)
    
    # 7. æ€»ç»“
    print("\nğŸ’¡ å…³é”®å‘ç°:")
    print("-" * 50)
    softmax_acc = results['Softmax']['accuracy']
    causal_acc = results['CausalEngine']['accuracy']
    gap = softmax_acc - causal_acc
    
    print(f"ğŸ“Š æ€§èƒ½å·®è·: {gap:.4f} ({gap/softmax_acc*100:.1f}%)")
    print(f"   Softmax:     {softmax_acc:.4f}")
    print(f"   CausalEngine: {causal_acc:.4f}")
    
    print(f"\nğŸ”§ è¶…å‚æ•°è°ƒä¼˜åæœ€ä½³CausalEngineå‡†ç¡®ç‡: {tuning_results[-1]['accuracy']:.4f}")
    
    if gap > 0.01:  # å¦‚æœå·®è·è¶…è¿‡1%
        print(f"\nğŸ¯ å¯èƒ½çš„æ”¹è¿›æ–¹å‘:")
        print(f"1. è¿›ä¸€æ­¥è°ƒä¼˜CausalEngineçš„è¶…å‚æ•°")
        print(f"2. ä½¿ç”¨ä¸åŒçš„æŸå¤±å‡½æ•°")
        print(f"3. è°ƒæ•´æ¸©åº¦å‚æ•°")
        print(f"4. è€ƒè™‘æ˜¯å¦çœŸçš„éœ€è¦ä¸ç¡®å®šæ€§å»ºæ¨¡")
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print("ğŸ“Š è¯·æŸ¥çœ‹ deep_causal_analysis.png äº†è§£è¯¦ç»†åˆ†æ")


if __name__ == "__main__":
    main() 