"""
CausalEngine 任务激活机制详解
============================

基于最新数学理论深入解析三种任务激活机制的设计原理和实现细节
探讨如何扩展CausalEngine到新的任务类型和应用场景

三种激活机制:
1. 词元索引激活 (分类任务): P_k = P(S_k > C_k) - OvR策略的独立概率
2. 数值激活 (回归任务): Y_k ~ Cauchy(w_k·loc_S + b_k, |w_k|·scale_S)
3. 离散有序激活 (有序分类): P(y_i) = P(C_i < S_k ≤ C_{i+1})

核心创新: 统一的决策得分→任务输出的映射框架，支持任意任务类型扩展
"""

import sys
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# 添加路径
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

from causal_engine import CausalEngine


class TaskActivationAnalyzer:
    """
    任务激活机制分析器 - 深度分析三种激活机制的特性和扩展性
    """
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # 创建不同任务类型的CausalEngine实例
        self.engines = {
            'classification': CausalEngine(
                hidden_size=64,
                vocab_size=5,  # 5类分类
                causal_size=32,
                activation_modes="classification"
            ),
            'regression': CausalEngine(
                hidden_size=64,
                vocab_size=3,  # 3个回归目标
                causal_size=32,
                activation_modes="regression"
            ),
            'ordinal': CausalEngine(
                hidden_size=64,
                vocab_size=1,  # 1个有序分类目标
                causal_size=32,
                activation_modes="ordinal"
            )
        }
    
    def demonstrate_mathematical_foundations(self):
        """
        演示三种激活机制的数学基础
        """
        print("🔬 任务激活机制的数学基础")
        print("=" * 60)
        
        print("\\n📐 核心数学框架:")
        print("  决策得分: S_k ~ Cauchy(loc_k, scale_k)")
        print("  激活函数: f_k(s_k) → 任务特定输出")
        print("  关键创新: 直接用随机变量预测，而非统计量")
        
        # 创建示例决策得分
        batch_size = 8\n        num_decisions = 5\n        \n        # 模拟决策得分分布参数\n        loc_S = torch.randn(batch_size, num_decisions) * 2\n        scale_S = torch.abs(torch.randn(batch_size, num_decisions)) + 0.1\n        \n        print(f\"\\n🎲 示例决策得分分布:\")\n        print(f\"  批次大小: {batch_size}\")\n        print(f\"  决策维度: {num_decisions}\")\n        print(f\"  位置参数范围: [{loc_S.min():.3f}, {loc_S.max():.3f}]\")\n        print(f\"  尺度参数范围: [{scale_S.min():.3f}, {scale_S.max():.3f}]\")\n        \n        # 分析三种激活机制\n        self._analyze_classification_activation(loc_S, scale_S)\n        self._analyze_regression_activation(loc_S, scale_S)\n        self._analyze_ordinal_activation(loc_S, scale_S)\n    \n    def _analyze_classification_activation(self, loc_S, scale_S):\n        \"\"\"\n        分析词元索引激活 (分类任务)\n        \"\"\"\n        print(f\"\\n🎯 激活机制1: 词元索引激活 (分类任务)\")\n        print(f\"  数学公式: f_k(s_k) = I(s_k > C_k)\")\n        print(f\"  概率计算: P_k = 1/2 + arctan((loc_k - C_k)/scale_k)/π\")\n        \n        # 设置分类阈值\n        C_k = torch.zeros_like(loc_S)  # 使用0作为阈值\n        \n        # 计算分类概率 (解析方式)\n        def cauchy_cdf_complement(loc, scale, threshold):\n            \"\"\"计算柯西分布的互补累积分布函数\"\"\"\n            return 0.5 + torch.atan((loc - threshold) / scale) / np.pi\n        \n        probs = cauchy_cdf_complement(loc_S, scale_S, C_k)\n        \n        print(f\"  激活概率范围: [{probs.min():.3f}, {probs.max():.3f}]\")\n        print(f\"  平均激活概率: {probs.mean():.3f}\")\n        \n        # OvR决策策略\n        predictions = torch.argmax(probs, dim=1)\n        print(f\"  OvR决策结果: {predictions.tolist()}\")\n        \n        print(f\"\\n  💡 关键特性:\")\n        print(f\"    ✨ 独立概率: 每个类别有独立的激活概率\")\n        print(f\"    ✨ 非归一化: 不受softmax归一化约束\")\n        print(f\"    ✨ 可解释性: 直观的阈值比较机制\")\n        print(f\"    ✨ 灵活性: 支持多标签和层次分类\")\n        \n        return probs\n    \n    def _analyze_regression_activation(self, loc_S, scale_S):\n        \"\"\"\n        分析数值激活 (回归任务)\n        \"\"\"\n        print(f\"\\n📈 激活机制2: 数值激活 (回归任务)\")\n        print(f\"  数学公式: f_k(s_k) = w_k·s_k + b_k\")\n        print(f\"  分布变换: Y_k ~ Cauchy(w_k·loc_k + b_k, |w_k|·scale_k)\")\n        \n        # 设置回归参数\n        w_k = torch.ones_like(loc_S)  # 权重\n        b_k = torch.zeros_like(loc_S)  # 偏置\n        \n        # 计算输出分布参数\n        output_loc = w_k * loc_S + b_k\n        output_scale = torch.abs(w_k) * scale_S\n        \n        # 获取点估计 (位置参数)\n        predictions = output_loc\n        \n        print(f\"  输出位置参数范围: [{output_loc.min():.3f}, {output_loc.max():.3f}]\")\n        print(f\"  输出尺度参数范围: [{output_scale.min():.3f}, {output_scale.max():.3f}]\")\n        print(f\"  点估计 (位置): {predictions.mean():.3f} ± {predictions.std():.3f}\")\n        \n        print(f\"\\n  💡 关键特性:\")\n        print(f\"    ✨ 完整分布: 保留输出的完整概率分布\")\n        print(f\"    ✨ 不确定性量化: 尺度参数表示预测不确定性\")\n        print(f\"    ✨ 线性稳定性: 柯西分布的线性变换仍为柯西分布\")\n        print(f\"    ✨ 解析计算: 无需采样的高效计算\")\n        \n        return output_loc, output_scale\n    \n    def _analyze_ordinal_activation(self, loc_S, scale_S):\n        \"\"\"\n        分析离散有序激活 (有序分类)\n        \"\"\"\n        print(f\"\\n🔢 激活机制3: 离散有序激活 (有序分类)\")\n        print(f\"  数学公式: f_k(s_k) = ∑y_i·I(C_i < s_k ≤ C_{i+1})\")\n        print(f\"  概率计算: P(y_i) = F(C_{i+1}) - F(C_i)\")\n        \n        # 设置有序类别边界 (例如：评分1-5)\n        num_categories = 5\n        boundaries = torch.linspace(-3, 3, num_categories + 1)  # [-3, -1.5, 0, 1.5, 3]\n        \n        # 只使用第一个决策得分作为示例\n        sample_loc = loc_S[:, 0]  # shape: (batch_size,)\n        sample_scale = scale_S[:, 0]\n        \n        def cauchy_cdf(x, loc, scale):\n            \"\"\"柯西分布的累积分布函数\"\"\"\n            return 0.5 + torch.atan((x - loc) / scale) / np.pi\n        \n        # 计算每个类别的概率\n        category_probs = []\n        for i in range(num_categories):\n            lower_bound = boundaries[i]\n            upper_bound = boundaries[i + 1]\n            \n            prob_upper = cauchy_cdf(upper_bound, sample_loc, sample_scale)\n            prob_lower = cauchy_cdf(lower_bound, sample_loc, sample_scale)\n            \n            category_prob = prob_upper - prob_lower\n            category_probs.append(category_prob)\n        \n        category_probs = torch.stack(category_probs, dim=1)  # shape: (batch_size, num_categories)\n        \n        # 预测类别 (最高概率)\n        predictions = torch.argmax(category_probs, dim=1) + 1  # 类别从1开始\n        \n        print(f\"  类别边界: {boundaries.tolist()}\")\n        print(f\"  类别概率形状: {category_probs.shape}\")\n        print(f\"  平均类别概率: {category_probs.mean(dim=0).tolist()}\")\n        print(f\"  预测类别: {predictions.tolist()}\")\n        \n        print(f\"\\n  💡 关键特性:\")\n        print(f\"    ✨ 有序约束: 保持类别间的有序关系\")\n        print(f\"    ✨ 区间概率: 基于区间的概率计算\")\n        print(f\"    ✨ 阈值学习: 可学习的类别边界\")\n        print(f\"    ✨ 校准性: 更好的概率校准\")\n        \n        return category_probs\n    \n    def demonstrate_task_extensions(self):\n        \"\"\"\n        演示如何扩展到新的任务类型\n        \"\"\"\n        print(f\"\\n🚀 任务激活机制的扩展性\")\n        print(f\"=\" * 60)\n        \n        print(f\"\\n🎯 扩展原理:\")\n        print(f\"  1. 定义基础激活函数 f_k(s_k)\")\n        print(f\"  2. 推导在柯西分布下的解析形式\")\n        print(f\"  3. 实现相应的损失函数\")\n        print(f\"  4. 集成到CausalEngine框架\")\n        \n        # 示例扩展任务\n        extensions = {\n            'time_prediction': {\n                'name': '时间预测任务',\n                'activation': 'f_k(s_k) = exp(w_k·s_k + b_k)',\n                'output_dist': 'Lognormal分布 (通过指数变换)',\n                'loss': 'Lognormal负对数似然',\n                'applications': ['事件发生时间', '生存分析', '可靠性工程']\n            },\n            'probability_estimation': {\n                'name': '概率估计任务',\n                'activation': 'f_k(s_k) = sigmoid(w_k·s_k + b_k)',\n                'output_dist': 'Beta分布 (通过logit变换)',\n                'loss': 'Beta分布负对数似然',\n                'applications': ['风险概率', '成功率预测', '置信度估计']\n            },\n            'count_prediction': {\n                'name': '计数预测任务',\n                'activation': 'f_k(s_k) = softplus(w_k·s_k + b_k)',\n                'output_dist': 'Poisson分布 (通过对数链接)',\n                'loss': 'Poisson负对数似然',\n                'applications': ['客流量预测', '故障次数', '库存需求']\n            },\n            'multi_label': {\n                'name': '多标签分类',\n                'activation': 'f_k(s_k) = I(s_k > C_k) for all k',\n                'output_dist': '独立伯努利分布',\n                'loss': '多个二元交叉熵之和',\n                'applications': ['标签推荐', '症状诊断', '技能评估']\n            },\n            'ranking': {\n                'name': '排序任务',\n                'activation': 'f_k(s_k) = rank(s_k)',\n                'output_dist': '排列分布',\n                'loss': '排序损失 (如ListNet)',\n                'applications': ['搜索排序', '推荐系统', '优先级排序']\n            }\n        }\n        \n        for task_key, task_info in extensions.items():\n            print(f\"\\n📋 {task_info['name']}\")\n            print(f\"  激活函数: {task_info['activation']}\")\n            print(f\"  输出分布: {task_info['output_dist']}\")\n            print(f\"  损失函数: {task_info['loss']}\")\n            print(f\"  应用场景: {', '.join(task_info['applications'])}\")\n    \n    def implement_custom_activation(self):\n        \"\"\"\n        实现自定义激活函数的示例\n        \"\"\"\n        print(f\"\\n🛠️ 自定义激活函数实现示例\")\n        print(f\"=\" * 60)\n        \n        print(f\"\\n💡 示例: 时间预测任务 (生存分析)\")\n        \n        class TimeActivationHead(nn.Module):\n            \"\"\"\n            时间预测激活头 - 基于指数变换的生存分析\n            \"\"\"\n            def __init__(self, input_size, num_targets):\n                super().__init__()\n                self.weight = nn.Parameter(torch.ones(num_targets, input_size))\n                self.bias = nn.Parameter(torch.zeros(num_targets))\n            \n            def forward(self, loc_S, scale_S):\n                \"\"\"\n                前向传播: 决策得分 → 时间预测\n                \n                Args:\n                    loc_S: 决策得分位置参数 (batch, seq, decisions)\n                    scale_S: 决策得分尺度参数 (batch, seq, decisions)\n                \n                Returns:\n                    时间预测的对数正态分布参数\n                \"\"\"\n                # 线性变换\n                log_time_loc = torch.einsum('bsd,nd->bsn', loc_S, self.weight) + self.bias\n                log_time_scale = torch.einsum('bsd,nd->bsn', scale_S, torch.abs(self.weight))\n                \n                # 输出对数正态分布参数\n                return {\n                    'log_loc': log_time_loc,\n                    'log_scale': log_time_scale,\n                    'mean_time': torch.exp(log_time_loc + 0.5 * log_time_scale**2),\n                    'median_time': torch.exp(log_time_loc)\n                }\n            \n            def sample(self, loc_S, scale_S, num_samples=1):\n                \"\"\"\n                从预测分布中采样时间值\n                \"\"\"\n                output = self.forward(loc_S, scale_S)\n                \n                # 从对数正态分布采样\n                log_normal = torch.distributions.LogNormal(\n                    output['log_loc'], output['log_scale']\n                )\n                \n                return log_normal.sample((num_samples,))\n            \n            def loss(self, loc_S, scale_S, target_times, censoring_indicator=None):\n                \"\"\"\n                计算生存分析损失 (支持删失数据)\n                \"\"\"\n                output = self.forward(loc_S, scale_S)\n                \n                # 对数正态分布的负对数似然\n                log_normal = torch.distributions.LogNormal(\n                    output['log_loc'], output['log_scale']\n                )\n                \n                if censoring_indicator is None:\n                    # 无删失数据\n                    return -log_normal.log_prob(target_times).mean()\n                else:\n                    # 处理删失数据\n                    uncensored_loss = -log_normal.log_prob(target_times) * (1 - censoring_indicator)\n                    censored_loss = -log_normal.log_survival_function(target_times) * censoring_indicator\n                    return (uncensored_loss + censored_loss).mean()\n        \n        # 演示使用\n        print(f\"\\n🔧 实现细节:\")\n        print(f\"  激活函数: f(s) = exp(w·s + b)\")\n        print(f\"  输出分布: Y ~ LogNormal(μ, σ)\")\n        print(f\"  参数映射: μ = w·loc_S + b, σ = |w|·scale_S\")\n        print(f\"  损失函数: -log P(t|μ,σ) + 删失处理\")\n        \n        # 创建示例\n        time_head = TimeActivationHead(input_size=5, num_targets=2)\n        \n        # 模拟数据\n        batch_size = 4\n        loc_S = torch.randn(batch_size, 1, 5)\n        scale_S = torch.abs(torch.randn(batch_size, 1, 5)) + 0.1\n        target_times = torch.exponential(torch.ones(batch_size, 1, 2))\n        \n        # 前向传播\n        time_output = time_head(loc_S, scale_S)\n        \n        print(f\"\\n📊 演示结果:\")\n        print(f\"  输入决策得分: {loc_S.shape}\")\n        print(f\"  预测平均时间: {time_output['mean_time'].mean():.3f}\")\n        print(f\"  预测中位时间: {time_output['median_time'].mean():.3f}\")\n        \n        # 计算损失\n        loss_value = time_head.loss(loc_S, scale_S, target_times)\n        print(f\"  损失值: {loss_value:.4f}\")\n        \n        print(f\"\\n✅ 自定义激活函数实现完成！\")\n    \n    def analyze_activation_properties(self):\n        \"\"\"\n        分析激活机制的重要性质\n        \"\"\"\n        print(f\"\\n🔍 激活机制的重要性质分析\")\n        print(f\"=\" * 60)\n        \n        properties = {\n            'computational_efficiency': {\n                'name': '计算效率',\n                'description': '相比采样方法的计算优势',\n                'analysis': {\n                    '解析计算': '利用柯西分布CDF避免蒙特卡洛采样',\n                    '线性复杂度': '计算复杂度与输出维度成线性关系',\n                    '并行友好': '所有激活函数可并行计算',\n                    '内存高效': '无需存储大量采样结果'\n                }\n            },\n            'mathematical_rigor': {\n                'name': '数学严格性',\n                'description': '基于分布的精确计算',\n                'analysis': {\n                    '分布保持': '柯西分布的线性稳定性保证运算正确性',\n                    '解析精确': '避免数值采样的近似误差',\n                    '理论支撑': '建立在成熟的概率论基础上',\n                    '可证明性': '数学性质可严格证明'\n                }\n            },\n            'uncertainty_quantification': {\n                'name': '不确定性量化',\n                'description': '完整保留和传播不确定性信息',\n                'analysis': {\n                    '完整分布': '保留输出的完整概率分布信息',\n                    '校准性': '提供校准的不确定性估计',\n                    '传播性': '从输入到输出的完整不确定性传播',\n                    '可解释性': '不确定性来源清晰可解释'\n                }\n            },\n            'task_agnostic': {\n                'name': '任务无关性',\n                'description': '统一框架支持多种任务类型',\n                'analysis': {\n                    '通用性': '决策得分与具体任务无关',\n                    '扩展性': '易于扩展到新的任务类型',\n                    '组合性': '支持多任务联合学习',\n                    '一致性': '所有任务共享相同的数学框架'\n                }\n            },\n            'interpretability': {\n                'name': '可解释性',\n                'description': '清晰的决策过程和物理意义',\n                'analysis': {\n                    '阈值含义': '分类阈值有明确的物理解释',\n                    '参数意义': '所有参数都有具体的数学含义',\n                    '决策路径': '从证据到决策的完整可追踪路径',\n                    '因果性': '体现真正的因果推理过程'\n                }\n            }\n        }\n        \n        for prop_key, prop_info in properties.items():\n            print(f\"\\n🏆 {prop_info['name']}\")\n            print(f\"  定义: {prop_info['description']}\")\n            print(f\"  具体分析:\")\n            for aspect, detail in prop_info['analysis'].items():\n                print(f\"    • {aspect}: {detail}\")\n    \n    def visualize_activation_behaviors(self):\n        \"\"\"\n        可视化三种激活机制的行为特征\n        \"\"\"\n        print(f\"\\n📊 生成激活机制行为可视化\")\n        \n        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n        fig.suptitle('CausalEngine 任务激活机制行为分析', fontsize=16, fontweight='bold')\n        \n        # 创建测试数据\n        s_range = torch.linspace(-4, 4, 100)\n        batch_size = 50\n        \n        # 1. 分类激活：概率vs决策得分\n        thresholds = [-1, 0, 1]\n        scale = 0.5\n        \n        ax1 = axes[0, 0]\n        for i, threshold in enumerate(thresholds):\n            probs = 0.5 + torch.atan((s_range - threshold) / scale) / np.pi\n            ax1.plot(s_range, probs, label=f'阈值={threshold}', linewidth=2)\n        \n        ax1.set_xlabel('决策得分 s')\n        ax1.set_ylabel('激活概率 P(s > C)')\n        ax1.set_title('分类激活：阈值效应')\n        ax1.legend()\n        ax1.grid(True, alpha=0.3)\n        \n        # 2. 回归激活：输出分布\n        weights = [0.5, 1.0, 2.0]\n        input_loc = 1.0\n        input_scale = 0.5\n        \n        ax2 = axes[0, 1]\n        for w in weights:\n            output_loc = w * input_loc\n            output_scale = abs(w) * input_scale\n            \n            # 绘制输出分布\n            y_range = torch.linspace(output_loc - 3*output_scale, \n                                   output_loc + 3*output_scale, 100)\n            pdf = 1 / (np.pi * output_scale * (1 + ((y_range - output_loc) / output_scale)**2))\n            \n            ax2.plot(y_range, pdf, label=f'权重={w}', linewidth=2)\n        \n        ax2.set_xlabel('输出值 y')\n        ax2.set_ylabel('概率密度')\n        ax2.set_title('回归激活：权重效应')\n        ax2.legend()\n        ax2.grid(True, alpha=0.3)\n        \n        # 3. 有序分类：类别概率\n        boundaries = torch.tensor([-2, -1, 0, 1, 2])\n        loc_values = [-1, 0, 1]\n        scale = 0.7\n        \n        ax3 = axes[0, 2]\n        category_names = ['C1', 'C2', 'C3', 'C4']\n        \n        for loc in loc_values:\n            probs = []\n            for i in range(len(boundaries) - 1):\n                prob_upper = 0.5 + torch.atan((boundaries[i+1] - loc) / scale) / np.pi\n                prob_lower = 0.5 + torch.atan((boundaries[i] - loc) / scale) / np.pi\n                probs.append(prob_upper - prob_lower)\n            \n            ax3.bar([f'{cat}\\n(loc={loc})' for cat in category_names], probs, \n                   alpha=0.7, label=f'位置={loc}')\n        \n        ax3.set_ylabel('类别概率')\n        ax3.set_title('有序分类：位置效应')\n        ax3.legend()\n        ax3.grid(True, alpha=0.3, axis='y')\n        \n        # 4. 不确定性传播：尺度参数效应\n        scales = [0.1, 0.5, 1.0]\n        threshold = 0\n        \n        ax4 = axes[1, 0]\n        for scale in scales:\n            probs = 0.5 + torch.atan((s_range - threshold) / scale) / np.pi\n            ax4.plot(s_range, probs, label=f'尺度={scale}', linewidth=2)\n        \n        ax4.set_xlabel('决策得分 s')\n        ax4.set_ylabel('激活概率')\n        ax4.set_title('不确定性传播：尺度效应')\n        ax4.legend()\n        ax4.grid(True, alpha=0.3)\n        \n        # 5. 多任务激活：独立性展示\n        num_tasks = 3\n        task_thresholds = [-0.5, 0, 0.5]\n        scale = 0.8\n        \n        ax5 = axes[1, 1]\n        colors = ['red', 'green', 'blue']\n        \n        for i, (threshold, color) in enumerate(zip(task_thresholds, colors)):\n            probs = 0.5 + torch.atan((s_range - threshold) / scale) / np.pi\n            ax5.plot(s_range, probs, label=f'任务{i+1}', color=color, linewidth=2)\n        \n        ax5.set_xlabel('决策得分 s')\n        ax5.set_ylabel('各任务激活概率')\n        ax5.set_title('多任务激活：独立性')\n        ax5.legend()\n        ax5.grid(True, alpha=0.3)\n        \n        # 6. 激活函数对比\n        activation_types = {\n            '阶跃函数 (传统)': lambda x: (x > 0).float(),\n            'Sigmoid': lambda x: torch.sigmoid(x),\n            'CausalEngine': lambda x: 0.5 + torch.atan(x / 0.5) / np.pi\n        }\n        \n        ax6 = axes[1, 2]\n        for name, func in activation_types.items():\n            outputs = func(s_range)\n            ax6.plot(s_range, outputs, label=name, linewidth=2)\n        \n        ax6.set_xlabel('输入值')\n        ax6.set_ylabel('输出值')\n        ax6.set_title('激活函数对比')\n        ax6.legend()\n        ax6.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.savefig('tutorials/04_advanced_topics/task_activation_analysis.png', \n                   dpi=300, bbox_inches='tight')\n        plt.close()\n        \n        print(\"✅ 可视化图表已保存: tutorials/04_advanced_topics/task_activation_analysis.png\")\n\n\ndef main():\n    \"\"\"\n    主函数: 完整的任务激活机制解析\n    \"\"\"\n    print(\"🌟 CausalEngine 任务激活机制深度解析\")\n    print(\"基于最新数学理论的统一激活框架分析\")\n    print(\"=\" * 80)\n    \n    # 创建分析器\n    analyzer = TaskActivationAnalyzer()\n    \n    # 1. 数学基础演示\n    print(\"\\n🔬 步骤1: 数学基础演示\")\n    analyzer.demonstrate_mathematical_foundations()\n    \n    # 2. 任务扩展演示\n    print(\"\\n🚀 步骤2: 任务扩展能力\")\n    analyzer.demonstrate_task_extensions()\n    \n    # 3. 自定义激活实现\n    print(\"\\n🛠️ 步骤3: 自定义激活实现\")\n    analyzer.implement_custom_activation()\n    \n    # 4. 性质分析\n    print(\"\\n🔍 步骤4: 重要性质分析\")\n    analyzer.analyze_activation_properties()\n    \n    # 5. 行为可视化\n    print(\"\\n📊 步骤5: 行为可视化\")\n    analyzer.visualize_activation_behaviors()\n    \n    # 6. 总结\n    print(\"\\n🎉 任务激活机制解析完成！\")\n    print(\"=\" * 80)\n    print(\"🔬 核心发现:\")\n    print(\"  ✅ 三种激活机制覆盖了主要的ML任务类型\")\n    print(\"  ✅ 统一的数学框架确保了一致性和可扩展性\")\n    print(\"  ✅ 解析计算避免了采样的计算开销\")\n    print(\"  ✅ 完整的不确定性传播保持了信息完整性\")\n    \n    print(\"\\n💡 设计优势:\")\n    print(\"  🎯 任务无关: 决策得分与具体任务解耦\")\n    print(\"  🔄 可组合: 支持多任务联合学习\")\n    print(\"  📐 数学严格: 基于概率论的精确计算\")\n    print(\"  🚀 易扩展: 新任务只需定义激活函数\")\n    \n    print(\"\\n📚 进一步学习:\")\n    print(\"  1. 多任务学习: tutorials/04_advanced_topics/multi_task_learning_framework.py\")\n    print(\"  2. 自定义设计: tutorials/04_advanced_topics/custom_activation_design.py\")\n    print(\"  3. 推理模式: tutorials/04_advanced_topics/four_inference_modes_deep_dive.py\")\n    print(\"  4. 数学理论: causal_engine/MATHEMATICAL_FOUNDATIONS_CN.md\")\n\n\nif __name__ == \"__main__\":\n    main()"