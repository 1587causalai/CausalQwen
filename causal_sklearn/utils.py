#!/usr/bin/env python3
"""
CausalSklearnå·¥å…·å‡½æ•°æ¨¡å— - æœ€ä¼˜ç‰ˆæœ¬
=====================================

æä¾›é€šç”¨çš„å·¥å…·å‡½æ•°ï¼ŒåŒ…æ‹¬æ ‡ç­¾å¼‚å¸¸å¤„ç†ã€æ•°æ®å¤„ç†ç­‰åŠŸèƒ½ã€‚
åŸºäºUltraThinké‡æ„æ€æƒ³ï¼Œé‡‡ç”¨æœ€ä¼˜é›…å’Œç®€æ´çš„è®¾è®¡ã€‚
"""

import numpy as np
from sklearn.model_selection import train_test_split
from dataclasses import dataclass
from typing import Optional, Tuple


def add_label_anomalies(y, anomaly_ratio=0.1, anomaly_type='regression', 
                       regression_anomaly_strategy='shuffle', 
                       classification_anomaly_strategy='shuffle'):
    """
    ç»™æ ‡ç­¾æ·»åŠ å¼‚å¸¸ - ç”¨äºæµ‹è¯•æ¨¡å‹çš„é²æ£’æ€§
    
    è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„æ ‡ç­¾å™ªå£°æ³¨å…¥å·¥å…·ï¼Œæ”¯æŒå›å½’å’Œåˆ†ç±»ä»»åŠ¡çš„å¤šç§å¼‚å¸¸ç­–ç•¥ã€‚
    
    Args:
        y: åŸå§‹æ ‡ç­¾æ•°ç»„
        anomaly_ratio: å¼‚å¸¸æ¯”ä¾‹ (0.0-1.0)
        anomaly_type: ä»»åŠ¡ç±»å‹ ('regression' æˆ– 'classification')
        regression_anomaly_strategy: å›å½’å¼‚å¸¸ç­–ç•¥ ('shuffle' æˆ– 'outlier')
        classification_anomaly_strategy: åˆ†ç±»å¼‚å¸¸ç­–ç•¥ ('flip' æˆ– 'shuffle')
    
    Returns:
        numpy.ndarray: æ·»åŠ å¼‚å¸¸åçš„æ ‡ç­¾æ•°ç»„
    
    Examples:
        >>> y_reg = np.array([1.0, 2.0, 3.0, 4.0, 5.0])
        >>> y_noisy = add_label_anomalies(y_reg, 0.4, 'regression', 'shuffle')
        
        >>> y_cls = np.array([0, 1, 2, 0, 1, 2])
        >>> y_noisy = add_label_anomalies(y_cls, 0.3, 'classification', 'flip')
    """
    y_noisy = y.copy()
    n_anomalies = int(len(y) * anomaly_ratio)
    
    if n_anomalies == 0:
        return y_noisy
        
    # éšæœºé€‰æ‹©å¼‚å¸¸æ ·æœ¬ç´¢å¼•
    anomaly_indices = np.random.choice(len(y), n_anomalies, replace=False)
    
    if anomaly_type == 'regression':
        if regression_anomaly_strategy == 'shuffle':
            # ç­–ç•¥1: é€šè¿‡éšæœºæ’åºä¸€éƒ¨åˆ†æ ‡ç­¾æ¥åˆ›å»ºé”™è¯¯çš„X-yé…å¯¹
            labels_to_shuffle = y_noisy[anomaly_indices]
            np.random.shuffle(labels_to_shuffle)
            y_noisy[anomaly_indices] = labels_to_shuffle
        
        elif regression_anomaly_strategy == 'outlier':
            # ç­–ç•¥2: æç«¯ç¦»ç¾¤å€¼å¼‚å¸¸
            y_std = np.std(y)
            for idx in anomaly_indices:
                if np.random.random() < 0.5:
                    # 3å€æ ‡å‡†å·®åç§»
                    sign = np.random.choice([-1, 1])
                    y_noisy[idx] = y[idx] + sign * 3.0 * y_std
                else:
                    # 10å€ç¼©æ”¾
                    scale_factor = np.random.choice([0.1, 10.0])
                    y_noisy[idx] = y[idx] * scale_factor
            
    elif anomaly_type == 'classification':
        unique_labels = np.unique(y)
        
        if classification_anomaly_strategy == 'flip':
            # ç­–ç•¥1: æ ‡ç­¾ç¿»è½¬åˆ°å…¶ä»–ç±»åˆ«
            for idx in anomaly_indices:
                other_labels = unique_labels[unique_labels != y[idx]]
                if len(other_labels) > 0:
                    y_noisy[idx] = np.random.choice(other_labels)
        
        elif classification_anomaly_strategy == 'shuffle':
            # ç­–ç•¥2: æ ‡ç­¾æ‰“ä¹±ï¼ˆä¿æŒç±»åˆ«åˆ†å¸ƒï¼‰
            labels_to_shuffle = y_noisy[anomaly_indices].copy()
            np.random.shuffle(labels_to_shuffle)
            y_noisy[anomaly_indices] = labels_to_shuffle
    
    return y_noisy


@dataclass
class SplitConfig:
    """æ•°æ®åˆ†å‰²é…ç½®ç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰åˆ†å‰²å‚æ•°"""
    # åŸºç¡€åˆ†å‰²å‚æ•°
    test_size: Optional[float] = 0.2
    random_state: Optional[int] = None
    shuffle: bool = True
    stratify: Optional[np.ndarray] = None
    
    # å¼‚å¸¸æ³¨å…¥é…ç½®ï¼ˆé»˜è®¤æ¯”ä¾‹ä¸º0ï¼Œå³æ­£å¸¸åˆ†å‰²ï¼‰
    anomaly_ratio: float = 0.0
    anomaly_type: str = 'regression'
    regression_strategy: str = 'shuffle'
    classification_strategy: str = 'shuffle'
    
    # è¾“å‡ºé…ç½®
    verbose: bool = False


class CausalSplitter:
    """
    å› æœæ•°æ®åˆ†å‰²å™¨ - ç®€åŒ–çš„åˆ†å‰²é€»è¾‘å®ç°
    
    æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š
    1. åªæ”¯æŒ2åˆ†å‰²ï¼ˆtrain/testï¼‰
    2. åˆ†ç¦»å…³æ³¨ç‚¹ - å¼‚å¸¸æ³¨å…¥ä¸åˆ†å‰²é€»è¾‘è§£è€¦
    3. ç®€åŒ–æ¥å£ - é…ç½®ç±»ç®¡ç†å‚æ•°
    """
    
    def __init__(self, *arrays, config: Optional[SplitConfig] = None):
        self.arrays = list(arrays)
        self.config = config or SplitConfig()
        
    def split(self) -> Tuple[np.ndarray, ...]:
        """æ‰§è¡Œåˆ†å‰²å¹¶è¿”å›ç»“æœ"""
        # æ‰§è¡Œ2åˆ†å‰²
        result = self._two_way_split()
        
        # åº”ç”¨å¼‚å¸¸æ³¨å…¥ï¼ˆä»…å½“å¼‚å¸¸æ¯”ä¾‹ > 0æ—¶ï¼‰
        if self.config.anomaly_ratio > 0:
            result = self._apply_anomalies(result)
        
        # æ‰“å°ä¿¡æ¯
        if self.config.verbose:
            self._print_summary(result)
        
        return self._to_sklearn_format(result)
    
    def _two_way_split(self) -> dict:
        """2åˆ†å‰²å®ç°"""
        split_arrays = train_test_split(
            *self.arrays,
            test_size=self.config.test_size,
            random_state=self.config.random_state,
            shuffle=self.config.shuffle,
            stratify=self.config.stratify
        )
        
        # é‡æ–°ç»„ç»‡æ•°ç»„
        n_arrays = len(self.arrays)
        train_arrays = [split_arrays[i * 2] for i in range(n_arrays)]
        test_arrays = [split_arrays[i * 2 + 1] for i in range(n_arrays)]
        
        return {
            'train': train_arrays,
            'test': test_arrays
        }
    
    
    def _apply_anomalies(self, result: dict) -> dict:
        """åº”ç”¨å¼‚å¸¸æ³¨å…¥ - ä»…å¯¹è®­ç»ƒé›†ï¼Œæµ‹è¯•é›†å§‹ç»ˆä¿æŒçº¯å‡€"""
        # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸæ•°æ®
        new_result = {}
        for key, arrays in result.items():
            new_result[key] = [arr.copy() for arr in arrays]
        
        # å¯¹è®­ç»ƒé›†æ³¨å…¥å¼‚å¸¸ï¼ˆå‡è®¾yæ˜¯ç¬¬äºŒä¸ªæ•°ç»„ï¼‰
        if len(new_result['train']) >= 2:
            new_result['train'][1] = add_label_anomalies(
                new_result['train'][1],
                anomaly_ratio=self.config.anomaly_ratio,
                anomaly_type=self.config.anomaly_type,
                regression_anomaly_strategy=self.config.regression_strategy,
                classification_anomaly_strategy=self.config.classification_strategy
            )
        
        # æµ‹è¯•é›†å§‹ç»ˆä¿æŒçº¯å‡€ï¼Œä¸æ³¨å…¥å¼‚å¸¸
        
        return new_result
    
    def _print_summary(self, result: dict):
        """æ‰“å°åˆ†å‰²æ‘˜è¦"""
        print(f"ğŸ”„ CausalSklearnæ•°æ®åˆ†å‰²")
        print(f"   æ¨¡å¼: 2åˆ†å‰² (train/test)")
        print(f"   æ ·æœ¬æ•°: {len(self.arrays[0])}")
        
        if self.config.anomaly_ratio > 0:
            print(f"   å¼‚å¸¸æ³¨å…¥: {self.config.anomaly_type}, æ¯”ä¾‹={self.config.anomaly_ratio:.1%}")
            strategy = self.config.regression_strategy if self.config.anomaly_type == 'regression' else self.config.classification_strategy
            print(f"   å¼‚å¸¸ç­–ç•¥: {strategy}")
            print(f"   æµ‹è¯•é›†: ä¿æŒçº¯å‡€")
        
        print(f"   åˆ†å‰²ç»“æœ: train={len(result['train'][0])}, test={len(result['test'][0])}")
    
    def _to_sklearn_format(self, result: dict) -> Tuple[np.ndarray, ...]:
        """è½¬æ¢ä¸ºsklearné£æ ¼çš„tuple"""
        # 2åˆ†å‰²: X_train, X_test, y_train, y_test, ...
        output = []
        for i in range(len(self.arrays)):
            output.extend([result['train'][i], result['test'][i]])
        return tuple(output)


def causal_split(*arrays, **kwargs) -> Tuple[np.ndarray, ...]:
    """
    å› æœæ•°æ®åˆ†å‰²å‡½æ•° - ç®€æ´é«˜æ•ˆçš„å®ç°
    
    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. åªæ”¯æŒ2åˆ†å‰²æ¨¡å¼ï¼ˆtrain/testï¼‰
    2. è®­ç»ƒé›†å¯é€‰å¼‚å¸¸æ³¨å…¥ï¼Œæµ‹è¯•é›†å§‹ç»ˆçº¯å‡€
    3. å¼‚å¸¸æ¯”ä¾‹é»˜è®¤0.0ï¼ˆæ­£å¸¸åˆ†å‰²ï¼‰
    4. éªŒè¯é›†åˆ†å‰²ç”±å„ä¼°è®¡å™¨å†…éƒ¨å¤„ç†ï¼ˆearly stoppingï¼‰
    
    Args:
        *arrays: è¦åˆ†å‰²çš„æ•°ç»„ï¼ˆX, yç­‰ï¼‰
        test_size: æµ‹è¯•é›†å¤§å° (é»˜è®¤0.2)
        random_state: éšæœºç§å­
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ® (é»˜è®¤True)
        stratify: åˆ†å±‚åˆ†å‰²çš„ç›®æ ‡æ•°ç»„
        
        anomaly_ratio: å¼‚å¸¸æ¯”ä¾‹ (é»˜è®¤0.0ï¼Œå³æ­£å¸¸åˆ†å‰²)
        anomaly_type: 'regression' æˆ– 'classification' (é»˜è®¤'regression')
        regression_anomaly_strategy: å›å½’å¼‚å¸¸ç­–ç•¥ ('shuffle' æˆ– 'outlier')
        classification_anomaly_strategy: åˆ†ç±»å¼‚å¸¸ç­–ç•¥ ('flip' æˆ– 'shuffle')
        
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
    Returns:
        X_train, X_test, y_train, y_test (ä»¥åŠæ›´å¤šæ•°ç»„å¦‚æœæä¾›)
        
    Examples:
        >>> # æ­£å¸¸åˆ†å‰²ï¼ˆæ— å¼‚å¸¸ï¼‰
        >>> X_train, X_test, y_train, y_test = causal_split(X, y)
        
        >>> # å¸¦å¼‚å¸¸æ³¨å…¥çš„åˆ†å‰²
        >>> X_train, X_test, y_train, y_test = causal_split(
        ...     X, y, anomaly_ratio=0.1, anomaly_type='regression', verbose=True
        ... )
        
        >>> # åˆ†ç±»ä»»åŠ¡çš„åˆ†å±‚åˆ†å‰²
        >>> X_train, X_test, y_train, y_test = causal_split(
        ...     X, y, stratify=y, anomaly_ratio=0.2, anomaly_type='classification'
        ... )
    """
    # å‚æ•°æ˜ å°„
    config = SplitConfig()
    
    # åŸºç¡€å‚æ•°
    if 'test_size' in kwargs: config.test_size = kwargs['test_size']
    if 'random_state' in kwargs: config.random_state = kwargs['random_state']
    if 'shuffle' in kwargs: config.shuffle = kwargs['shuffle']
    if 'stratify' in kwargs: config.stratify = kwargs['stratify']
    
    # å¼‚å¸¸æ³¨å…¥å‚æ•°
    if 'anomaly_ratio' in kwargs: config.anomaly_ratio = kwargs['anomaly_ratio']
    if 'anomaly_type' in kwargs: config.anomaly_type = kwargs['anomaly_type']
    if 'regression_anomaly_strategy' in kwargs: config.regression_strategy = kwargs['regression_anomaly_strategy']
    if 'classification_anomaly_strategy' in kwargs: config.classification_strategy = kwargs['classification_anomaly_strategy']
    
    # è¾“å‡ºå‚æ•°
    if 'verbose' in kwargs: config.verbose = kwargs['verbose']
    
    # å‚æ•°éªŒè¯
    if len(arrays) < 2:
        raise ValueError("è‡³å°‘éœ€è¦æä¾›2ä¸ªæ•°ç»„ï¼ˆé€šå¸¸æ˜¯Xå’Œyï¼‰")
    
    # æ‰§è¡Œåˆ†å‰²
    splitter = CausalSplitter(*arrays, config=config)
    return splitter.split()


