#!/usr/bin/env python
"""
æ•°å€¼æ„ŸçŸ¥åµŒå…¥æ¨¡å— (Numerical-aware Embedding) ä¸“é¡¹æµ‹è¯•è„šæœ¬

æœ¬è„šæœ¬æ—¨åœ¨æ¸…æ™°ã€ç‹¬ç«‹åœ°éªŒè¯æ•°å€¼æ„ŸçŸ¥åµŒå…¥æ¨¡å—çš„æ•°å­¦æ­£ç¡®æ€§ï¼Œ
ç¡®ä¿å…¶è¡Œä¸ºä¸ `mathematical_foundations.md` ä¸­å®šä¹‰çš„ç†è®ºå®Œå…¨ä¸€è‡´ã€‚
"""
import os
import sys
import torch
import numpy as np

# Add project root to Python path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models.causal_lm import CausalLMConfig
from src.models.feature_network import NumAwareFeatureNetwork
from src.data.tokenizer import QwenTokenizerWrapper
from src.models.causal_lm import CausalLanguageModel

def print_step(step_num, description):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{'='*70}")
    print(f"â¡ï¸  æ­¥éª¤ {step_num}: {description}")
    print(f"{'='*70}")

def print_tensor_stats(name, tensor):
    """æ‰“å°å¼ é‡çš„ç®€è¦ç»Ÿè®¡ä¿¡æ¯ã€‚"""
    if not isinstance(tensor, torch.Tensor):
        print(f"   - {name}: Not a tensor")
        return
    tensor = tensor.detach().cpu().to(torch.float32)
    print(f"   - {name} | Shape: {tensor.shape} | Mean: {tensor.mean():.4f} | Std: {tensor.std():.4f}")

def main():
    print("ğŸš€ CausalQwen - æ•°å€¼æ„ŸçŸ¥åµŒå…¥æ¨¡å—ä¸“é¡¹æµ‹è¯•")
    
    # --- 1. åˆå§‹åŒ– ---
    print_step(1, "åˆå§‹åŒ–åˆ†è¯å™¨å’Œæ¨¡å‹ç»„ä»¶")
    device = torch.device('cpu')
    qwen_model_path = os.path.expanduser('~/models/Qwen2.5-0.5B')
    assert os.path.exists(qwen_model_path), "Qwenæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨"
    
    tokenizer = QwenTokenizerWrapper(model_path=qwen_model_path, use_real_tokenizer=True)
    config = CausalLMConfig(
        vocab_size=tokenizer.vocab_size_info()['causalqwen_vocab'],
        num_token_id=tokenizer.num_token_id,
        hidden_size=896,
        use_real_qwen=True, # å¿…é¡»åŠ è½½çœŸå®æ¨¡å‹ä»¥è·å–åµŒå…¥å±‚
        qwen_model_path=qwen_model_path
    )
    
    # å¿…é¡»åˆ›å»ºå®Œæ•´çš„CausalLanguageModelä»¥æ­£ç¡®åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
    full_model = CausalLanguageModel(config).to(device)
    full_model.eval()
    
    # ä»å®Œæ•´æ¨¡å‹ä¸­æå–æˆ‘ä»¬æƒ³è¦æµ‹è¯•çš„ç»„ä»¶
    feature_network = full_model.feature_network
    
    print("âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    print(f"   <NUM> token ID: {config.num_token_id}")

    # --- 2. å‡†å¤‡æµ‹è¯•æ•°æ® ---
    print_step(2, "å‡†å¤‡ä¸¤ç»„æµ‹è¯•æ•°æ® (æœ‰/æ— æ•°å€¼)")
    text_with_num = "The price is 99.9 dollars"
    text_without_num = "Hello world, this is a test"
    
    inputs_with_num = tokenizer.batch_encode_plus([text_with_num], return_tensors='pt')
    inputs_without_num = tokenizer.batch_encode_plus([text_without_num], return_tensors='pt')

    print(f"   - æœ‰æ•°å€¼æ–‡æœ¬: '{text_with_num}'")
    print(f"   - æ— æ•°å€¼æ–‡æœ¬: '{text_without_num}'")

    # --- 3. æ ¸å¿ƒéªŒè¯ï¼šæ¨¡å—çš„æ•´ä½“è¡Œä¸º ---
    print_step(3, "éªŒè¯æ¨¡å—çš„æ•´ä½“è¡Œä¸º")
    print("ç†è®ºï¼šå¯¹äºæœ‰æ•°å€¼å’Œæ— æ•°å€¼çš„è¾“å…¥ï¼Œæ¨¡å—è¾“å‡ºçš„å·®å¼‚åº”è¯¥åªä½“ç°åœ¨æ•°å€¼ç¼–ç ä¸Šã€‚")

    with torch.no_grad():
        # è·å–"æ— æ•°å€¼"æƒ…å†µä¸‹çš„è¾“å‡ºç‰¹å¾
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è°ƒç”¨å®Œæ•´çš„ forwardï¼Œè€Œä¸æ˜¯è¯•å›¾æ‹†è§£å®ƒ
        # `numerical_values` ä»ç„¶éœ€è¦ä¼ å…¥ï¼Œå³ä½¿å®ƒå…¨æ˜¯é›¶
        features_without_num = feature_network(
            input_ids=inputs_without_num['input_ids'],
            numerical_values=inputs_without_num['numerical_values']
        )
        
        # è·å–"æœ‰æ•°å€¼"æƒ…å†µä¸‹çš„è¾“å‡ºç‰¹å¾
        features_with_num = feature_network(
            input_ids=inputs_with_num['input_ids'],
            numerical_values=inputs_with_num['numerical_values']
        )

    print_tensor_stats("è¾“å‡º (æ— æ•°å€¼)", features_without_num)
    print_tensor_stats("è¾“å‡º (æœ‰æ•°å€¼)", features_with_num)
    
    # --- 4. éªŒè¯æ•°å€¼ç¼–ç çš„ç‹¬ç«‹æ€§ ---
    print_step(4, "éªŒè¯æ•°å€¼ç¼–ç çš„ç‹¬ç«‹æ€§ (e' = e_base + Ï†(v))")
    print("ç†è®ºï¼šæ¨¡å—çš„ `forward` æ–¹æ³•è¾“å‡ºçš„ç‰¹å¾ï¼Œå¯ä»¥è¢«çœ‹ä½œæ˜¯ `e_base + Ï†(v)`ã€‚")
    
    with torch.no_grad():
        ids = inputs_with_num['input_ids']
        num_values = inputs_with_num['numerical_values']
        
        # æ‰¾åˆ°<NUM>è¯å…ƒçš„ä½ç½®
        num_token_pos = (ids == config.num_token_id).nonzero(as_tuple=True)
        pos_idx = num_token_pos[1][0]

        # 1. è®¡ç®—åŸºç¡€ç‰¹å¾ (base_features)
        # è¿™æ˜¯æ¨¡å—åœ¨æ²¡æœ‰æ•°å€¼ä¿¡æ¯æ—¶åº”è¯¥è¾“å‡ºçš„ç»“æœã€‚
        # æˆ‘ä»¬é€šè¿‡ä¼ å…¥ä¸€ä¸ªå…¨é›¶çš„ numerical_values æ¥æ¨¡æ‹Ÿè¿™ç§æƒ…å†µã€‚
        zeros_for_nums = torch.zeros_like(num_values)
        base_features_equivalent = feature_network(
            input_ids=ids,
            numerical_values=zeros_for_nums
        )

        # 2. è®¡ç®—å®é™…è¾“å‡º (features_with_num)
        # è¿™ä¸ªæˆ‘ä»¬å·²ç»åœ¨ä¸Šä¸€æ­¥è®¡ç®—è¿‡äº†
        
        # 3. è®¡ç®—å·®å€¼ï¼Œå®ƒåº”è¯¥ç­‰äºæ•°å€¼ç¼–ç  Ï†(v)
        phi_v = features_with_num - base_features_equivalent

    print_tensor_stats("æ¨¡æ‹Ÿçš„åŸºç¡€ç‰¹å¾ (e_base)", base_features_equivalent)
    print_tensor_stats("å®é™…çš„è¾“å‡º (e')", features_with_num)
    print_tensor_stats("ä¸¤è€…çš„å·®å€¼ (Ï†(v))", phi_v)

    # éªŒè¯é<NUM>ä½ç½®
    print("\n   --- éªŒè¯é<NUM>ä½ç½® ---")
    is_zero_elsewhere = (phi_v[:, :pos_idx].abs().max() < 1e-8) and \
                        (phi_v[:, pos_idx+1:].abs().max() < 1e-8)
    print(f"   - é<NUM>ä½ç½®çš„å·®å€¼ä¸ºé›¶: {'âœ… é€šè¿‡' if is_zero_elsewhere else 'âŒ å¤±è´¥'}")
    assert is_zero_elsewhere, "é<NUM>ä½ç½®çš„åµŒå…¥ä¸åº”è¢«æ”¹å˜"

    # éªŒè¯<NUM>ä½ç½®
    print("\n   --- éªŒè¯<NUM>ä½ç½® ---")
    phi_v_at_pos = phi_v[0, pos_idx]
    is_nonzero_at_pos = phi_v_at_pos.abs().max() > 1e-6
    print(f"   - <NUM>ä½ç½®çš„å·®å€¼éé›¶: {'âœ… é€šè¿‡' if is_nonzero_at_pos else 'âŒ å¤±è´¥'}")
    assert is_nonzero_at_pos, "<NUM>ä½ç½®çš„åµŒå…¥åº”è¯¥è¢«æ”¹å˜"

    # æ ¹æ®å…¬å¼éªŒè¯ Ï†(v) çš„èŒƒæ•°
    v = num_values[num_token_pos].item()
    expected_norm = np.abs(np.log(1 + np.abs(v)))
    actual_norm = torch.norm(phi_v_at_pos).item()
    norm_match = np.isclose(expected_norm, actual_norm, rtol=1e-6)
    print(f"   - éªŒè¯ Ï†({v:.4f}) çš„èŒƒæ•°:")
    print(f"     - ç†è®ºèŒƒæ•° |ln(1+|v|)|: {expected_norm:.6f}")
    print(f"     - å®é™…èŒƒæ•° ||Ï†(v)||: {actual_norm:.6f}")
    print(f"     - èŒƒæ•°æ˜¯å¦åŒ¹é…: {'âœ… é€šè¿‡' if norm_match else 'âŒ å¤±è´¥'}")
    assert norm_match, "Ï†(v) çš„èŒƒæ•°ä¸ç†è®ºä¸ç¬¦"
    
    print("\n   ç»“è®ºï¼šæ•°å€¼ç¼–ç æ¨¡å—çš„è¡Œä¸ºå®Œå…¨ç¬¦åˆæ•°å­¦å®šä¹‰ï¼ŒéªŒè¯é€šè¿‡ï¼")

if __name__ == '__main__':
    main() 