#!/usr/bin/env python3
"""
ActionNetworkåˆå§‹åŒ–ä¸“é¡¹æµ‹è¯•

ä¸“é—¨æµ‹è¯•ActionNetworkçš„ç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–æ˜¯å¦æ­£ç¡®å®æ–½
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import torch
import torch.nn as nn
from src.models.action_network import ActionNetwork

def test_action_network_init():
    """æµ‹è¯•ActionNetworkçš„ç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–"""
    
    print("=" * 60)
    print("=   ActionNetworkç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–æµ‹è¯•   =")
    print("=" * 60)
    
    # 1. åˆ›å»ºActionNetwork
    causal_dim = 896
    vocab_size = 151666
    num_token_id = 151665  # <NUM> token ID
    
    action_net = ActionNetwork(causal_dim, vocab_size, num_token_id)
    print(f"åˆ›å»ºActionNetwork: causal_dim={causal_dim}, vocab_size={vocab_size}")
    
    # 2. åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„Qwen lm_headç”¨äºæµ‹è¯•
    mock_qwen_lm_head = nn.Linear(causal_dim, vocab_size)
    print(f"åˆ›å»ºæ¨¡æ‹ŸQwen lm_headç”¨äºæµ‹è¯•")
    
    # 3. æ‰§è¡Œç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–
    print("\næ‰§è¡Œç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–...")
    dummy_median = 50.0  # è¿™ä¸ªå€¼åº”è¯¥è¢«å¿½ç•¥
    dummy_scale = 25.0   # è¿™ä¸ªå€¼åº”è¯¥è¢«å¿½ç•¥
    
    action_net.init_weights(mock_qwen_lm_head, dummy_median, dummy_scale, num_token_id)
    
    # 4. éªŒè¯åˆ†ç±»å¤´åç½®
    print(f"\nğŸ” éªŒè¯åˆ†ç±»å¤´åç½®:")
    cls_head = action_net.classification_head.causal_linear
    cls_bias = cls_head.bias.data if cls_head.bias is not None else None
    
    if cls_bias is not None:
        bias_zero_check = torch.allclose(cls_bias, torch.zeros_like(cls_bias), atol=1e-6)
        print(f"  æ‰€æœ‰åç½®æ˜¯å¦ä¸º0: {'âœ…' if bias_zero_check else 'âŒ'}")
        print(f"  åç½®ç»Ÿè®¡: å‡å€¼={cls_bias.mean().item():.6f}, æœ€å¤§ç»å¯¹å€¼={cls_bias.abs().max().item():.6f}")
        
        # æ£€æŸ¥<NUM> token
        num_bias = cls_bias[num_token_id].item()
        print(f"  <NUM> tokenåç½®: {num_bias:.6f} (åº”è¯¥æ˜¯0.0)")
        
        if bias_zero_check:
            print(f"  âœ… ç¬¬ä¸€æ€§åŸç†éªŒè¯é€šè¿‡")
        else:
            print(f"  âŒ å‘ç°éé›¶åç½®")
            # è¾“å‡ºä¸€äº›éé›¶åç½®çš„ä¾‹å­
            non_zero_indices = torch.nonzero(cls_bias.abs() > 1e-6).flatten()
            if len(non_zero_indices) > 0:
                print(f"  éé›¶åç½®æ ·æœ¬: {[(i.item(), cls_bias[i].item()) for i in non_zero_indices[:5]]}")
    else:
        print(f"  âŒ åˆ†ç±»å¤´æ²¡æœ‰åç½®å±‚")
    
    # 5. éªŒè¯å›å½’å¤´åç½®
    print(f"\nğŸ” éªŒè¯å›å½’å¤´åç½®:")
    reg_head = action_net.regression_head.causal_linear
    reg_bias = reg_head.bias.data if reg_head.bias is not None else None
    
    if reg_bias is not None:
        reg_bias_zero = torch.allclose(reg_bias, torch.zeros_like(reg_bias), atol=1e-6)
        print(f"  å›å½’åç½®æ˜¯å¦ä¸º0: {'âœ…' if reg_bias_zero else 'âŒ'}")
        print(f"  å›å½’åç½®å€¼: {reg_bias.item():.6f} (åº”è¯¥æ˜¯0.0)")
        
        if reg_bias_zero:
            print(f"  âœ… ç¬¬ä¸€æ€§åŸç†éªŒè¯é€šè¿‡")
        else:
            print(f"  âŒ å‘ç°éé›¶å›å½’åç½®")
    else:
        print(f"  âŒ å›å½’å¤´æ²¡æœ‰åç½®å±‚")
    
    # 6. æ€»ç»“
    print(f"\n" + "=" * 60)
    print(f"=   æµ‹è¯•æ€»ç»“   =")
    print(f"=" * 60)
    
    success = True
    if cls_bias is not None:
        if bias_zero_check:
            print(f"âœ… åˆ†ç±»å¤´åç½®: ç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–æˆåŠŸ")
        else:
            print(f"âŒ åˆ†ç±»å¤´åç½®: åˆå§‹åŒ–å¤±è´¥ï¼Œå­˜åœ¨éé›¶åç½®")
            success = False
    
    if reg_bias is not None:
        if reg_bias_zero:
            print(f"âœ… å›å½’å¤´åç½®: ç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–æˆåŠŸ")
        else:
            print(f"âŒ å›å½’å¤´åç½®: åˆå§‹åŒ–å¤±è´¥ï¼Œå­˜åœ¨éé›¶åç½®")
            success = False
    
    if success:
        print(f"\nğŸ‰ ç¬¬ä¸€æ€§åŸç†åˆå§‹åŒ–æµ‹è¯•é€šè¿‡!")
        print(f"   æ‰€æœ‰åç½®éƒ½æ­£ç¡®è®¾ç½®ä¸º0")
        print(f"   ç§»é™¤äº†é­”æ³•æ•°å­—åè§")
    else:
        print(f"\nâš ï¸  æµ‹è¯•å¤±è´¥: åˆå§‹åŒ–æ²¡æœ‰æŒ‰ç…§ç¬¬ä¸€æ€§åŸç†æ‰§è¡Œ")
    
    return success

if __name__ == "__main__":
    success = test_action_network_init()
    exit(0 if success else 1) 