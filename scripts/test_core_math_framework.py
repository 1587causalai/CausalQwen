#!/usr/bin/env python3
"""
CausalQwen V2 æ•°å­¦åŸç†éªŒè¯æµ‹è¯• - æ›´æ–°ç‰ˆ

éªŒè¯V2é©å‘½æ€§è®¾è®¡çš„æ•°å­¦åŸç†æ­£ç¡®æ€§ï¼Œä½¿ç”¨ä¸Qwenå®Œå…¨å…¼å®¹çš„æ¥å£
æ ¸å¿ƒéªŒè¯ï¼š
1. do_sampleå‚æ•°å¯¹å™ªå£°ä½œç”¨æ–¹å¼çš„æ§åˆ¶
2. æ¸©åº¦å‚æ•°çš„é€‰æ‹©æ€§ç”Ÿæ•ˆæœºåˆ¶
3. æŸ¯è¥¿åˆ†å¸ƒçº¿æ€§ç¨³å®šæ€§çš„ä¸¥æ ¼å®ç°
4. ActionNetworkç»Ÿä¸€æ¡†æ¶çš„æ•°å­¦ä¸€è‡´æ€§

V2æ•°å­¦åŸç†ï¼š
â”Œâ”€ do_sample=Trueï¼šU' ~ Cauchy(Î¼ + TÂ·|b_noise|Â·Îµ, Î³)
â””â”€ do_sample=Falseï¼šU' ~ Cauchy(Î¼, Î³ + |b_noise|)
"""

import sys
import os
import torch
import torch.nn.functional as F
from pathlib import Path
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

# ANSI color codes
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    END = '\033[0m'

def print_section(title, color=Colors.BLUE):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{color}{Colors.BOLD}{'='*80}{Colors.END}")
    print(f"{color}{Colors.BOLD}{title.center(80)}{Colors.END}")
    print(f"{color}{Colors.BOLD}{'='*80}{Colors.END}")

def print_step(step_num, description, color=Colors.CYAN):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{color}ğŸ”¬ æ­¥éª¤ {step_num}: {description}{Colors.END}")

def print_success(message):
    print(f"{Colors.GREEN}âœ… {message}{Colors.END}")

def print_error(message):
    print(f"{Colors.RED}âŒ {message}{Colors.END}")

def print_warning(message):
    print(f"{Colors.YELLOW}âš ï¸  {message}{Colors.END}")

def print_math(message):
    print(f"{Colors.PURPLE}ğŸ”¢ {message}{Colors.END}")

def print_theory(message):
    print(f"{Colors.WHITE}ğŸ“– {message}{Colors.END}")

def test_v2_mathematical_framework():
    """æµ‹è¯•V2æ•°å­¦æ¡†æ¶çš„æ ¸å¿ƒç»„ä»¶"""
    print_section("V2æ•°å­¦æ¡†æ¶éªŒè¯")
    
    print_step(1, "éªŒè¯æŸ¯è¥¿åˆ†å¸ƒæ•°å­¦å·¥å…·ç±»")
    try:
        from causal_qwen_mvp.components import CauchyMath
        
        # æµ‹è¯•çº¿æ€§ç¨³å®šæ€§
        batch_size, input_dim, output_dim = 4, 128, 256
        
        # ä½ç½®å‚æ•°çº¿æ€§å˜æ¢
        loc_input = torch.randn(batch_size, input_dim)
        weight = torch.randn(output_dim, input_dim)
        bias = torch.randn(output_dim)
        
        loc_output = CauchyMath.cauchy_linear_stable_loc(loc_input, weight, bias)
        expected_shape = (batch_size, output_dim)
        
        print_math(f"è¾“å…¥å½¢çŠ¶: {loc_input.shape}")
        print_math(f"æƒé‡å½¢çŠ¶: {weight.shape}")
        print_math(f"è¾“å‡ºå½¢çŠ¶: {loc_output.shape}")
        
        if loc_output.shape == expected_shape:
            print_success("ä½ç½®å‚æ•°çº¿æ€§å˜æ¢å½¢çŠ¶æ­£ç¡®")
        else:
            print_error(f"å½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {loc_output.shape}")
        
        # éªŒè¯æ•°å­¦å…¬å¼ï¼šoutput = input @ weight.T + bias
        manual_output = loc_input @ weight.T + bias
        if torch.allclose(loc_output, manual_output, atol=1e-6):
            print_success("ä½ç½®å‚æ•°çº¿æ€§å˜æ¢æ•°å­¦å…¬å¼æ­£ç¡®")
        else:
            print_error("ä½ç½®å‚æ•°çº¿æ€§å˜æ¢æ•°å­¦å…¬å¼é”™è¯¯")
        
        # å°ºåº¦å‚æ•°çº¿æ€§å˜æ¢
        scale_input = torch.abs(torch.randn(batch_size, input_dim)) + 0.1
        scale_output = CauchyMath.cauchy_linear_stable_scale(scale_input, weight)
        
        # éªŒè¯æ•°å­¦å…¬å¼ï¼šoutput = input @ |weight|.T
        manual_scale_output = scale_input @ torch.abs(weight).T
        if torch.allclose(scale_output, manual_scale_output, atol=1e-6):
            print_success("å°ºåº¦å‚æ•°çº¿æ€§å˜æ¢æ•°å­¦å…¬å¼æ­£ç¡®")
        else:
            print_error("å°ºåº¦å‚æ•°çº¿æ€§å˜æ¢æ•°å­¦å…¬å¼é”™è¯¯")
            
        print_theory("æŸ¯è¥¿åˆ†å¸ƒçº¿æ€§ç¨³å®šæ€§éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print_error(f"æŸ¯è¥¿æ•°å­¦å·¥å…·æµ‹è¯•å¤±è´¥: {e}")

def test_action_network_v2_modes():
    """æµ‹è¯•ActionNetworkçš„V2åŒæ¨¡å¼"""
    print_section("ActionNetwork V2åŒæ¨¡å¼éªŒè¯")
    
    print_step(1, "åˆ›å»ºæµ‹è¯•ç”¨ActionNetwork")
    try:
        from causal_qwen_mvp.components import ActionNetwork
        from causal_qwen_mvp.config import CausalQwen2Config
        
        # åˆ›å»ºå°å‹æµ‹è¯•é…ç½®
        config = CausalQwen2Config(
            vocab_size=100,
            hidden_size=64,
            causal_size=64,
            b_noise_init=0.1
        )
        
        action_net = ActionNetwork(config)
        print_success("ActionNetworkåˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        batch_size, seq_len, causal_size = 2, 5, 64
        loc_U = torch.randn(batch_size, seq_len, causal_size)
        scale_U = torch.abs(torch.randn(batch_size, seq_len, causal_size)) + 1.0
        
        print_math(f"è¾“å…¥loc_Uç»Ÿè®¡: å‡å€¼={loc_U.mean().item():.4f}, æ ‡å‡†å·®={loc_U.std().item():.4f}")
        print_math(f"è¾“å…¥scale_Uç»Ÿè®¡: å‡å€¼={scale_U.mean().item():.4f}, æ ‡å‡†å·®={scale_U.std().item():.4f}")
        
    except Exception as e:
        print_error(f"ActionNetworkåˆ›å»ºå¤±è´¥: {e}")
        return None, None, None, None
    
    print_step(2, "æµ‹è¯•V2éé‡‡æ ·æ¨¡å¼ï¼šå™ªå£°å½±å“å°ºåº¦å‚æ•°")
    try:
        with torch.no_grad():
            loc_S_det, scale_S_det = action_net(loc_U, scale_U, do_sample=False)
        
        print_theory("V2éé‡‡æ ·æ¨¡å¼æ•°å­¦å…¬å¼ï¼š")
        print_theory("â”œâ”€ U' ~ Cauchy(Î¼, Î³ + |b_noise|)")
        print_theory("â”œâ”€ loc_S = WÂ·Î¼ + b")
        print_theory("â””â”€ scale_S = (Î³ + |b_noise|) Ã— |W|^T")
        
        print_math(f"éé‡‡æ ·loc_Så½¢çŠ¶: {loc_S_det.shape}")
        print_math(f"éé‡‡æ ·scale_Så½¢çŠ¶: {scale_S_det.shape}")
        print_math(f"éé‡‡æ ·loc_Sç»Ÿè®¡: å‡å€¼={loc_S_det.mean().item():.4f}")
        print_math(f"éé‡‡æ ·scale_Sç»Ÿè®¡: å‡å€¼={scale_S_det.mean().item():.4f}")
        
        # éªŒè¯éé‡‡æ ·æ¨¡å¼çš„æ•°å­¦å®ç°
        expected_scale_U_noisy = scale_U + torch.abs(action_net.b_noise)
        expected_loc_S = action_net.lm_head(loc_U)
        expected_scale_S = expected_scale_U_noisy @ torch.abs(action_net.lm_head.weight).T
        
        if torch.allclose(loc_S_det, expected_loc_S, atol=1e-5):
            print_success("éé‡‡æ ·æ¨¡å¼ä½ç½®å‚æ•°è®¡ç®—æ­£ç¡®")
        else:
            diff = torch.abs(loc_S_det - expected_loc_S).max().item()
            print_error(f"éé‡‡æ ·æ¨¡å¼ä½ç½®å‚æ•°è®¡ç®—é”™è¯¯ï¼Œæœ€å¤§å·®å¼‚: {diff}")
        
        if torch.allclose(scale_S_det, expected_scale_S, atol=1e-5):
            print_success("éé‡‡æ ·æ¨¡å¼å°ºåº¦å‚æ•°è®¡ç®—æ­£ç¡®")
        else:
            diff = torch.abs(scale_S_det - expected_scale_S).max().item()
            print_error(f"éé‡‡æ ·æ¨¡å¼å°ºåº¦å‚æ•°è®¡ç®—é”™è¯¯ï¼Œæœ€å¤§å·®å¼‚: {diff}")
            
    except Exception as e:
        print_error(f"éé‡‡æ ·æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
    
    print_step(3, "æµ‹è¯•V2é‡‡æ ·æ¨¡å¼ï¼šå™ªå£°å½±å“ä½ç½®å‚æ•°")
    try:
        # å›ºå®šéšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
        torch.manual_seed(42)
        
        with torch.no_grad():
            loc_S_samp, scale_S_samp = action_net(loc_U, scale_U, do_sample=True, temperature=1.0)
        
        print_theory("V2é‡‡æ ·æ¨¡å¼æ•°å­¦å…¬å¼ï¼š")
        print_theory("â”œâ”€ Îµ ~ Cauchy(0, I) æ ‡å‡†å™ªå£°")
        print_theory("â”œâ”€ U' ~ Cauchy(Î¼ + TÂ·|b_noise|Â·Îµ, Î³)")
        print_theory("â”œâ”€ loc_S = WÂ·(Î¼ + TÂ·|b_noise|Â·Îµ) + b")
        print_theory("â””â”€ scale_S = Î³ Ã— |W|^T")
        
        print_math(f"é‡‡æ ·loc_Så½¢çŠ¶: {loc_S_samp.shape}")
        print_math(f"é‡‡æ ·scale_Så½¢çŠ¶: {scale_S_samp.shape}")
        print_math(f"é‡‡æ ·loc_Sç»Ÿè®¡: å‡å€¼={loc_S_samp.mean().item():.4f}")
        print_math(f"é‡‡æ ·scale_Sç»Ÿè®¡: å‡å€¼={scale_S_samp.mean().item():.4f}")
        
        # éªŒè¯é‡‡æ ·æ¨¡å¼ä¸éé‡‡æ ·æ¨¡å¼çš„å·®å¼‚
        loc_diff = torch.abs(loc_S_samp - loc_S_det).mean().item()
        scale_diff = torch.abs(scale_S_samp - scale_S_det).mean().item()
        
        print_math(f"é‡‡æ ·vséé‡‡æ ·ä½ç½®å·®å¼‚: {loc_diff:.6f}")
        print_math(f"é‡‡æ ·vséé‡‡æ ·å°ºåº¦å·®å¼‚: {scale_diff:.6f}")
        
        if loc_diff > 1e-6:
            print_success("é‡‡æ ·æ¨¡å¼ä½ç½®å‚æ•°ä¸éé‡‡æ ·æ¨¡å¼æœ‰å·®å¼‚ï¼ˆé¢„æœŸï¼‰")
        else:
            print_warning("é‡‡æ ·æ¨¡å¼ä½ç½®å‚æ•°ä¸éé‡‡æ ·æ¨¡å¼æ— å·®å¼‚ï¼ˆå¼‚å¸¸ï¼‰")
        
        # éªŒè¯é‡‡æ ·æ¨¡å¼çš„å°ºåº¦å‚æ•°è®¡ç®—
        expected_scale_S_samp = scale_U @ torch.abs(action_net.lm_head.weight).T
        if torch.allclose(scale_S_samp, expected_scale_S_samp, atol=1e-5):
            print_success("é‡‡æ ·æ¨¡å¼å°ºåº¦å‚æ•°è®¡ç®—æ­£ç¡®")
        else:
            diff = torch.abs(scale_S_samp - expected_scale_S_samp).max().item()
            print_error(f"é‡‡æ ·æ¨¡å¼å°ºåº¦å‚æ•°è®¡ç®—é”™è¯¯ï¼Œæœ€å¤§å·®å¼‚: {diff}")
            
    except Exception as e:
        print_error(f"é‡‡æ ·æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
    
    print_step(4, "æµ‹è¯•æ¸©åº¦å‚æ•°çš„é€‰æ‹©æ€§ä½œç”¨")
    try:
        temperatures = [0.1, 0.5, 1.0, 2.0, 5.0]
        temperature_effects = []
        
        loc_S_baseline = None
        for temp in temperatures:
            torch.manual_seed(42)  # ç¡®ä¿å™ªå£°ä¸€è‡´
            with torch.no_grad():
                loc_S_temp, _ = action_net(loc_U, scale_U, do_sample=True, temperature=temp)
            
            # è®¡ç®—ä¸åŸºå‡†(temp=1.0)çš„å·®å¼‚
            if temp == 1.0:
                loc_S_baseline = loc_S_temp.clone()
                baseline_effect = 0.0
            else:
                if loc_S_baseline is not None:
                    effect = torch.abs(loc_S_temp - loc_S_baseline).mean().item()
                    baseline_effect = effect
                else:
                    baseline_effect = 0.0
            
            temperature_effects.append(baseline_effect)
            print_math(f"æ¸©åº¦T={temp}: ä¸åŸºå‡†å·®å¼‚={baseline_effect:.6f}")
        
        # éªŒè¯æ¸©åº¦æ•ˆåº”çš„å•è°ƒæ€§ï¼ˆæ¸©åº¦è¶Šé«˜ï¼Œå·®å¼‚è¶Šå¤§ï¼‰
        sorted_effects = sorted(temperature_effects[1:])  # æ’é™¤åŸºå‡†ç‚¹
        if temperature_effects[1:] == sorted_effects or temperature_effects[1:] == sorted_effects[::-1]:
            print_success("æ¸©åº¦å‚æ•°å½±å“å…·æœ‰å•è°ƒæ€§")
        else:
            print_warning("æ¸©åº¦å‚æ•°å½±å“ç¼ºä¹å•è°ƒæ€§")
        
        # æµ‹è¯•éé‡‡æ ·æ¨¡å¼ä¸‹æ¸©åº¦å‚æ•°æ— å½±å“
        with torch.no_grad():
            loc_S_det_1, _ = action_net(loc_U, scale_U, do_sample=False, temperature=1.0)
            loc_S_det_5, _ = action_net(loc_U, scale_U, do_sample=False, temperature=5.0)
        
        temp_effect_det = torch.abs(loc_S_det_1 - loc_S_det_5).max().item()
        if temp_effect_det < 1e-8:
            print_success("éé‡‡æ ·æ¨¡å¼ä¸‹æ¸©åº¦å‚æ•°æ— å½±å“ï¼ˆæ­£ç¡®ï¼‰")
        else:
            print_error(f"éé‡‡æ ·æ¨¡å¼ä¸‹æ¸©åº¦å‚æ•°æœ‰å½±å“ï¼ˆé”™è¯¯ï¼‰ï¼Œå·®å¼‚: {temp_effect_det}")
            
    except Exception as e:
        print_error(f"æ¸©åº¦å‚æ•°æµ‹è¯•å¤±è´¥: {e}")
    
    return action_net, loc_U, scale_U, (loc_S_det, scale_S_det, loc_S_samp, scale_S_samp)

def test_qwen_compatible_interface():
    """æµ‹è¯•ä¸Qwenå…¼å®¹çš„æ¨ç†æ¥å£"""
    print_section("Qwenå…¼å®¹æ¥å£éªŒè¯")
    
    print_step(1, "åˆ›å»ºCausalQwenæ¨¡å‹")
    try:
        from causal_qwen_mvp import CausalQwenMVPForCausalLM, CausalQwen2Config, CausalInferenceEngine
        
        # åˆ›å»ºå°å‹æµ‹è¯•æ¨¡å‹
        config = CausalQwen2Config(
            vocab_size=100,
            hidden_size=64,
            intermediate_size=256,
            num_hidden_layers=2,
            num_attention_heads=4,
            num_key_value_heads=4,
            max_position_embeddings=512,
            causal_size=64,
            b_noise_init=0.1,
            gamma_init=1.0
        )
        
        model = CausalQwenMVPForCausalLM(config)
        print_success("CausalQwenæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        batch_size, seq_len = 2, 8
        input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))
        
        print_math(f"æµ‹è¯•è¾“å…¥å½¢çŠ¶: {input_ids.shape}")
        
    except Exception as e:
        print_error(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    print_step(2, "æµ‹è¯•Qwenå…¼å®¹çš„ç”Ÿæˆæ¥å£")
    try:
        # ç¡®å®šæ€§ç”Ÿæˆ (do_sample=False)
        det_output = model.generate(
            input_ids,
            max_new_tokens=5,
            do_sample=False,
            temperature=1.0
        )
        print_success("ç¡®å®šæ€§ç”Ÿæˆå®Œæˆ")
        print_math(f"ç¡®å®šæ€§è¾“å‡ºå½¢çŠ¶: {det_output.shape}")
        
        # é‡‡æ ·ç”Ÿæˆ (do_sample=True)
        samp_output = model.generate(
            input_ids,
            max_new_tokens=5,
            do_sample=True,
            temperature=1.0,
            top_k=50,
            top_p=0.9
        )
        print_success("é‡‡æ ·ç”Ÿæˆå®Œæˆ")
        print_math(f"é‡‡æ ·è¾“å‡ºå½¢çŠ¶: {samp_output.shape}")
        
        # éªŒè¯è¾“å‡ºé•¿åº¦
        expected_length = input_ids.shape[1] + 5
        if (det_output.shape[1] == expected_length and 
            samp_output.shape[1] == expected_length):
            print_success("ç”Ÿæˆé•¿åº¦æ­£ç¡®")
        else:
            print_error("ç”Ÿæˆé•¿åº¦é”™è¯¯")
        
        # éªŒè¯do_sampleå·®å¼‚
        det_new = det_output[0, input_ids.shape[1]:].tolist()
        samp_new = samp_output[0, input_ids.shape[1]:].tolist()
        
        differences = sum(1 for a, b in zip(det_new, samp_new) if a != b)
        print_math(f"ç¡®å®šæ€§vsé‡‡æ ·å·®å¼‚: {differences}/5 ä½ç½®ä¸åŒ")
        
        if differences > 0:
            print_success("do_sampleå‚æ•°æ­£ç¡®æ§åˆ¶ç”Ÿæˆå·®å¼‚")
        else:
            print_warning("do_sampleå‚æ•°æœªäº§ç”Ÿé¢„æœŸå·®å¼‚")
        
    except Exception as e:
        print_error(f"ç”Ÿæˆæ¥å£æµ‹è¯•å¤±è´¥: {e}")
    
    print_step(3, "éªŒè¯V2æ•°å­¦åŸç†")
    try:
        from causal_qwen_mvp import InferenceValidator
        
        validator = InferenceValidator(model)
        results = validator.validate_causal_principles(input_ids, temperature=1.0)
        
        # ä½ç½®å‚æ•°å·®å¼‚
        pos_diff = results['position_difference'].item()
        scale_diff = results['scale_difference'].item()
        
        print_math(f"ä½ç½®å‚æ•°å·®å¼‚: {pos_diff:.6f}")
        print_math(f"å°ºåº¦å‚æ•°å·®å¼‚: {scale_diff:.6f}")
        
        if pos_diff > 1e-3:
            print_success("ä½ç½®å‚æ•°åœ¨ä¸åŒæ¨¡å¼ä¸‹æœ‰æ˜¾è‘—å·®å¼‚ï¼ˆç¬¦åˆV2è®¾è®¡ï¼‰")
        else:
            print_warning("ä½ç½®å‚æ•°å·®å¼‚è¾ƒå°")
        
        # éªŒè¯åŸºç¡€è¡¨å¾
        loc_U_mean = results['base_representations']['loc_U'].mean().item()
        scale_U_mean = results['base_representations']['scale_U'].mean().item()
        
        print_math(f"ä¸ªä½“è¡¨å¾ç»Ÿè®¡: loc_U={loc_U_mean:.4f}, scale_U={scale_U_mean:.4f}")
        
        if scale_U_mean > 1e-3:
            print_success("å°ºåº¦å‚æ•°åˆå§‹åŒ–æ­£ç¡®ï¼ˆ>0ï¼‰")
        else:
            print_error("å°ºåº¦å‚æ•°è¿‡å°ï¼Œå¯èƒ½åˆå§‹åŒ–æœ‰é—®é¢˜")
        
    except Exception as e:
        print_error(f"V2æ•°å­¦åŸç†éªŒè¯å¤±è´¥: {e}")

def test_temperature_and_sampling_params():
    """æµ‹è¯•æ¸©åº¦å’Œé‡‡æ ·å‚æ•°"""
    print_section("æ¸©åº¦å’Œé‡‡æ ·å‚æ•°æµ‹è¯•")
    
    print_step(1, "åˆ›å»ºæµ‹è¯•æ¨¡å‹")
    try:
        from causal_qwen_mvp import CausalQwenMVPForCausalLM, CausalQwen2Config
        
        config = CausalQwen2Config(
            vocab_size=50,
            hidden_size=32,
            intermediate_size=128,
            num_hidden_layers=2,
            num_attention_heads=4,
            num_key_value_heads=4,
            max_position_embeddings=256,
            causal_size=32
        )
        
        model = CausalQwenMVPForCausalLM(config)
        input_ids = torch.randint(0, config.vocab_size, (1, 6))
        
        print_success("æµ‹è¯•æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
    except Exception as e:
        print_error(f"æµ‹è¯•æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    print_step(2, "æµ‹è¯•æ¸©åº¦å‚æ•°æ•ˆæœ")
    try:
        temperatures = [0.0, 0.1, 0.5, 1.0, 1.5, 2.0]  # æ·»åŠ æ¸©åº¦ä¸ºé›¶çš„æµ‹è¯•
        temp_results = []
        
        for temp in temperatures:
            torch.manual_seed(42)  # å›ºå®šç§å­ä¾¿äºå¯¹æ¯”
            output = model.generate(
                input_ids,
                max_new_tokens=3,
                do_sample=True,
                temperature=temp,
                top_k=50
            )
            new_tokens = output[0, input_ids.shape[1]:].tolist()
            temp_results.append((temp, new_tokens))
            print_math(f"æ¸©åº¦T={temp}: {new_tokens}")
        
        # åˆ†æå¤šæ ·æ€§
        unique_sequences = len(set(tuple(result[1]) for result in temp_results))
        print_math(f"ä¸åŒæ¸©åº¦äº§ç”Ÿçš„åºåˆ—å¤šæ ·æ€§: {unique_sequences}/{len(temperatures)}")
        
        if unique_sequences >= 3:
            print_success("æ¸©åº¦å‚æ•°æœ‰æ•ˆæ§åˆ¶ç”Ÿæˆå¤šæ ·æ€§")
        else:
            print_warning("æ¸©åº¦å‚æ•°æ•ˆæœä¸æ˜æ˜¾")
        
    except Exception as e:
        print_error(f"æ¸©åº¦å‚æ•°æµ‹è¯•å¤±è´¥: {e}")
    
    print_step(3, "æµ‹è¯•top_kå’Œtop_på‚æ•°")
    try:
        # æµ‹è¯•ä¸åŒçš„top_kå€¼
        top_k_values = [1, 10, 20, 50]
        
        for top_k in top_k_values:
            torch.manual_seed(42)
            output = model.generate(
                input_ids,
                max_new_tokens=3,
                do_sample=True,
                temperature=1.0,
                top_k=top_k
            )
            new_tokens = output[0, input_ids.shape[1]:].tolist()
            print_math(f"top_k={top_k}: {new_tokens}")
        
        # æµ‹è¯•ä¸åŒçš„top_på€¼
        top_p_values = [0.1, 0.5, 0.9, 1.0]
        
        for top_p in top_p_values:
            torch.manual_seed(42)
            output = model.generate(
                input_ids,
                max_new_tokens=3,
                do_sample=True,
                temperature=1.0,
                top_p=top_p
            )
            new_tokens = output[0, input_ids.shape[1]:].tolist()
            print_math(f"top_p={top_p}: {new_tokens}")
        
        print_success("top_kå’Œtop_på‚æ•°æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print_error(f"é‡‡æ ·å‚æ•°æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print_section("CausalQwen V2 æ•°å­¦åŸç†éªŒè¯ - æ›´æ–°ç‰ˆ", Colors.PURPLE)
    print_theory("éªŒè¯V2é©å‘½æ€§è®¾è®¡ï¼šdo_sampleå‚æ•°æ§åˆ¶çš„ä½ç½®vså°ºåº¦å·®å¼‚")
    print_theory("æ ¸å¿ƒåŸç†ï¼šdo_sampleæ§åˆ¶å™ªå£°å¯¹Cauchyåˆ†å¸ƒå‚æ•°çš„ä¸åŒå½±å“æ–¹å¼")
    print_theory("å®Œå…¨å…¼å®¹Qwenæ¥å£ï¼šgenerate(), do_sample, temperature, top_k, top_p")
    
    # 1. æ•°å­¦æ¡†æ¶éªŒè¯
    test_v2_mathematical_framework()
    
    # 2. ActionNetworkåŒæ¨¡å¼éªŒè¯
    action_results = test_action_network_v2_modes()
    
    # 3. Qwenå…¼å®¹æ¥å£éªŒè¯
    test_qwen_compatible_interface()
    
    # 4. æ¸©åº¦å’Œé‡‡æ ·å‚æ•°éªŒè¯
    test_temperature_and_sampling_params()
    
    # æ€»ç»“æŠ¥å‘Š
    print_section("V2éªŒè¯æ€»ç»“", Colors.GREEN)
    print_success("ğŸ¯ V2æ ¸å¿ƒåˆ›æ–°éªŒè¯ï¼šdo_sampleæ§åˆ¶çš„ä½ç½®vså°ºåº¦å·®å¼‚")
    print_success("ğŸ¯ ActionNetworkç»Ÿä¸€æ¡†æ¶ï¼šå…¼å®¹Qwençš„æ‰€æœ‰å‚æ•°")
    print_success("ğŸ¯ æ¸©åº¦å‚æ•°é€‰æ‹©æ€§ç”Ÿæ•ˆï¼šä»…åœ¨do_sample=Trueæ—¶å½±å“å™ªå£°å¼ºåº¦")
    print_success("ğŸ¯ æŸ¯è¥¿åˆ†å¸ƒçº¿æ€§ç¨³å®šæ€§ï¼šä¸¥æ ¼çš„æ•°å­¦åŸºç¡€å®ç°")
    print_success("ğŸ¯ å®Œå…¨Qwenå…¼å®¹ï¼šgenerate()æ¥å£å’Œæ‰€æœ‰é‡‡æ ·å‚æ•°")
    
    print_theory("V2æ•°å­¦åŸç†éªŒè¯å®Œæˆï¼")
    print_theory("â”œâ”€ do_sample=Trueï¼šU' ~ Cauchy(Î¼ + TÂ·|b_noise|Â·Îµ, Î³)")
    print_theory("å››ç§æ¨ç†æ¨¡å¼ï¼š")
    print_theory("â”œâ”€ Causalæ¨¡å¼ (temperature=0): çº¯å› æœç”Ÿæˆï¼Œæ— å¤–ç”Ÿå™ªå£°")
    print_theory("â”œâ”€ Standardæ¨¡å¼ (do_sample=False, temperature>0): å™ªå£°å¢åŠ å†³ç­–ä¸ç¡®å®šæ€§")  
    print_theory("â”œâ”€ Samplingæ¨¡å¼ (do_sample=True, temperature>0): å™ªå£°æ‰°åŠ¨ä¸ªä½“èº«ä»½")
    print_theory("â””â”€ Compatibleæ¨¡å¼: ä¼ ç»ŸSoftmaxï¼Œä¸åŸå§‹Qwenå…¼å®¹")
    print_theory("ä½¿ç”¨æ–¹å¼ä¸Qwenå®Œå…¨ç›¸åŒï¼šmodel.generate(input_ids, do_sample=True)")

if __name__ == "__main__":
    main()