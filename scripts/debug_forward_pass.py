#!/usr/bin/env python
"""
å› æœè¯­è¨€æ¨¡å‹çš„å‰å‘ä¼ æ’­è°ƒè¯•è„šæœ¬ (V6: æ·±åº¦åˆ†æç‰ˆ)

ä¸“æ³¨äºéªŒè¯å‰å‘ä¼ æ’­ä¸­æ¯ä¸ªæ ¸å¿ƒç»„ä»¶çš„æ•°å­¦é€»è¾‘å’Œæ•°æ®æµã€‚
"""
import os
import sys
import torch
import numpy as np

# Add project root to Python path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def print_step(step_num, description):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{'='*70}")
    print(f"â¡ï¸  æ­¥éª¤ {step_num}: {description}")
    print(f"{'='*70}")

def print_tensor_stats(name, tensor):
    """æ‰“å°å¼ é‡çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼Œä½¿ç”¨å¯¹æŸ¯è¥¿åˆ†å¸ƒé²æ£’çš„æŒ‡æ ‡ã€‚"""
    if not isinstance(tensor, torch.Tensor):
        print(f"   - {name}: Not a tensor")
        return
    
    # ç»Ÿä¸€è½¬æ¢åˆ°CPUå’Œfloat32è¿›è¡Œåˆ†æ
    tensor = tensor.detach().cpu().to(torch.float32)
    
    # å¯¹äºç±»æŸ¯è¥¿åˆ†å¸ƒï¼Œä¸­ä½æ•°å’ŒIQRæ˜¯æ›´é²æ£’çš„ç»Ÿè®¡é‡
    median = torch.median(tensor).item()
    q1 = torch.quantile(tensor, 0.25).item()
    q3 = torch.quantile(tensor, 0.75).item()
    iqr = q3 - q1

    print(f"   - {name}:")
    print(f"     - Shape:  {tensor.shape}")
    print(f"     - Has NaN: {torch.isnan(tensor).any().item()}")
    print(f"     - Has Inf: {torch.isinf(tensor).any().item()}")
    print(f"     - Median: {median:.6f} (ä¸­ä½æ•°)")
    print(f"     - IQR:    {iqr:.6f} (å››åˆ†ä½è·)")

def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œè°ƒè¯•å‰å‘ä¼ æ’­ã€‚"""
    try:
        print("ğŸš€ CausalQwen å‰å‘ä¼ æ’­è°ƒè¯•è„šæœ¬ (æ·±åº¦åˆ†æç‰ˆ)")
        print("=" * 80)

        # æ­¥éª¤1: åŸºæœ¬å¯¼å…¥æµ‹è¯•
        print_step(1, "æµ‹è¯•åŸºæœ¬å¯¼å…¥")
        from src.models.causal_lm import CausalLMConfig, CausalLanguageModel
        from src.data.tokenizer import QwenTokenizerWrapper
        print("âœ… å¯¼å…¥æˆåŠŸ")

        # æ­¥éª¤2: ç¯å¢ƒå’Œè·¯å¾„æ£€æŸ¥
        print_step(2, "ç¯å¢ƒå’Œè·¯å¾„æ£€æŸ¥")
        device = torch.device('cpu')
        qwen_model_path = os.path.expanduser('~/models/Qwen2.5-0.5B')
        print(f"è®¾å¤‡: {device}")
        print(f"Qwenè·¯å¾„: {qwen_model_path}")
        assert os.path.exists(qwen_model_path), "Qwenæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨"
        print(f"âœ… Qwenæ¨¡å‹è·¯å¾„å­˜åœ¨")

        # æ­¥éª¤3: åˆ†è¯å™¨å’Œæ¨¡å‹ä¿¡æ¯
        print_step(3, "åˆ†è¯å™¨å’Œæ¨¡å‹ä¿¡æ¯åˆå§‹åŒ–")
        tokenizer = QwenTokenizerWrapper(model_path=qwen_model_path, use_real_tokenizer=True)
        print(f"âœ… åˆ†è¯å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        from src.utils.model_utils import get_qwen_model_info
        model_info = get_qwen_model_info(qwen_model_path)
        assert model_info is not None, "æ— æ³•è·å–Qwenæ¨¡å‹ä¿¡æ¯"
        print("âœ… æˆåŠŸä»æ¨¡å‹é…ç½®è·å–ä¿¡æ¯")
        print(f"   - æ¨¡å‹é…ç½®è¯æ±‡è¡¨å¤§å°: {model_info['vocab_size']}")
        print(f"   - <NUM> token ID: {tokenizer.num_token_id}")

        # æ­¥éª¤4: æ¨¡å‹é…ç½®
        print_step(4, "æ¨¡å‹é…ç½®åˆ›å»º")
        config = CausalLMConfig(
            vocab_size=model_info['vocab_size'], # ä½¿ç”¨ä»é…ç½®ä¸­è¯»å–çš„æƒå¨è¯æ±‡è¡¨å¤§å°
            num_token_id=tokenizer.num_token_id,
            hidden_size=model_info['hidden_size'],
            causal_dim=model_info['hidden_size'],
            use_real_qwen=True,
            qwen_model_path=qwen_model_path,
            use_numerical_features=True # ç¡®ä¿æ•°å€¼åŠŸèƒ½å¼€å¯
        )
        print(f"âœ… é…ç½®åˆ›å»ºæˆåŠŸ")

        # æ­¥éª¤5: æ¨¡å‹åˆ›å»ºä¸åˆå§‹åŒ–
        print_step(5, "æ¨¡å‹åˆ›å»ºä¸åˆå§‹åŒ–")
        model = CausalLanguageModel(config).to(device)
        model.init_weights()
        print(f"âœ… æ¨¡å‹åˆ›å»ºä¸åˆå§‹åŒ–æˆåŠŸ")
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   - æ€»å‚æ•°æ•°é‡: {total_params:,}")

        # æ­¥éª¤6: æµ‹è¯•æ•°æ®å‡†å¤‡
        print_step(6, "å‡†å¤‡æµ‹è¯•æ•°æ®")
        test_texts = [
        "The price of the book is 99.99 dollars and the temperature is -10.5 degrees.",
        "Hello world! This is a test without numbers."
        ]
        inputs = tokenizer.batch_encode_plus(
        test_texts, padding=True, truncation=True, return_tensors='pt'
        )
        input_ids = inputs['input_ids'].to(device)
        numerical_values = inputs['numerical_values'].to(device)
        attention_mask = inputs['attention_mask'].to(device)
        print(f"âœ… æµ‹è¯•æ•°æ®å‡†å¤‡æˆåŠŸ (Batch Size: {input_ids.shape[0]}, Seq Len: {input_ids.shape[1]})")

        # æ­¥éª¤7: åˆ†æ­¥å‰å‘ä¼ æ’­ä¸éªŒè¯
        print_step(7, "åˆ†æ­¥å‰å‘ä¼ æ’­ä¸éªŒè¯")
        model.eval()
        with torch.no_grad():
            
            # 7.1 ç‰¹å¾æå–ç½‘ç»œ (ä¿®æ­£æ•°æ®æµ)
            print("\n--- 7.1. å¢å¼ºåµŒå…¥ä¸ç‰¹å¾æå– ---")
            print("è¾“å…¥: input_ids, numerical_values")
            print("è¾“å‡º: ä¸Šä¸‹æ–‡ç‰¹å¾ z")
            print("ç†è®º: e = NumericalAwareEmbedding(input); z = FeatureNetwork(inputs_embeds=e)")
            
            # æ­¥éª¤ 7.1a: è·å–æ•°å€¼æ„ŸçŸ¥åµŒå…¥ e
            enhanced_embeddings = model.numerical_aware_embedding(
                input_ids=input_ids,
                numerical_values=numerical_values
            )
            print_tensor_stats("å¢å¼ºåµŒå…¥ e", enhanced_embeddings)

            # æ­¥éª¤ 7.1b: ä½¿ç”¨å¢å¼ºåµŒå…¥è¿›è¡Œç‰¹å¾æå– z
            z = model.feature_network(
                inputs_embeds=enhanced_embeddings,
                attention_mask=attention_mask
            )
            print_tensor_stats("ä¸Šä¸‹æ–‡ç‰¹å¾ z", z)
            assert z.shape == (input_ids.shape[0], input_ids.shape[1], config.hidden_size), "z å½¢çŠ¶é”™è¯¯"

            # 7.2 å½’å› æ¨æ–­ç½‘ç»œ
            print("\n--- 7.2. å½’å› æ¨æ–­ (Abduction) ---")
            print("è¾“å…¥: ä¸Šä¸‹æ–‡ç‰¹å¾ z")
            print("è¾“å‡º: loc_U, scale_U")
            print("ç†è®º: loc_U åº”è¯¥çº¦ç­‰äº z (å› åˆå§‹åŒ–ä¸ºæ’ç­‰æ˜ å°„), scale_U åº”è¯¥ä¸ºè¾ƒå¤§çš„æ­£æ•° (çº¦10)")
            
            loc_U, scale_U = model.abduction_network(z)
            print_tensor_stats("å› æœè¡¨å¾ä½ç½® loc_U", loc_U)
            print_tensor_stats("å› æœè¡¨å¾å°ºåº¦ scale_U", scale_U)
            assert torch.allclose(loc_U, z, atol=1e-5), "loc_U ä¸ z ä¸ä¸€è‡´"
            assert scale_U.mean() > 5, "scale_U çš„å‡å€¼è¿‡å°"

            # 7.3 è¡ŒåŠ¨å†³ç­–ç½‘ç»œ
            print("\n--- 7.3. è¡ŒåŠ¨å†³ç­– (Action) ---")
            print("è¾“å…¥: loc_U, scale_U")
            print("è¾“å‡º: loc_S, scale_S (åˆ†ç±»), loc_Y, scale_Y (å›å½’)")
            print("ç†è®º: scale_S å’Œ scale_Y åº”è¯¥ä¹Ÿæ˜¯è¾ƒå¤§çš„æ­£æ•°ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ scale_U çš„çº¿æ€§å˜æ¢")

            output_dict = model.action_network(loc_U, scale_U)
            
            print("\n   --- åˆ†ç±»è¾“å‡º ---")
            print_tensor_stats("åˆ†ç±» logits (loc_S)", output_dict.get('loc_S'))
            print_tensor_stats("åˆ†ç±»å°ºåº¦ (scale_S)", output_dict.get('scale_S'))

            print("\n   --- å›å½’è¾“å‡º ---")
            print_tensor_stats("å›å½’é¢„æµ‹ (loc_Y)", output_dict.get('loc_Y'))
            print_tensor_stats("å›å½’ä¸ç¡®å®šæ€§ (scale_Y)", output_dict.get('scale_Y'))
            
            # å…³é”®éªŒè¯
            final_scale_Y = output_dict.get('scale_Y')
            assert final_scale_Y is not None, "æ¨¡å‹æœªè¾“å‡º scale_Y"
            if final_scale_Y.mean().item() < 1.0:
                 print("\nğŸš¨ğŸš¨ğŸš¨ è­¦å‘Š: å›å½’ä¸ç¡®å®šæ€§ scale_Y çš„å‡å€¼éå¸¸å°! è¿™å¯èƒ½æ˜¯å¯¼è‡´ PICP=0 çš„ç›´æ¥åŸå› ã€‚")
            else:
                 print("\nâœ… å›å½’ä¸ç¡®å®šæ€§ scale_Y çš„å‡å€¼çœ‹èµ·æ¥åˆç†ã€‚")

        # æ­¥éª¤8: æ€»ç»“
        print_step("å®Œæˆ", "è°ƒè¯•æ€»ç»“")
        print("ğŸ‰ è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚è¯·ä»”ç»†æ£€æŸ¥ä¸Šé¢æ¯ä¸ªæ­¥éª¤çš„è¾“å‡ºï¼Œç‰¹åˆ«æ˜¯ `scale_U` å’Œ `scale_Y` çš„å€¼ã€‚")
        return True

    except KeyboardInterrupt:
        print(f"\nâŒ ç”¨æˆ·ä¸­æ–­ (Ctrl+C)")
        return False
    except Exception as e:
        print(f"\nâŒ è„šæœ¬æ‰§è¡Œä¸­å‡ºç°æ„å¤–é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    success = main()
    if not success:
        sys.exit(1)