#!/usr/bin/env python3
"""
CausalQwenä¸Qwenå…¼å®¹æ€§æµ‹è¯•

éªŒè¯é‡ç‚¹ï¼š
1. CausalQwenå®Œå…¨å…¼å®¹Qwençš„ç”Ÿæˆæ¥å£
2. do_sampleå‚æ•°æ§åˆ¶å› æœæ¨ç†è¡Œä¸ºå·®å¼‚
3. ä¸Qwenç›¸åŒçš„å‚æ•°äº§ç”ŸæœŸæœ›çš„è¡Œä¸º
4. ç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§éªŒè¯
"""

import sys
import os
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    END = '\033[0m'

def print_section(title):
    print(f"\n{Colors.BLUE}{Colors.BOLD}{'='*60}{Colors.END}")
    print(f"{Colors.BLUE}{Colors.BOLD}{title}{Colors.END}")
    print(f"{Colors.BLUE}{Colors.BOLD}{'='*60}{Colors.END}")

def print_success(msg):
    print(f"{Colors.GREEN}âœ… {msg}{Colors.END}")

def print_error(msg):
    print(f"{Colors.RED}âŒ {msg}{Colors.END}")

def print_info(msg):
    print(f"{Colors.WHITE}â„¹ï¸  {msg}{Colors.END}")

def test_qwen_compatibility():
    """æµ‹è¯•ä¸Qwençš„æ¥å£å…¼å®¹æ€§"""
    print_section("Qwenæ¥å£å…¼å®¹æ€§æµ‹è¯•")
    
    try:
        from causal_qwen_mvp import CausalQwenMVPForCausalLM, CausalQwen2Config
        
        # åˆ›å»ºå°å‹æµ‹è¯•æ¨¡å‹
        config = CausalQwen2Config(
            vocab_size=1000,
            hidden_size=128,
            intermediate_size=512,
            num_hidden_layers=2,
            num_attention_heads=8,
            num_key_value_heads=8,
            max_position_embeddings=512,
            causal_size=128
        )
        
        model = CausalQwenMVPForCausalLM(config)
        print_success("CausalQwenæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è¾“å…¥
        input_ids = torch.randint(0, 1000, (2, 5))
        print_info(f"æµ‹è¯•è¾“å…¥: {input_ids.shape}")
        
        return model, input_ids
        
    except Exception as e:
        print_error(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return None, None

def test_generation_interface(model, input_ids):
    """æµ‹è¯•ç”Ÿæˆæ¥å£"""
    print_section("ç”Ÿæˆæ¥å£æµ‹è¯•")
    
    try:
        # æµ‹è¯•1: ç¡®å®šæ€§ç”Ÿæˆ (do_sample=False)
        print_info("æµ‹è¯•ç¡®å®šæ€§ç”Ÿæˆ (do_sample=False)")
        det_output = model.generate(
            input_ids,
            max_new_tokens=5,
            do_sample=False,
            temperature=1.0
        )
        print_success(f"ç¡®å®šæ€§ç”ŸæˆæˆåŠŸ: {det_output.shape}")
        print_info(f"ç”Ÿæˆåºåˆ—: {det_output[0].tolist()}")
        
        # æµ‹è¯•2: é‡‡æ ·ç”Ÿæˆ (do_sample=True)
        print_info("æµ‹è¯•é‡‡æ ·ç”Ÿæˆ (do_sample=True)")
        samp_output = model.generate(
            input_ids,
            max_new_tokens=5,
            do_sample=True,
            temperature=0.8,
            top_k=50,
            top_p=0.9
        )
        print_success(f"é‡‡æ ·ç”ŸæˆæˆåŠŸ: {samp_output.shape}")
        print_info(f"ç”Ÿæˆåºåˆ—: {samp_output[0].tolist()}")
        
        # æµ‹è¯•3: éªŒè¯é•¿åº¦æ­£ç¡®æ€§
        expected_length = input_ids.shape[1] + 5
        if det_output.shape[1] == expected_length and samp_output.shape[1] == expected_length:
            print_success("ç”Ÿæˆé•¿åº¦æ­£ç¡®")
        else:
            print_error(f"ç”Ÿæˆé•¿åº¦é”™è¯¯: æœŸæœ›{expected_length}, å®é™…det={det_output.shape[1]}, samp={samp_output.shape[1]}")
        
        # æµ‹è¯•4: éªŒè¯do_sampleå·®å¼‚
        det_new = det_output[0, input_ids.shape[1]:].tolist()
        samp_new = samp_output[0, input_ids.shape[1]:].tolist()
        
        difference_count = sum(1 for a, b in zip(det_new, samp_new) if a != b)
        print_info(f"ç¡®å®šæ€§vsé‡‡æ ·å·®å¼‚: {difference_count}/5 ä¸ªä½ç½®ä¸åŒ")
        
        if difference_count > 0:
            print_success("do_sampleå‚æ•°æ­£ç¡®æ§åˆ¶ç”Ÿæˆå·®å¼‚")
        else:
            print_error("do_sampleå‚æ•°æœªäº§ç”Ÿé¢„æœŸå·®å¼‚")
        
        return True
        
    except Exception as e:
        print_error(f"ç”Ÿæˆæ¥å£æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_causal_mathematical_principles(model, input_ids):
    """æµ‹è¯•å› æœæ•°å­¦åŸç†"""
    print_section("å› æœæ•°å­¦åŸç†æµ‹è¯•")
    
    try:
        from causal_qwen_mvp import InferenceValidator
        
        validator = InferenceValidator(model)
        results = validator.validate_causal_principles(input_ids, temperature=1.0)
        
        # ä½ç½®å‚æ•°å·®å¼‚
        pos_diff = results['position_difference'].item()
        scale_diff = results['scale_difference'].item()
        
        print_info(f"ä½ç½®å‚æ•°å·®å¼‚: {pos_diff:.6f}")
        print_info(f"å°ºåº¦å‚æ•°å·®å¼‚: {scale_diff:.6f}")
        
        if pos_diff > 1e-3:
            print_success("ä½ç½®å‚æ•°åœ¨ä¸åŒæ¨¡å¼ä¸‹æœ‰æ˜¾è‘—å·®å¼‚ï¼ˆç¬¦åˆå› æœè®¾è®¡ï¼‰")
        else:
            print_error("ä½ç½®å‚æ•°å·®å¼‚è¿‡å°")
        
        # éªŒè¯åŸºç¡€è¡¨å¾
        loc_U_mean = results['base_representations']['loc_U'].mean().item()
        scale_U_mean = results['base_representations']['scale_U'].mean().item()
        
        print_info(f"ä¸ªä½“è¡¨å¾ç»Ÿè®¡: loc_U={loc_U_mean:.4f}, scale_U={scale_U_mean:.4f}")
        
        if scale_U_mean > 1e-3:
            print_success("å°ºåº¦å‚æ•°åˆå§‹åŒ–æ­£ç¡®ï¼ˆ>0ï¼‰")
        else:
            print_error("å°ºåº¦å‚æ•°è¿‡å°ï¼Œå¯èƒ½åˆå§‹åŒ–æœ‰é—®é¢˜")
        
        return True
        
    except Exception as e:
        print_error(f"å› æœæ•°å­¦åŸç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_temperature_effects(model, input_ids):
    """æµ‹è¯•æ¸©åº¦å‚æ•°æ•ˆæœ"""
    print_section("æ¸©åº¦å‚æ•°æ•ˆæœæµ‹è¯•")
    
    try:
        temperatures = [0.0, 0.1, 0.5, 1.0, 1.5, 2.0]  # æ·»åŠ æ¸©åº¦ä¸ºé›¶çš„æµ‹è¯•
        results = []
        
        for temp in temperatures:
            # å›ºå®šéšæœºç§å­ç¡®ä¿å¯æ¯”æ€§
            torch.manual_seed(42)
            output = model.generate(
                input_ids,
                max_new_tokens=3,
                do_sample=True,
                temperature=temp,
                top_k=100  # å¢å¤§top_kä»¥æ›´å¥½è§‚å¯Ÿæ¸©åº¦æ•ˆæœ
            )
            new_tokens = output[0, input_ids.shape[1]:].tolist()
            results.append((temp, new_tokens))
            print_info(f"æ¸©åº¦T={temp}: {new_tokens}")
        
        # ç‰¹åˆ«éªŒè¯æ¸©åº¦ä¸ºé›¶çš„åœºæ™¯
        if len(results) > 0 and results[0][0] == 0.0:
            print_info("ğŸŒ¡ï¸ æ¸©åº¦ä¸ºé›¶æ˜¯æå…¶é‡è¦çš„è¾¹ç•Œæ¡ä»¶ï¼")
            temp_zero_tokens = results[0][1]
            print_info(f"æ¸©åº¦T=0ç»“æœ: {temp_zero_tokens}")
        
        # åˆ†ææ¸©åº¦æ•ˆæœ
        unique_sequences = len(set(tuple(result[1]) for result in results))
        print_info(f"ä¸åŒæ¸©åº¦äº§ç”Ÿçš„åºåˆ—å¤šæ ·æ€§: {unique_sequences}/{len(temperatures)}")
        
        if unique_sequences >= 3:
            print_success("æ¸©åº¦å‚æ•°æœ‰æ•ˆæ§åˆ¶ç”Ÿæˆå¤šæ ·æ€§")
        else:
            print_error("æ¸©åº¦å‚æ•°æ•ˆæœä¸æ˜æ˜¾")
        
        # æµ‹è¯•ç¡®å®šæ€§æ¨¡å¼ä¸‹æ¸©åº¦æ— æ•ˆ
        torch.manual_seed(42)
        det_output1 = model.generate(input_ids, max_new_tokens=3, do_sample=False, temperature=0.1)
        torch.manual_seed(42) 
        det_output2 = model.generate(input_ids, max_new_tokens=3, do_sample=False, temperature=2.0)
        
        if torch.equal(det_output1, det_output2):
            print_success("ç¡®å®šæ€§æ¨¡å¼ä¸‹æ¸©åº¦å‚æ•°æ­£ç¡®æ— æ•ˆ")
        else:
            print_error("ç¡®å®šæ€§æ¨¡å¼ä¸‹æ¸©åº¦å‚æ•°æ„å¤–ç”Ÿæ•ˆ")
        
        return True
        
    except Exception as e:
        print_error(f"æ¸©åº¦å‚æ•°æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_batch_generation(model, input_ids):
    """æµ‹è¯•æ‰¹é‡ç”Ÿæˆ"""
    print_section("æ‰¹é‡ç”Ÿæˆæµ‹è¯•")
    
    try:
        batch_size = input_ids.shape[0]
        
        # æ‰¹é‡é‡‡æ ·ç”Ÿæˆ
        batch_output = model.generate(
            input_ids,
            max_new_tokens=4,
            do_sample=True,
            temperature=1.0,
            top_k=50
        )
        
        print_success(f"æ‰¹é‡ç”ŸæˆæˆåŠŸ: {batch_output.shape}")
        
        # éªŒè¯æ‰¹å†…å¤šæ ·æ€§
        batch_sequences = []
        for i in range(batch_size):
            new_tokens = batch_output[i, input_ids.shape[1]:].tolist()
            batch_sequences.append(new_tokens)
            print_info(f"æ‰¹æ¬¡{i}: {new_tokens}")
        
        unique_in_batch = len(set(tuple(seq) for seq in batch_sequences))
        print_info(f"æ‰¹å†…åºåˆ—å¤šæ ·æ€§: {unique_in_batch}/{batch_size}")
        
        if batch_size > 1 and unique_in_batch > 1:
            print_success("æ‰¹é‡ç”Ÿæˆå…·æœ‰å¤šæ ·æ€§")
        
        return True
        
    except Exception as e:
        print_error(f"æ‰¹é‡ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print_section("CausalQwenä¸Qwenå…¼å®¹æ€§æµ‹è¯•")
    print_info("éªŒè¯CausalQwenæ˜¯å¦å®Œå…¨å…¼å®¹Qwençš„ç”Ÿæˆæ¥å£")
    
    # åˆ›å»ºæ¨¡å‹
    model, input_ids = test_qwen_compatibility()
    if model is None:
        return
    
    # æ‰§è¡Œæµ‹è¯•
    tests = [
        ("ç”Ÿæˆæ¥å£å…¼å®¹æ€§", test_generation_interface),
        ("å› æœæ•°å­¦åŸç†", test_causal_mathematical_principles),
        ("æ¸©åº¦å‚æ•°æ•ˆæœ", test_temperature_effects),
        ("æ‰¹é‡ç”Ÿæˆ", test_batch_generation)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\n{Colors.CYAN}ğŸ”¬ æ­£åœ¨æ‰§è¡Œ: {test_name}{Colors.END}")
        success = test_func(model, input_ids)
        results.append((test_name, success))
    
    # æ€»ç»“æŠ¥å‘Š
    print_section("æµ‹è¯•æ€»ç»“")
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {status} {test_name}")
    
    print(f"\n{Colors.BOLD}æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡{Colors.END}")
    
    if passed == total:
        print_success("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼CausalQwenä¸Qwenå®Œå…¨å…¼å®¹ï¼")
    else:
        print_error("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    print_info("CausalQwenæ ¸å¿ƒåˆ›æ–°ï¼š")
    print_info("â”œâ”€ Causalæ¨¡å¼ (temperature=0): çº¯å› æœç”Ÿæˆï¼Œæ— å¤–ç”Ÿå™ªå£°")
    print_info("â”œâ”€ Standardæ¨¡å¼ (do_sample=False, temperature>0): å™ªå£°å¢åŠ å†³ç­–ä¸ç¡®å®šæ€§")
    print_info("â”œâ”€ Samplingæ¨¡å¼ (do_sample=True, temperature>0): å™ªå£°æ‰°åŠ¨ä¸ªä½“èº«ä»½")
    print_info("â””â”€ Compatibleæ¨¡å¼: ä¼ ç»ŸSoftmaxï¼Œä¸åŸå§‹Qwenå…¼å®¹")

if __name__ == "__main__":
    main()