#!/usr/bin/env python3
"""
æŸ¯è¥¿åˆ†å¸ƒçº¿æ€§å˜æ¢æ•°å­¦éªŒè¯è„šæœ¬

æœ¬è„šæœ¬è¯¦ç»†éªŒè¯ CauchyLinear å±‚çš„æ•°å­¦æ­£ç¡®æ€§ï¼ŒåŒ…æ‹¬ï¼š
1. æŸ¯è¥¿åˆ†å¸ƒçº¿æ€§å˜æ¢å…¬å¼çš„æ­£ç¡®å®ç°
2. åˆ†ç±»å¤´å’Œå›å½’å¤´çš„scaleè®¡ç®—éªŒè¯
3. ä¿®å¤åçš„å›å½’å¤´åˆå§‹åŒ–éªŒè¯
"""

import torch
import torch.nn as nn
import sys
import os

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.models.causal_lm import CausalLanguageModel, CausalLMConfig
from src.data.tokenizer import QwenTokenizerWrapper
from src.utils.distributions import CauchyLinear

def verify_cauchy_linear_math():
    """éªŒè¯ CauchyLinear çš„æ•°å­¦æ­£ç¡®æ€§"""
    print("ğŸ§® æŸ¯è¥¿åˆ†å¸ƒçº¿æ€§å˜æ¢æ•°å­¦éªŒè¯")
    print("=" * 60)
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„CauchyLinearå±‚è¿›è¡Œæµ‹è¯•
    in_features = 4
    out_features = 3
    cauchy_layer = CauchyLinear(in_features, out_features)
    
    # è®¾ç½®å·²çŸ¥çš„æƒé‡å’Œåç½®ç”¨äºéªŒè¯
    with torch.no_grad():
        cauchy_layer.weight.data = torch.tensor([
            [1.0, -2.0, 0.5, 1.5],    # ç¬¬ä¸€ä¸ªè¾“å‡º
            [0.0, 1.0, -1.0, 0.5],    # ç¬¬äºŒä¸ªè¾“å‡º  
            [-0.5, 0.0, 2.0, -1.0]    # ç¬¬ä¸‰ä¸ªè¾“å‡º
        ])
        cauchy_layer.bias.data = torch.tensor([1.0, -0.5, 2.0])
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    input_loc = torch.tensor([
        [1.0, 2.0, -1.0, 0.5],   # ç¬¬ä¸€ä¸ªæ ·æœ¬
        [0.0, 1.5, 1.0, -0.5]    # ç¬¬äºŒä¸ªæ ·æœ¬
    ])
    input_scale = torch.tensor([
        [0.5, 1.0, 0.8, 1.2],    # ç¬¬ä¸€ä¸ªæ ·æœ¬
        [1.5, 0.5, 1.0, 0.8]     # ç¬¬äºŒä¸ªæ ·æœ¬
    ])
    
    print(f"è¾“å…¥ loc: {input_loc}")
    print(f"è¾“å…¥ scale: {input_scale}")
    print(f"æƒé‡çŸ©é˜µ:\n{cauchy_layer.weight}")
    print(f"åç½®: {cauchy_layer.bias}")
    
    # ä½¿ç”¨CauchyLinearè¿›è¡Œå˜æ¢
    output_loc, output_scale = cauchy_layer(input_loc, input_scale)
    
    print(f"\nCauchyLinear è¾“å‡º:")
    print(f"è¾“å‡º loc: {output_loc}")
    print(f"è¾“å‡º scale: {output_scale}")
    
    # æ‰‹å·¥éªŒè¯ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç¬¬ä¸€ä¸ªè¾“å‡º
    print(f"\nğŸ“ æ‰‹å·¥éªŒè¯ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç¬¬ä¸€ä¸ªè¾“å‡º:")
    sample_idx = 0
    output_idx = 0
    
    weight_row = cauchy_layer.weight[output_idx]  # [1.0, -2.0, 0.5, 1.5]
    bias_val = cauchy_layer.bias[output_idx]      # 1.0
    
    # ç†è®ºè®¡ç®— loc: W * input_loc + bias
    theoretical_loc = torch.dot(weight_row, input_loc[sample_idx]) + bias_val
    print(f"ç†è®º loc = {weight_row} Â· {input_loc[sample_idx]} + {bias_val}")
    print(f"         = {torch.dot(weight_row, input_loc[sample_idx]):.4f} + {bias_val}")
    print(f"         = {theoretical_loc:.4f}")
    print(f"å®é™… loc = {output_loc[sample_idx, output_idx]:.4f}")
    print(f"loc ä¸€è‡´æ€§: {'âœ…' if abs(theoretical_loc - output_loc[sample_idx, output_idx]) < 1e-5 else 'âŒ'}")
    
    # ç†è®ºè®¡ç®— scale: |W| * input_scale
    abs_weight_row = torch.abs(weight_row)
    theoretical_scale = torch.dot(abs_weight_row, input_scale[sample_idx])
    print(f"\nç†è®º scale = |{weight_row}| Â· {input_scale[sample_idx]}")
    print(f"          = {abs_weight_row} Â· {input_scale[sample_idx]}")
    print(f"          = {theoretical_scale:.4f}")
    print(f"å®é™… scale = {output_scale[sample_idx, output_idx]:.4f}")
    print(f"scale ä¸€è‡´æ€§: {'âœ…' if abs(theoretical_scale - output_scale[sample_idx, output_idx]) < 1e-5 else 'âŒ'}")

def verify_model_cauchy_math():
    """éªŒè¯æ¨¡å‹ä¸­çš„æŸ¯è¥¿æ•°å­¦å®ç°"""
    print("\nğŸ—ï¸ æ¨¡å‹ä¸­çš„æŸ¯è¥¿åˆ†å¸ƒæ•°å­¦éªŒè¯")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡å‹å’Œåˆ†è¯å™¨
    tokenizer = QwenTokenizerWrapper(
        model_path="~/models/Qwen2.5-0.5B", 
        use_real_tokenizer=True
    )
    
    config = CausalLMConfig(
        vocab_size=tokenizer.vocab_size,
        num_token_id=tokenizer.num_token_id,
        hidden_size=896,
        causal_dim=896,
        use_real_qwen=True,
        qwen_model_path="~/models/Qwen2.5-0.5B"
    )
    
    model = CausalLanguageModel(config)
    
    # æ‰§è¡ŒçŸ¥è¯†ä¼ è¾“åˆå§‹åŒ–
    print("æ‰§è¡ŒçŸ¥è¯†ä¼ è¾“åˆå§‹åŒ–...")
    model.init_weights(num_target_median=50.0, num_target_scale=10.0)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    text = "The price is 42.5 dollars."
    inputs = tokenizer([text], padding=True, truncation=True, return_tensors='pt')
    
    # å‰å‘ä¼ æ’­
    print("æ‰§è¡Œå‰å‘ä¼ æ’­...")
    with torch.no_grad():
        outputs = model(inputs['input_ids'], inputs['numerical_values'], inputs['attention_mask'])
    
    # éªŒè¯åˆ†ç±»å¤´çš„æ•°å­¦
    print(f"\nğŸ” åˆ†ç±»å¤´æ•°å­¦éªŒè¯:")
    cls_head = model.action_network.classification_head.causal_linear
    sample_pos = 0  # ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼Œç¬¬ä¸€ä¸ªä½ç½®
    
    # è·å–è¾“å…¥çš„å› æœè¡¨å¾
    causal_loc = outputs['causal_loc'][0, sample_pos]  # [causal_dim]
    causal_scale = outputs['causal_scale'][0, sample_pos]  # [causal_dim]
    
    print(f"è¾“å…¥å› æœè¡¨å¾ç»Ÿè®¡:")
    print(f"  causal_loc å‡å€¼: {causal_loc.mean():.4f}, æ ‡å‡†å·®: {causal_loc.std():.4f}")
    print(f"  causal_scale å‡å€¼: {causal_scale.mean():.4f}, æ ‡å‡†å·®: {causal_scale.std():.4f}")
    
    # è·å–åˆ†ç±»å¤´çš„æƒé‡
    cls_weight = cls_head.weight  # [vocab_size, causal_dim]
    cls_bias = cls_head.bias if cls_head.bias is not None else torch.zeros(cls_weight.shape[0])
    
    print(f"åˆ†ç±»å¤´æƒé‡ç»Ÿè®¡:")
    print(f"  æƒé‡å½¢çŠ¶: {cls_weight.shape}")
    print(f"  æƒé‡å‡å€¼: {cls_weight.mean():.6f}, æ ‡å‡†å·®: {cls_weight.std():.6f}")
    print(f"  |æƒé‡| å‡å€¼: {torch.abs(cls_weight).mean():.6f}")
    
    # éªŒè¯å‡ ä¸ªç‰¹å®šä½ç½®çš„è®¡ç®—
    test_indices = [0, 1, tokenizer.num_token_id]  # åŒ…æ‹¬<NUM> token
    
    for idx in test_indices:
        if idx >= cls_weight.shape[0]:
            continue
            
        weight_row = cls_weight[idx]
        bias_val = cls_bias[idx]
        
        # ç†è®ºè®¡ç®—
        theoretical_loc = torch.dot(weight_row, causal_loc) + bias_val
        theoretical_scale = torch.dot(torch.abs(weight_row), causal_scale)
        
        # å®é™…è¾“å‡º
        actual_loc = outputs['cls_loc'][0, sample_pos, idx]
        actual_scale = outputs['cls_scale'][0, sample_pos, idx]
        
        print(f"\n  Token {idx} {'(<NUM>)' if idx == tokenizer.num_token_id else ''}:")
        print(f"    ç†è®º loc: {theoretical_loc:.6f}")
        print(f"    å®é™… loc: {actual_loc:.6f}")
        print(f"    ç†è®º scale: {theoretical_scale:.6f}")
        print(f"    å®é™… scale: {actual_scale:.6f}")
        
        loc_match = abs(theoretical_loc - actual_loc) < 1e-5
        scale_match = abs(theoretical_scale - actual_scale) < 1e-5
        print(f"    æ•°å­¦ä¸€è‡´æ€§: loc {'âœ…' if loc_match else 'âŒ'}, scale {'âœ…' if scale_match else 'âŒ'}")
        
        if not loc_match or not scale_match:
            print(f"    âŒ æ•°å­¦å…¬å¼å¯èƒ½å­˜åœ¨å®ç°é”™è¯¯ï¼")
    
    # éªŒè¯å›å½’å¤´çš„æ•°å­¦ 
    print(f"\nğŸ” å›å½’å¤´æ•°å­¦éªŒè¯:")
    reg_head = model.action_network.regression_head.causal_linear
    
    reg_weight = reg_head.weight[0]  # [causal_dim] - åªæœ‰ä¸€ä¸ªè¾“å‡º
    reg_bias = reg_head.bias[0] if reg_head.bias is not None else torch.tensor(0.0)
    
    print(f"å›å½’å¤´æƒé‡ç»Ÿè®¡:")
    print(f"  æƒé‡å½¢çŠ¶: {reg_weight.shape}")
    print(f"  æƒé‡å‡å€¼: {reg_weight.mean():.6f}, æ ‡å‡†å·®: {reg_weight.std():.6f}")
    print(f"  |æƒé‡| å‡å€¼: {torch.abs(reg_weight).mean():.6f}")
    print(f"  åç½®å€¼: {reg_bias:.4f}")
    
    # ç†è®ºè®¡ç®—
    theoretical_reg_loc = torch.dot(reg_weight, causal_loc) + reg_bias
    theoretical_reg_scale = torch.dot(torch.abs(reg_weight), causal_scale)
    
    # å®é™…è¾“å‡º
    actual_reg_loc = outputs['reg_loc'][0, sample_pos]
    actual_reg_scale = outputs['reg_scale'][0, sample_pos]
    
    print(f"\nå›å½’è¾“å‡ºéªŒè¯:")
    print(f"  ç†è®º reg_loc: {theoretical_reg_loc:.6f}")
    print(f"  å®é™… reg_loc: {actual_reg_loc:.6f}")
    print(f"  ç†è®º reg_scale: {theoretical_reg_scale:.6f}")
    print(f"  å®é™… reg_scale: {actual_reg_scale:.6f}")
    
    reg_loc_match = abs(theoretical_reg_loc - actual_reg_loc) < 1e-5
    reg_scale_match = abs(theoretical_reg_scale - actual_reg_scale) < 1e-5
    print(f"  æ•°å­¦ä¸€è‡´æ€§: loc {'âœ…' if reg_loc_match else 'âŒ'}, scale {'âœ…' if reg_scale_match else 'âŒ'}")
    
    if not reg_loc_match or not reg_scale_match:
        print(f"  âŒ å›å½’å¤´æ•°å­¦å…¬å¼å¯èƒ½å­˜åœ¨å®ç°é”™è¯¯ï¼")
    else:
        print(f"  âœ… å›å½’å¤´ä¿®å¤åçš„åˆå§‹åŒ–å’Œæ•°å­¦å®ç°æ­£ç¡®ï¼")
    
    # éªŒè¯ä¿®å¤æ•ˆæœ
    print(f"\nğŸ“Š ä¿®å¤æ•ˆæœéªŒè¯:")
    print(f"  ä¿®å¤å‰é—®é¢˜: reg_loc=50.0 (å¿½ç•¥è¾“å…¥), reg_scale=0.001 (æœ€å°å€¼)")
    print(f"  ä¿®å¤åç»“æœ: reg_loc={actual_reg_loc:.4f} (å“åº”è¾“å…¥), reg_scale={actual_reg_scale:.4f} (åˆç†å€¼)")
    
    if abs(actual_reg_loc - 50.0) > 0.01:
        print(f"  âœ… å›å½’å¤´ç°åœ¨æ­£ç¡®å“åº”è¾“å…¥çš„å› æœè¡¨å¾ï¼")
    else:
        print(f"  âŒ å›å½’å¤´ä»ç„¶åªä¾èµ–åç½®ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        
    if actual_reg_scale > 0.01:
        print(f"  âœ… å›å½’å¤´çš„scaleç°åœ¨æœ‰åˆç†çš„å€¼ï¼")
    else:
        print(f"  âŒ å›å½’å¤´çš„scaleä»ç„¶å¤ªå°")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ æŸ¯è¥¿åˆ†å¸ƒçº¿æ€§å˜æ¢æ•°å­¦éªŒè¯è„šæœ¬")
    print("=" * 80)
    
    try:
        # 1. éªŒè¯åŸºç¡€çš„CauchyLinearæ•°å­¦
        verify_cauchy_linear_math()
        
        # 2. éªŒè¯æ¨¡å‹ä¸­çš„æ•°å­¦å®ç°
        verify_model_cauchy_math()
        
        print("\n" + "=" * 80)
        print("âœ… æ•°å­¦éªŒè¯å®Œæˆï¼æ£€æŸ¥ä¸Šè¿°è¾“å‡ºä»¥ç¡®è®¤æ‰€æœ‰å…¬å¼çš„æ­£ç¡®æ€§ã€‚")
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 