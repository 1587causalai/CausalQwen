#!/usr/bin/env python3
"""
CausalQwenä¸Qwenç®€å•é›†æˆæµ‹è¯•
æœ€å°å¯è¿è¡Œçš„ç«¯åˆ°ç«¯éªŒè¯

æµ‹è¯•ç›®æ ‡ï¼šè¾“å…¥"ä½ å¥½"ï¼ŒéªŒè¯compatibleæ¨¡å¼ä¸‹çš„æ•°å€¼ä¸€è‡´æ€§

Author: CausalQwen Team
Date: 2024-01-16
"""

import torch
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ç¡®ä¿srcç›®å½•åœ¨Pythonè·¯å¾„ä¸­
src_path = project_root / "src"
sys.path.insert(0, str(src_path))

def test_simple_integration():
    """ç®€å•é›†æˆæµ‹è¯•"""
    
    print("ğŸš€ å¼€å§‹CausalQwenç®€å•é›†æˆæµ‹è¯•")
    print("ç›®æ ‡ï¼šéªŒè¯'ä½ å¥½'è¾“å…¥çš„æ•°å€¼ä¸€è‡´æ€§")
    print("=" * 50)
    
    try:
        # 1. å¯¼å…¥æ¨¡å—
        print("ğŸ“¦ å¯¼å…¥æ¨¡å—...")
        from transformers import Qwen2ForCausalLM, AutoTokenizer
        from causal_qwen_mvp.models import CausalQwenMVPForCausalLM
        from causal_qwen_mvp.models import CausalQwen2Config
        
        # 2. åŠ è½½Qwenæ¨¡å‹
        print("ğŸ“¥ åŠ è½½åŸå§‹Qwen2.5-0.5B...")
        qwen_model_path = "~/models/Qwen2.5-0.5B"
        
        try:
            tokenizer = AutoTokenizer.from_pretrained(qwen_model_path)
            qwen_model = Qwen2ForCausalLM.from_pretrained(
                qwen_model_path,
                torch_dtype=torch.float32,
                device_map="cpu"
            )
            print(f"âœ… Qwenæ¨¡å‹åŠ è½½æˆåŠŸï¼Œå‚æ•°é‡: {sum(p.numel() for p in qwen_model.parameters()):,}")
        except Exception as e:
            print(f"âŒ Qwenæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿ ~/models/Qwen2.5-0.5B è·¯å¾„å­˜åœ¨")
            return
        
        # 3. åˆ›å»ºCausalQwenæ¨¡å‹
        print("ğŸ”§ åˆ›å»ºCausalQwenæ¨¡å‹...")
        try:
            causal_config = CausalQwen2Config(
                vocab_size=qwen_model.config.vocab_size,
                hidden_size=qwen_model.config.hidden_size,
                intermediate_size=qwen_model.config.intermediate_size,
                num_hidden_layers=qwen_model.config.num_hidden_layers,
                num_attention_heads=qwen_model.config.num_attention_heads,
                num_key_value_heads=getattr(qwen_model.config, 'num_key_value_heads', qwen_model.config.num_attention_heads),
                max_position_embeddings=qwen_model.config.max_position_embeddings,
                individual_dim=128,
                num_individuals=16
            )
            
            causal_qwen_model = CausalQwenMVPForCausalLM(causal_config)
            print(f"âœ… CausalQwenæ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°é‡: {sum(p.numel() for p in causal_qwen_model.parameters()):,}")
        except Exception as e:
            print(f"âŒ CausalQwenæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            return
        
        # 4. å…³é”®æƒé‡æ˜ å°„ï¼ˆç®€åŒ–ç‰ˆï¼‰
        print("ğŸ”„ æ‰§è¡Œå…³é”®æƒé‡æ˜ å°„...")
        try:
            with torch.no_grad():
                # æ˜ å°„è¯åµŒå…¥
                causal_qwen_model.qwen_model.embed_tokens.weight.copy_(
                    qwen_model.model.embed_tokens.weight
                )
                
                # æ˜ å°„lm_headåˆ°action_network.linearï¼ˆå…³é”®æ˜ å°„ï¼ï¼‰
                causal_qwen_model.action_network.linear.weight.copy_(
                    qwen_model.lm_head.weight
                )
                
                # æ˜ å°„normå±‚
                causal_qwen_model.qwen_model.norm.weight.copy_(
                    qwen_model.model.norm.weight
                )
                
                # æ˜ å°„Transformerå±‚ï¼ˆç®€åŒ–ï¼šåªå¤åˆ¶èƒ½åŒ¹é…çš„ï¼‰
                for i, (qwen_layer, causal_layer) in enumerate(
                    zip(qwen_model.model.layers, causal_qwen_model.qwen_model.layers)
                ):
                    try:
                        # å°è¯•ç›´æ¥å¤åˆ¶state_dict
                        causal_layer.load_state_dict(qwen_layer.state_dict(), strict=False)
                    except Exception as layer_e:
                        print(f"  âš ï¸ ç¬¬{i}å±‚æ˜ å°„å¤±è´¥ï¼Œè·³è¿‡: {layer_e}")
                        continue
                
            print("âœ… å…³é”®æƒé‡æ˜ å°„å®Œæˆ")
        except Exception as e:
            print(f"âŒ æƒé‡æ˜ å°„å¤±è´¥: {e}")
            return
        
        # 5. æ‰§è¡Œç®€å•æµ‹è¯•
        print("\nğŸ§ª æ‰§è¡Œ'ä½ å¥½'ä¸€è‡´æ€§æµ‹è¯•...")
        test_input = "ä½ å¥½"
        
        # å‡†å¤‡è¾“å…¥
        inputs = tokenizer(test_input, return_tensors="pt")
        input_ids = inputs["input_ids"]
        print(f"è¾“å…¥tokens: {input_ids}")
        
        with torch.no_grad():
            # Qwenè¾“å‡º
            qwen_outputs = qwen_model(input_ids)
            qwen_logits = qwen_outputs.logits[:, -1, :]  # æœ€åä¸€ä¸ªtokençš„logits
            
            # CausalQwenè¾“å‡º
            causal_outputs = causal_qwen_model(input_ids)
            causal_logits = causal_outputs.loc_S[:, -1, :]  # åœ¨compatibleæ¨¡å¼ä¸‹åº”è¯¥ç­‰ä»·
            
            # è®¡ç®—å·®å¼‚
            max_diff = torch.max(torch.abs(qwen_logits - causal_logits)).item()
            mean_diff = torch.mean(torch.abs(qwen_logits - causal_logits)).item()
            relative_error = torch.mean(
                torch.abs(qwen_logits - causal_logits) / (torch.abs(qwen_logits) + 1e-8)
            ).item()
            
            print(f"\nğŸ“Š æ•°å€¼å¯¹æ¯”ç»“æœ:")
            print(f"  æœ€å¤§å·®å¼‚: {max_diff:.8f}")
            print(f"  å¹³å‡å·®å¼‚: {mean_diff:.8f}")
            print(f"  ç›¸å¯¹è¯¯å·®: {relative_error:.8f}")
            
            # æ˜¾ç¤ºå‰5ä¸ªlogitsä½œä¸ºæ ·æœ¬
            print(f"\nğŸ“‹ å‰5ä¸ªlogitså¯¹æ¯”:")
            print(f"  Qwen:      {qwen_logits[0, :5].numpy()}")
            print(f"  CausalQwen: {causal_logits[0, :5].numpy()}")
            
            # åˆ¤æ–­æˆåŠŸæ ‡å‡†
            success_threshold = 1e-4
            is_success = max_diff < success_threshold
            
            print(f"\nğŸ¯ æµ‹è¯•ç»“æœ:")
            if is_success:
                print(f"  âœ… æˆåŠŸï¼æ•°å€¼å·®å¼‚ ({max_diff:.8f}) < é˜ˆå€¼ ({success_threshold})")
                print("  ğŸ‰ CausalQwençš„compatibleæ¨¡å¼åŸºæœ¬ä¸Qwenä¸€è‡´ï¼")
            else:
                print(f"  âŒ å¤±è´¥ï¼æ•°å€¼å·®å¼‚ ({max_diff:.8f}) >= é˜ˆå€¼ ({success_threshold})")
                print("  ğŸ”§ éœ€è¦æ£€æŸ¥æƒé‡æ˜ å°„æˆ–æ¨¡å‹ç»“æ„")
        
        # 6. ç®€å•çš„ç”Ÿæˆæµ‹è¯•
        print(f"\nğŸ—£ï¸ ç®€å•ç”Ÿæˆå¯¹æ¯”æµ‹è¯•...")
        try:
            # Qwenç”Ÿæˆ
            qwen_generated = qwen_model.generate(
                input_ids,
                max_new_tokens=3,
                do_sample=False,
                pad_token_id=tokenizer.eos_token_id
            )
            qwen_text = tokenizer.decode(qwen_generated[0], skip_special_tokens=True)
            
            # CausalQwen compatibleç”Ÿæˆ
            causal_generated = causal_qwen_model.generate(
                input_ids,
                max_new_tokens=3,
                causal_mode='compatible',
                do_sample=False,
                pad_token_id=tokenizer.eos_token_id
            )
            causal_text = tokenizer.decode(causal_generated[0], skip_special_tokens=True)
            
            print(f"  Qwenè¾“å‡º:      '{qwen_text}'")
            print(f"  CausalQwenè¾“å‡º: '{causal_text}'")
            
            if qwen_text == causal_text:
                print("  âœ… ç”Ÿæˆè¾“å‡ºå®Œå…¨ä¸€è‡´ï¼")
            else:
                print("  âš ï¸ ç”Ÿæˆè¾“å‡ºæœ‰å·®å¼‚ï¼Œä½†è¿™å¯èƒ½æ­£å¸¸ï¼ˆå› ä¸ºæƒé‡æ˜ å°„ä¸å®Œæ•´ï¼‰")
                
        except Exception as e:
            print(f"  âš ï¸ ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        
        print(f"\n" + "=" * 50)
        print("ğŸ† ç®€å•é›†æˆæµ‹è¯•å®Œæˆï¼")
        if is_success:
            print("ğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®ï¼šå®Œå–„æƒé‡æ˜ å°„ï¼Œæµ‹è¯•æ›´å¤šæ ·ä¾‹")
        else:
            print("ğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®ï¼šè°ƒè¯•æƒé‡æ˜ å°„é€»è¾‘ï¼Œæ£€æŸ¥æ¨¡å‹ç»“æ„")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_simple_integration() 