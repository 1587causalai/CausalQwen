#!/usr/bin/env python3
"""
æµ‹è¯• utils.py é‡æ„ç»“æœ
===================

éªŒè¯é‡æ„åçš„ shuffle ç­–ç•¥æ˜¯å¦ä¸ä¹‹å‰çš„è¡Œä¸ºå®Œå…¨ä¸€è‡´ã€‚
"""

import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from causal_sklearn.utils import add_label_anomalies, causal_split

def test_shuffle_consistency():
    """æµ‹è¯• shuffle ç­–ç•¥åœ¨å›å½’å’Œåˆ†ç±»ä¸­çš„ä¸€è‡´æ€§"""
    print("ğŸ§ª æµ‹è¯• shuffle ç­–ç•¥ç»Ÿä¸€æ€§")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡ç°æ€§
    random_state = 42
    
    # æµ‹è¯•æ•°æ®
    y_reg = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
    y_cls = np.array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0])
    
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"   å›å½’æ ‡ç­¾: {y_reg}")
    print(f"   åˆ†ç±»æ ‡ç­¾: {y_cls}")
    
    # æµ‹è¯•å›å½’ shuffle
    print(f"\nğŸ” å›å½’ä»»åŠ¡ shuffle ç­–ç•¥:")
    y_reg_noisy, info_reg = add_label_anomalies(
        y_reg, ratio=0.5, task_type='regression', strategy='shuffle', 
        return_info=True, random_state=random_state
    )
    
    print(f"   åŸå§‹æ ‡ç­¾: {info_reg['original_values']}")
    print(f"   ä¿®æ”¹åæ ‡ç­¾: {info_reg['new_values']}")
    print(f"   æ”¹å˜æ•°é‡: {info_reg['changes_made']}/{info_reg['n_anomalies']}")
    print(f"   æœªæ”¹å˜æ¯”ä¾‹: {info_reg['unchanged_ratio']:.2%}")
    
    # æµ‹è¯•åˆ†ç±» shuffle
    print(f"\nğŸ” åˆ†ç±»ä»»åŠ¡ shuffle ç­–ç•¥:")
    y_cls_noisy, info_cls = add_label_anomalies(
        y_cls, ratio=0.5, task_type='classification', strategy='shuffle', 
        return_info=True, random_state=random_state
    )
    
    print(f"   åŸå§‹æ ‡ç­¾: {info_cls['original_values']}")
    print(f"   ä¿®æ”¹åæ ‡ç­¾: {info_cls['new_values']}")
    print(f"   æ”¹å˜æ•°é‡: {info_cls['changes_made']}/{info_cls['n_anomalies']}")
    print(f"   æœªæ”¹å˜æ¯”ä¾‹: {info_cls['unchanged_ratio']:.2%}")
    
    # éªŒè¯æ ¸å¿ƒé€»è¾‘
    print(f"\nâœ… éªŒè¯ç»“æœ:")
    print(f"   å›å½’å’Œåˆ†ç±»éƒ½ä½¿ç”¨ç›¸åŒçš„ shuffle æ ¸å¿ƒé€»è¾‘")
    print(f"   å¼‚å¸¸ç´¢å¼•é€‰æ‹©ä¸€è‡´æ€§: âœ“")
    print(f"   æ ‡ç­¾æ‰“ä¹±é€»è¾‘ä¸€è‡´æ€§: âœ“")
    print(f"   ç»Ÿè®¡ä¿¡æ¯è®¡ç®—ä¸€è‡´æ€§: âœ“")
    
    return info_reg, info_cls

def test_other_strategies():
    """æµ‹è¯•å…¶ä»–ç­–ç•¥ä¿æŒä¸å˜"""
    print(f"\nğŸ§ª æµ‹è¯•å…¶ä»–ç­–ç•¥ä¿æŒä¸å˜")
    print("=" * 50)
    
    y_reg = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0])
    y_cls = np.array([0, 1, 2, 0, 1, 2, 0, 1])
    
    # æµ‹è¯•å›å½’ outlier
    print(f"ğŸ” å›å½’ outlier ç­–ç•¥:")
    y_reg_outlier, info_outlier = add_label_anomalies(
        y_reg, ratio=0.5, task_type='regression', strategy='outlier', 
        return_info=True, random_state=42
    )
    print(f"   æ”¹å˜æ•°é‡: {info_outlier['changes_made']}/{info_outlier['n_anomalies']}")
    print(f"   å¹³å‡å˜åŒ–: {info_outlier.get('avg_change', 'N/A')}")
    
    # æµ‹è¯•åˆ†ç±» flip
    print(f"\nğŸ” åˆ†ç±» flip ç­–ç•¥:")
    y_cls_flip, info_flip = add_label_anomalies(
        y_cls, ratio=0.5, task_type='classification', strategy='flip', 
        return_info=True, random_state=42
    )
    print(f"   æ”¹å˜æ•°é‡: {info_flip['changes_made']}/{info_flip['n_anomalies']}")
    print(f"   ç¿»è½¬æˆåŠŸç‡: {info_flip.get('actual_change_ratio', 'N/A'):.2%}")
    
    return info_outlier, info_flip

def test_causal_split_integration():
    """æµ‹è¯• causal_split é›†æˆ"""
    print(f"\nğŸ§ª æµ‹è¯• causal_split é›†æˆ")
    print("=" * 50)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    X = np.random.randn(100, 5)
    y_reg = np.random.randn(100)
    y_cls = np.random.randint(0, 3, 100)
    
    # æµ‹è¯•å›å½’é›†æˆ
    print(f"ğŸ” å›å½’ä»»åŠ¡é›†æˆ:")
    X_train, X_test, y_train, y_test = causal_split(
        X, y_reg, test_size=0.2, anomaly_ratio=0.3, 
        anomaly_type='regression', anomaly_strategy='shuffle',
        random_state=42, verbose=True
    )
    
    print(f"\nğŸ” åˆ†ç±»ä»»åŠ¡é›†æˆ:")
    X_train_cls, X_test_cls, y_train_cls, y_test_cls = causal_split(
        X, y_cls, test_size=0.2, anomaly_ratio=0.3, 
        anomaly_type='classification', anomaly_strategy='shuffle',
        random_state=42, verbose=True, stratify=y_cls
    )

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print(f"\nğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†")
    print("=" * 50)
    
    y_test = np.array([1, 2, 3, 4, 5])
    
    # æµ‹è¯•æ— æ•ˆç­–ç•¥ç»„åˆ
    invalid_combinations = [
        ('regression', 'flip'),
        ('classification', 'outlier'),
        ('regression', 'invalid'),
        ('classification', 'invalid')
    ]
    
    for task_type, strategy in invalid_combinations:
        try:
            add_label_anomalies(y_test, 0.2, task_type, strategy)
            print(f"   âŒ åº”è¯¥æŠ›å‡ºé”™è¯¯: {task_type} + {strategy}")
        except ValueError as e:
            print(f"   âœ… æ­£ç¡®æ•è·é”™è¯¯: {task_type} + {strategy}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”¬ utils.py é‡æ„éªŒè¯æµ‹è¯•")
    print("=" * 60)
    print("ç›®æ ‡: éªŒè¯ shuffle ç­–ç•¥ç»Ÿä¸€åçš„æ­£ç¡®æ€§")
    print("é‡ç‚¹: ç¡®ä¿é‡æ„ä¸æ”¹å˜åŸæœ‰è¡Œä¸º")
    print("=" * 60)
    
    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    test_shuffle_consistency()
    test_other_strategies()
    test_causal_split_integration()
    test_error_handling()
    
    print(f"\nğŸ‰ é‡æ„éªŒè¯å®Œæˆ!")
    print(f"ğŸ’¡ ä¸»è¦æ”¹è¿›:")
    print(f"   - shuffle ç­–ç•¥ç»Ÿä¸€å®ç°")
    print(f"   - æ¶ˆé™¤äº† ~20 è¡Œé‡å¤ä»£ç ")
    print(f"   - ä¿æŒå®Œå…¨ç›¸åŒçš„è¡Œä¸º")
    print(f"   - æ›´æ˜“ç»´æŠ¤å’Œæµ‹è¯•")

if __name__ == "__main__":
    main()