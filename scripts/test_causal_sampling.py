#!/usr/bin/env python
"""
å› æœé‡‡æ ·æ¨¡å¼éªŒè¯è„šæœ¬

æœ¬è„šæœ¬ä¸¥æ ¼æŒ‰ç…§ `docs/mathematical_foundations.md` ä¸­ "3.2 å› æœé‡‡æ ·" ç« èŠ‚çš„å®šä¹‰ï¼Œ
å¯¹ CausalQwen ç‹¬æœ‰çš„å› æœé‡‡æ ·æ¨ç†æ¨¡å¼è¿›è¡Œç™½ç›’éªŒè¯ã€‚

éªŒè¯ç›®æ ‡:
1. "é‡‡æ ·åŸå› ": éªŒè¯æ¨¡å‹èƒ½ä» `Cauchy(loc_U, scale_U)` åˆ†å¸ƒä¸­æ­£ç¡®é‡‡æ ·å‡ºå…·ä½“çš„å› æœè¡¨å¾ `u`ã€‚
2. "è§‚å¯Ÿç»“æœ": éªŒè¯å°†é‡‡æ ·çš„ `u` ä¼ å…¥è¡ŒåŠ¨ç½‘ç»œåï¼Œèƒ½å¾—åˆ°ç¡®å®šæ€§çš„åˆ†ç±»å’Œå›å½’è¾“å‡ºã€‚
3. éšæœºæ€§éªŒè¯: éªŒè¯å¤šæ¬¡è¿è¡Œå› æœé‡‡æ ·ä¼šäº§ç”Ÿä¸åŒçš„ç»“æœï¼Œè¯æ˜éšæœºæ€§æ¥æºã€‚
"""
import os
import sys
import torch
import torch.nn.functional as F

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„ä¸­
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models.causal_lm import CausalLMConfig, CausalLanguageModel
from src.data.tokenizer import QwenTokenizerWrapper
from src.utils.model_utils import get_qwen_model_info

def print_step(step_name, description):
    """æ‰“å°æµç¨‹æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{'='*70}")
    print(f"â¡ï¸  {step_name}: {description}")
    print(f"{'-'*70}")

def print_tensor_stats(name, tensor):
    """æ‰“å°å¼ é‡çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼Œä½¿ç”¨å¯¹æŸ¯è¥¿åˆ†å¸ƒé²æ£’çš„æŒ‡æ ‡ã€‚"""
    if not isinstance(tensor, torch.Tensor):
        print(f"   - {name}: Not a tensor")
        return
    tensor = tensor.detach().cpu().to(torch.float32)
    median = torch.median(tensor).item()
    q1 = torch.quantile(tensor, 0.25).item()
    q3 = torch.quantile(tensor, 0.75).item()
    iqr = q3 - q1
    print(f"   - {name}:")
    print(f"     - Shape:  {tensor.shape}")
    print(f"     - Median: {median:.4f} (ä¸­ä½æ•°)")
    print(f"     - IQR:    {iqr:.4f} (å››åˆ†ä½è·)")

def main():
    print("ğŸš€ CausalQwen - å› æœé‡‡æ · (Causal Sampling) æ¨¡å¼éªŒè¯ ğŸš€")

    # --- æ­¥éª¤ 1: åˆå§‹åŒ– ---
    print_step("æ­¥éª¤ 1", "åˆå§‹åŒ–æ¨¡å‹å’Œåˆ†è¯å™¨")
    device = torch.device('cpu')
    qwen_model_path = os.path.expanduser('~/models/Qwen2.5-0.5B')
    model_info = get_qwen_model_info(qwen_model_path)
    if not model_info:
        sys.exit(1)
    tokenizer = QwenTokenizerWrapper(model_path=qwen_model_path, use_real_tokenizer=True)
    
    config = CausalLMConfig(
        vocab_size=model_info['vocab_size'],
        num_token_id=tokenizer.num_token_id,
        hidden_size=model_info['hidden_size'],
        causal_dim=model_info['hidden_size'],
        use_real_qwen=True,
        qwen_model_path=qwen_model_path,
        use_numerical_features=True,
    )
    model = CausalLanguageModel(config).to(device)
    model.init_weights()
    model.eval()
    print("   âœ… æ¨¡å‹å’Œåˆ†è¯å™¨åˆå§‹åŒ–å®Œæˆã€‚")

    # --- æ­¥éª¤ 2: å‡†å¤‡è¾“å…¥æ•°æ® ---
    print_step("æ­¥éª¤ 2", "å‡†å¤‡å•ä¸ªè¾“å…¥æ ·æœ¬")
    text = "The price is 99.9."
    inputs = tokenizer.batch_encode_plus([text], padding=True, return_tensors='pt')
    input_ids = inputs['input_ids'].to(device)
    numerical_values = inputs['numerical_values'].to(device)
    attention_mask = inputs['attention_mask'].to(device)
    print(f"   - è¾“å…¥æ–‡æœ¬: '{text}'")

    # --- æ­¥éª¤ 3: è·å–å› æœåˆ†å¸ƒå‚æ•° ---
    print_step("æ­¥éª¤ 3", "å‰å‘ä¼ æ’­è·å–å› æœè¡¨å¾ U çš„åˆ†å¸ƒå‚æ•°")
    with torch.no_grad():
        # æ‰§è¡Œå®Œæ•´çš„æ¨¡å‹å‰å‘ä¼ æ’­
        outputs = model(
            input_ids=input_ids,
            numerical_values=numerical_values,
            attention_mask=attention_mask,
        )
        loc_U = outputs.get('causal_loc')
        scale_U = outputs.get('causal_scale')

    # åˆ†ææœ€åä¸€ä¸ªè¯å…ƒçš„åˆ†å¸ƒ
    last_token_idx = -1
    loc_U_last = loc_U[:, last_token_idx, :]
    scale_U_last = scale_U[:, last_token_idx, :]
    print("   - å·²è·å–æœ€åä¸€ä¸ªè¯å…ƒçš„å› æœè¡¨å¾åˆ†å¸ƒå‚æ•°:")
    print_tensor_stats("loc_U (last token)", loc_U_last)
    print_tensor_stats("scale_U (last token)", scale_U_last)

    # --- æ­¥éª¤ 4: æ‰§è¡Œå› æœé‡‡æ · ---
    print_step("æ­¥éª¤ 4", "æ‰§è¡Œä¸¤æ¬¡å› æœé‡‡æ ·ä»¥éªŒè¯éšæœºæ€§")

    previous_u_sample = None
    for i in range(2):
        print(f"\n   --- é‡‡æ ·è¿è¡Œ #{i+1} ---")
        
        # 1. é‡‡æ ·"åŸå› "
        torch.manual_seed(42 + i) # ä½¿ç”¨ä¸åŒçš„ç§å­ä»¥ç¡®ä¿ç»“æœä¸åŒ
        cauchy_dist = torch.distributions.Cauchy(loc_U_last, scale_U_last)
        u_sample = cauchy_dist.sample()
        
        print("   - æ­¥éª¤ 4.1: é‡‡æ ·'åŸå› ' (Sample the Cause)")
        print_tensor_stats("é‡‡æ ·å¾—åˆ°çš„ u_sample", u_sample)

        # 2. è§‚å¯Ÿ'ç»“æœ' - æ‰‹åŠ¨æ‰§è¡Œç¡®å®šæ€§çº¿æ€§å˜æ¢
        with torch.no_grad():
            # åˆ†ç±»: logit = u * W_cls^T
            cls_logits = F.linear(
                u_sample,
                weight=model.action_network.classification_head.causal_linear.weight
            )
            # å›å½’: value = u * W_reg^T + b_reg
            reg_output = F.linear(
                u_sample,
                weight=model.action_network.regression_head.causal_linear.weight,
                bias=model.action_network.regression_head.causal_linear.bias
            ).squeeze(-1) # æŒ¤å‹æ‰æœ€åçš„ç»´åº¦
        
        predicted_token_id = torch.argmax(cls_logits, dim=-1).item()
        predicted_token = tokenizer.decode([predicted_token_id])
        predicted_value = reg_output.item()

        print("\n   - æ­¥éª¤ 4.2: è§‚å¯Ÿ'ç»“æœ' (Observe the Effect)")
        print(f"     - é¢„æµ‹çš„è¯å…ƒ (Argmax of Logits): '{predicted_token}' (ID: {predicted_token_id})")
        print(f"     - é¢„æµ‹çš„æ•°å€¼: {predicted_value:.4f}")

        # 3. éªŒè¯ä¸ä¸Šä¸€æ¬¡é‡‡æ ·çš„ç»“æœæ˜¯å¦ä¸åŒ
        if previous_u_sample is not None:
            u_is_different = not torch.allclose(u_sample, previous_u_sample)
            print("\n   - æ­¥éª¤ 4.3: éšæœºæ€§éªŒè¯")
            print(f"     - æœ¬æ¬¡é‡‡æ ·çš„ `u` ä¸ä¸Šæ¬¡æ˜¯å¦ä¸åŒ? {'âœ… æ˜¯' if u_is_different else 'âŒ å¦'}")
            assert u_is_different, "ä¸¤æ¬¡é‡‡æ ·çš„ u ç›¸åŒï¼Œéšæœºæ€§å¯èƒ½å­˜åœ¨é—®é¢˜ï¼"
        
        previous_u_sample = u_sample

    print(f"\n\n{'='*80}")
    print("ğŸ‰ éªŒè¯æˆåŠŸï¼å› æœé‡‡æ ·æµç¨‹ç¬¦åˆé¢„æœŸã€‚")
    print("   - æˆåŠŸä» `Cauchy(loc_U, scale_U)` åˆ†å¸ƒä¸­é‡‡æ ·å¾—åˆ°äº† `u`ã€‚")
    print("   - æˆåŠŸå°† `u` ä¼ å…¥è¡ŒåŠ¨ç½‘ç»œè·å¾—äº†ç¡®å®šæ€§è¾“å‡ºã€‚")
    print("   - è¿ç»­ä¸¤æ¬¡é‡‡æ ·äº§ç”Ÿäº†ä¸åŒçš„ `u`ï¼ŒéªŒè¯äº†éšæœºæ€§ã€‚")

if __name__ == '__main__':
    main() 