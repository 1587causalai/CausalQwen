"""
ç¦»æ•£æœ‰åºæ¿€æ´»æ•°å­¦éªŒè¯è„šæœ¬
è¯¦ç»†å±•ç¤ºæ•°å­¦è®¡ç®—è¿‡ç¨‹ï¼ŒéªŒè¯å®ç°çš„æ­£ç¡®æ€§
"""

import torch
import numpy as np
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from causal_engine import CausalEngine, ActivationHead


def manual_ordinal_calculation(loc_S, scale_S, thresholds):
    """
    æ‰‹åŠ¨è®¡ç®—ç¦»æ•£æœ‰åºæ¿€æ´»ï¼Œç”¨äºéªŒè¯è‡ªåŠ¨å®ç°
    
    æ•°å­¦å…¬å¼ï¼š
    P(Y = k) = P(C_k < S â‰¤ C_{k+1})
             = CDF_Cauchy(C_{k+1}) - CDF_Cauchy(C_k)
    
    å…¶ä¸­ CDF_Cauchy(c) = 1/2 + (1/Ï€)arctan((c - loc_S)/scale_S)
    """
    def cauchy_cdf(x, loc, scale):
        return 0.5 + (1 / np.pi) * torch.atan((x - loc) / scale)
    
    # æ„å»ºå®Œæ•´é˜ˆå€¼åºåˆ—ï¼š[-âˆ, C_1, C_2, ..., C_{K-1}, +âˆ]
    neg_inf = torch.tensor(float('-inf'))
    pos_inf = torch.tensor(float('+inf'))
    full_thresholds = torch.cat([
        neg_inf.unsqueeze(0), 
        thresholds, 
        pos_inf.unsqueeze(0)
    ])
    
    num_classes = len(full_thresholds) - 1
    probs = []
    
    print(f"æ‰‹åŠ¨è®¡ç®—è¿‡ç¨‹ï¼š")
    print(f"loc_S = {loc_S:.4f}, scale_S = {scale_S:.4f}")
    print(f"é˜ˆå€¼åºåˆ—: {[f'{t:.2f}' if not torch.isinf(t) else str(t.item()) for t in full_thresholds]}")
    print()
    
    for k in range(num_classes):
        lower_threshold = full_thresholds[k]
        upper_threshold = full_thresholds[k + 1]
        
        # è®¡ç®—CDFå€¼
        if torch.isinf(lower_threshold) and lower_threshold < 0:
            lower_cdf = torch.tensor(0.0)
        else:
            lower_cdf = cauchy_cdf(lower_threshold, loc_S, scale_S)
            
        if torch.isinf(upper_threshold) and upper_threshold > 0:
            upper_cdf = torch.tensor(1.0)
        else:
            upper_cdf = cauchy_cdf(upper_threshold, loc_S, scale_S)
        
        # åŒºé—´æ¦‚ç‡
        prob_k = upper_cdf - lower_cdf
        probs.append(prob_k)
        
        print(f"ç±»åˆ« {k}: P({lower_threshold:.2f} < S â‰¤ {upper_threshold:.2f}) = {prob_k.item():.4f}")
        print(f"  CDF({upper_threshold:.2f}) = {upper_cdf.item():.4f}")
        print(f"  CDF({lower_threshold:.2f}) = {lower_cdf.item():.4f}")
        print(f"  P(Y={k}) = {prob_k.item():.4f}")
        print()
    
    probs_tensor = torch.stack(probs)
    predicted_class = torch.argmax(probs_tensor)
    
    print(f"æ¦‚ç‡åˆ†å¸ƒ: {[f'{p.item():.4f}' for p in probs]}")
    print(f"æ¦‚ç‡å’Œ: {sum(probs).item():.4f} (åº”è¯¥â‰ˆ1.0)")
    print(f"é¢„æµ‹ç±»åˆ«: {predicted_class.item()}")
    
    return probs_tensor, predicted_class


def validate_ordinal_activation():
    """éªŒè¯ç¦»æ•£æœ‰åºæ¿€æ´»çš„æ•°å­¦æ­£ç¡®æ€§"""
    
    print("=" * 60)
    print("CausalEngine ç¦»æ•£æœ‰åºæ¿€æ´»æ•°å­¦éªŒè¯")
    print("=" * 60)
    print()
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„4çº§ç¦»æ•£æœ‰åºåˆ†ç±»å™¨
    activation_head = ActivationHead(
        output_size=1,
        activation_modes="ordinal",
        ordinal_num_classes=4,
        ordinal_threshold_init=1.0
    )
    
    # æ˜¾ç¤ºåˆå§‹åŒ–çš„é˜ˆå€¼
    thresholds = activation_head.ordinal_thresholds['ordinal_0']
    print(f"åˆå§‹åŒ–é˜ˆå€¼: {thresholds.tolist()}")
    print(f"è¿™å°†åˆ›å»º4ä¸ªåŒºé—´: (-âˆ, {thresholds[0]:.2f}], ({thresholds[0]:.2f}, {thresholds[1]:.2f}], ({thresholds[1]:.2f}, {thresholds[2]:.2f}], ({thresholds[2]:.2f}, +âˆ)")
    print()
    
    # æµ‹è¯•å‡ ä¸ªä¸åŒçš„Så€¼
    test_cases = [
        {"loc_S": -2.0, "scale_S": 1.0, "expected_class": 0, "desc": "å¼ºçƒˆåå‘ç¬¬1ç±»"},
        {"loc_S": 0.0, "scale_S": 1.0, "expected_class": 1, "desc": "ä¸­ç­‰åå‘ç¬¬2ç±»"}, 
        {"loc_S": 2.0, "scale_S": 1.0, "expected_class": 3, "desc": "å¼ºçƒˆåå‘ç¬¬4ç±»"},
        {"loc_S": 0.0, "scale_S": 0.1, "expected_class": None, "desc": "ä½ä¸ç¡®å®šæ€§"},
        {"loc_S": 0.0, "scale_S": 5.0, "expected_class": None, "desc": "é«˜ä¸ç¡®å®šæ€§"}
    ]
    
    for i, case in enumerate(test_cases):
        print(f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['desc']}")
        print("-" * 40)
        
        # æ„é€ è¾“å…¥
        loc_S = torch.tensor([[[case['loc_S']]]])  # [1, 1, 1] - batch_size, seq_len, output_size
        scale_S = torch.tensor([[[case['scale_S']]]])  # [1, 1, 1]
        
        # æ‰‹åŠ¨è®¡ç®—
        print("ã€æ‰‹åŠ¨è®¡ç®—ã€‘")
        manual_probs, manual_pred = manual_ordinal_calculation(
            loc_S[0, 0, 0], scale_S[0, 0, 0], thresholds
        )
        
        print("ã€ActivationHead è‡ªåŠ¨è®¡ç®—ã€‘")
        # ä½¿ç”¨ActivationHeadè‡ªåŠ¨è®¡ç®—
        with torch.no_grad():
            result = activation_head(loc_S, scale_S, return_dict=True)
            auto_pred = result['output'][0, 0, 0].item()
        
        print(f"è‡ªåŠ¨é¢„æµ‹ç±»åˆ«: {auto_pred}")
        print()
        
        # éªŒè¯ä¸€è‡´æ€§
        consistency = abs(manual_pred.item() - auto_pred) < 1e-6
        print(f"ä¸€è‡´æ€§æ£€éªŒ: {'âœ… é€šè¿‡' if consistency else 'âŒ å¤±è´¥'}")
        
        if case['expected_class'] is not None:
            expectation_met = case['expected_class'] == manual_pred.item()
            print(f"æœŸæœ›éªŒè¯: æœŸæœ›ç±»åˆ«{case['expected_class']}, å®é™…ç±»åˆ«{manual_pred.item()}, {'âœ… ç¬¦åˆ' if expectation_met else 'âŒ ä¸ç¬¦'}")
        
        print("=" * 60)
        print()


def validate_multi_class_ordinal():
    """éªŒè¯ä¸åŒç±»åˆ«æ•°çš„ç¦»æ•£æœ‰åºæ¿€æ´»"""
    
    print("å¤šç±»åˆ«ç¦»æ•£æœ‰åºæ¿€æ´»éªŒè¯")
    print("=" * 40)
    
    class_configs = [3, 5, 7]  # æµ‹è¯•3ç±»ã€5ç±»ã€7ç±»
    
    for num_classes in class_configs:
        print(f"\nğŸ¯ {num_classes}ç±»åˆ«ç¦»æ•£æœ‰åºæ¿€æ´»æµ‹è¯•:")
        
        head = ActivationHead(
            output_size=1,
            activation_modes="ordinal", 
            ordinal_num_classes=num_classes,
            ordinal_threshold_init=1.0
        )
        
        # è·å–é˜ˆå€¼
        thresholds = head.ordinal_thresholds['ordinal_0']
        print(f"é˜ˆå€¼æ•°é‡: {len(thresholds)} (ç±»åˆ«æ•°-1)")
        print(f"é˜ˆå€¼: {[f'{t:.2f}' for t in thresholds.tolist()]}")
        
        # æµ‹è¯•ä¸€ä¸ªä¸­æ€§çš„Så€¼
        loc_S = torch.tensor([[[0.0]]])  # [1, 1, 1]
        scale_S = torch.tensor([[[1.0]]])  # [1, 1, 1]
        
        result = head(loc_S, scale_S, return_dict=True)
        pred_class = result['output'][0, 0, 0].item()
        
        print(f"ä¸­æ€§è¾“å…¥ (loc_S=0, scale_S=1) é¢„æµ‹ç±»åˆ«: {int(pred_class)}")
        print(f"æœ‰æ•ˆç±»åˆ«èŒƒå›´: 0 åˆ° {num_classes-1}")
        
        # éªŒè¯è¾“å‡ºèŒƒå›´
        valid_range = 0 <= pred_class <= num_classes - 1
        print(f"èŒƒå›´æ£€éªŒ: {'âœ… é€šè¿‡' if valid_range else 'âŒ å¤±è´¥'}")


if __name__ == "__main__":
    validate_ordinal_activation()
    validate_multi_class_ordinal()
    
    print("\nğŸ‰ ç¦»æ•£æœ‰åºæ¿€æ´»æ•°å­¦éªŒè¯å®Œæˆï¼")
    print("\nğŸ“ éªŒè¯è¦ç‚¹:")
    print("1. æ‰‹åŠ¨è®¡ç®—ä¸è‡ªåŠ¨è®¡ç®—ç»“æœä¸€è‡´")
    print("2. æ¦‚ç‡åˆ†å¸ƒå’Œä¸º1.0")
    print("3. ä¸åŒSå€¼äº§ç”Ÿåˆç†çš„ç±»åˆ«é¢„æµ‹")
    print("4. æ”¯æŒä»»æ„æ•°é‡çš„æœ‰åºç±»åˆ«")
    print("5. æ•°å­¦å…¬å¼å®ç°æ­£ç¡®") 