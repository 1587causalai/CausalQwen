"""
çœŸå®æ•°æ®é›†ç¤ºä¾‹ - é¸¢å°¾èŠ±åˆ†ç±»
===========================

è¿™ä¸ªæ•™ç¨‹ä½¿ç”¨ç»å…¸çš„é¸¢å°¾èŠ±æ•°æ®é›†ï¼Œæ¼”ç¤ºå¦‚ä½•ç”¨ CausalQwen å¤„ç†çœŸå®æ•°æ®ã€‚
é¸¢å°¾èŠ±æ•°æ®é›†æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸæœ€è‘—åçš„æ•°æ®é›†ä¹‹ä¸€ï¼ŒåŒ…å«3ç§é¸¢å°¾èŠ±çš„æµ‹é‡æ•°æ®ã€‚

å­¦ä¹ ç›®æ ‡ï¼š
1. å­¦ä¼šå¤„ç†çœŸå®æ•°æ®é›†
2. ç†è§£æ•°æ®é¢„å¤„ç†çš„é‡è¦æ€§
3. æŒæ¡å°æ•°æ®é›†çš„å¤„ç†æŠ€å·§
4. å­¦ä¼šè§£é‡Šç°å®ä¸–ç•Œçš„é¢„æµ‹ç»“æœ
"""

import sys
import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from utils.simple_models import SimpleCausalClassifier, compare_with_sklearn
from utils.data_helpers import visualize_predictions


def main():
    """ä¸»å‡½æ•°ï¼šé¸¢å°¾èŠ±åˆ†ç±»å®Œæ•´æµç¨‹"""
    
    print("ğŸŒ¸ CausalQwen çœŸå®æ•°æ®ç¤ºä¾‹ - é¸¢å°¾èŠ±åˆ†ç±»")
    print("=" * 50)
    
    print("\\nğŸ“š å…³äºé¸¢å°¾èŠ±æ•°æ®é›†:")
    print("è¿™æ˜¯1936å¹´ç”±ç”Ÿç‰©å­¦å®¶Edgar Andersonæ”¶é›†çš„æ•°æ®ï¼Œ")
    print("åŒ…å«äº†3ç§é¸¢å°¾èŠ±ï¼ˆå±±é¸¢å°¾ã€å˜è‰²é¸¢å°¾ã€ç»´å‰å°¼äºšé¸¢å°¾ï¼‰çš„å½¢æ€æµ‹é‡æ•°æ®ã€‚")
    print("æ¯ç§èŠ±æœ‰50ä¸ªæ ·æœ¬ï¼Œå…±150ä¸ªæ ·æœ¬ï¼Œ4ä¸ªç‰¹å¾ã€‚")
    
    # 1. åŠ è½½æ•°æ®
    print("\\nğŸ“Š æ­¥éª¤ 1: åŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†")
    iris = load_iris()
    X = iris.data
    y = iris.target
    
    feature_names = iris.feature_names
    class_names = iris.target_names
    
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ:")
    print(f"   æ ·æœ¬æ•°é‡: {X.shape[0]}")
    print(f"   ç‰¹å¾æ•°é‡: {X.shape[1]}")
    print(f"   ç±»åˆ«æ•°é‡: {len(class_names)}")
    
    print(f"\\nğŸ·ï¸ ç‰¹å¾è¯´æ˜:")
    for i, name in enumerate(feature_names):
        print(f"   {i+1}. {name}")
    
    print(f"\\nğŸŒ¸ é¸¢å°¾èŠ±ç§ç±»:")
    for i, name in enumerate(class_names):
        print(f"   {i}. {name} ({name})")
    
    # 2. æ•°æ®æ¢ç´¢
    print("\\nğŸ” æ­¥éª¤ 2: æ•°æ®æ¢ç´¢")
    explore_iris_data(X, y, feature_names, class_names)
    
    # 3. æ•°æ®é¢„å¤„ç†
    print("\\nğŸ”§ æ­¥éª¤ 3: æ•°æ®é¢„å¤„ç†")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    print(f"   ç‰¹å¾å·²æ ‡å‡†åŒ–")
    
    # 4. è®­ç»ƒ CausalQwen æ¨¡å‹
    print("\\nğŸš€ æ­¥éª¤ 4: è®­ç»ƒ CausalQwen åˆ†ç±»å™¨")
    
    model = SimpleCausalClassifier(random_state=42)
    model.fit(X_train_scaled, y_train, epochs=100, verbose=True)
    
    # 5. æ¨¡å‹è¯„ä¼°
    print("\\nğŸ“Š æ­¥éª¤ 5: æ¨¡å‹è¯„ä¼°")
    
    # é¢„æµ‹
    predictions = model.predict(X_test_scaled)
    pred_probs = model.predict(X_test_scaled, return_probabilities=True)[1]
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(y_test, predictions)
    print(f"\\næµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print("\\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    report = classification_report(y_test, predictions, target_names=class_names)
    print(report)
    
    # 6. ä¸åŒæ¨ç†æ¨¡å¼å¯¹æ¯”
    print("\\nğŸŒ¡ï¸ æ­¥éª¤ 6: ä¸åŒæ¨ç†æ¨¡å¼å¯¹æ¯”")
    compare_inference_modes(model, X_test_scaled, y_test, class_names)
    
    # 7. é¢„æµ‹è§£é‡Š
    print("\\nğŸ§  æ­¥éª¤ 7: é¢„æµ‹è§£é‡Šåˆ†æ")
    analyze_predictions(model, X_test_scaled, y_test, feature_names, class_names)
    
    # 8. ç‰¹å¾é‡è¦æ€§
    print("\\nğŸ“ˆ æ­¥éª¤ 8: ç‰¹å¾é‡è¦æ€§åˆ†æ")
    analyze_feature_importance(model, X_test_scaled, feature_names, class_names)
    
    # 9. é”™è¯¯æ¡ˆä¾‹åˆ†æ
    print("\\nğŸ” æ­¥éª¤ 9: é”™è¯¯æ¡ˆä¾‹åˆ†æ")
    analyze_errors(X_test_scaled, y_test, predictions, feature_names, class_names, scaler)
    
    # 10. ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”
    print("\\nâš–ï¸ æ­¥éª¤ 10: ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ å¯¹æ¯”")
    comparison_results = compare_with_sklearn(X, y, task_type='classification')
    
    # 11. å®é™…åº”ç”¨æ¼”ç¤º
    print("\\nğŸŒ¸ æ­¥éª¤ 11: å®é™…åº”ç”¨æ¼”ç¤º")
    demo_real_world_prediction(model, scaler, feature_names, class_names)
    
    # 12. ç»“æœå¯è§†åŒ–
    print("\\nğŸ“Š æ­¥éª¤ 12: ç»“æœå¯è§†åŒ–")
    visualize_predictions(y_test, predictions, 'classification', 'é¸¢å°¾èŠ±åˆ†ç±» - CausalQwen ç»“æœ')
    
    # ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾
    plot_feature_distributions(X, y, feature_names, class_names)
    
    print("\\nğŸ‰ é¸¢å°¾èŠ±åˆ†ç±»æ•™ç¨‹å®Œæˆï¼")
    print("\\nğŸ¯ å…³é”®æ”¶è·:")
    print(f"   1. åœ¨ç»å…¸æ•°æ®é›†ä¸Šè¾¾åˆ°äº† {accuracy:.4f} çš„å‡†ç¡®ç‡")
    print("   2. å­¦ä¼šäº†å¤„ç†çœŸå®ä¸–ç•Œçš„å°æ•°æ®é›†")
    print("   3. ç†è§£äº†ç‰¹å¾çš„å®é™…å«ä¹‰å’Œé‡è¦æ€§")
    print("   4. æŒæ¡äº†æ¨¡å‹è§£é‡Šå’Œé”™è¯¯åˆ†ææ–¹æ³•")


def explore_iris_data(X, y, feature_names, class_names):
    """æ¢ç´¢é¸¢å°¾èŠ±æ•°æ®"""
    
    # åˆ›å»ºDataFrameä¾¿äºåˆ†æ
    df = pd.DataFrame(X, columns=feature_names)
    df['species'] = [class_names[i] for i in y]
    
    print("\\nåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
    print(df.describe())
    
    print("\\nå„ç±»åˆ«æ ·æœ¬æ•°:")
    print(df['species'].value_counts())
    
    # è®¡ç®—å„ç±»åˆ«å„ç‰¹å¾çš„å‡å€¼
    print("\\nå„ç±»åˆ«ç‰¹å¾å‡å€¼:")
    class_means = df.groupby('species')[feature_names].mean()
    print(class_means)
    
    # å¯»æ‰¾æœ€å…·åŒºåˆ†æ€§çš„ç‰¹å¾
    print("\\nç‰¹å¾åŒºåˆ†åº¦åˆ†æ:")
    for feature in feature_names:
        feature_values = df.groupby('species')[feature].mean()
        max_diff = feature_values.max() - feature_values.min()
        print(f"   {feature}: æœ€å¤§å·®å¼‚ = {max_diff:.3f}")


def compare_inference_modes(model, X_test, y_test, class_names):
    """å¯¹æ¯”ä¸åŒæ¨ç†æ¨¡å¼"""
    
    modes = [
        (0, False, "ç¡®å®šæ€§å› æœæ¨ç†"),
        (1.0, False, "æ ‡å‡†æ¨ç†"),
        (0.8, True, "æ¢ç´¢æ€§æ¨ç†")
    ]
    
    results = {}
    
    for temp, do_sample, mode_name in modes:
        try:
            if do_sample:
                # é‡‡æ ·æ¨¡å¼å¤šæ¬¡é¢„æµ‹å–ä¼—æ•°
                predictions_list = []
                for _ in range(5):
                    pred = model.predict(X_test, temperature=temp)
                    predictions_list.append(pred)
                
                # è®¡ç®—ä¼—æ•°
                predictions_array = np.array(predictions_list)
                final_pred = []
                for i in range(len(X_test)):
                    unique, counts = np.unique(predictions_array[:, i], return_counts=True)
                    final_pred.append(unique[np.argmax(counts)])
                final_pred = np.array(final_pred)
            else:
                final_pred = model.predict(X_test, temperature=temp)
            
            accuracy = accuracy_score(y_test, final_pred)
            results[mode_name] = accuracy
            
        except Exception as e:
            print(f"   {mode_name} é‡åˆ°é—®é¢˜: {e}")
            continue
    
    print("\\nä¸åŒæ¨ç†æ¨¡å¼å‡†ç¡®ç‡å¯¹æ¯”:")
    for mode_name, accuracy in results.items():
        print(f"   {mode_name}: {accuracy:.4f}")


def analyze_predictions(model, X_test, y_test, feature_names, class_names):
    """åˆ†æé¢„æµ‹ç»“æœ"""
    
    # è·å–å¸¦æ¦‚ç‡çš„é¢„æµ‹
    pred_labels, pred_probs = model.predict(X_test, return_probabilities=True)
    
    print("\\né¢„æµ‹ç½®ä¿¡åº¦åˆ†æ:")
    max_probs = np.max(pred_probs, axis=1)
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {max_probs.mean():.4f}")
    print(f"   æœ€é«˜ç½®ä¿¡åº¦: {max_probs.max():.4f}")
    print(f"   æœ€ä½ç½®ä¿¡åº¦: {max_probs.min():.4f}")
    
    # æ‰¾åˆ°å‡ ä¸ªæœ‰è¶£çš„é¢„æµ‹æ¡ˆä¾‹
    print("\\nä»£è¡¨æ€§é¢„æµ‹æ¡ˆä¾‹:")
    
    # é«˜ç½®ä¿¡åº¦æ­£ç¡®é¢„æµ‹
    correct_mask = pred_labels == y_test
    high_conf_correct = np.where(correct_mask & (max_probs > 0.9))[0]
    if len(high_conf_correct) > 0:
        idx = high_conf_correct[0]
        print(f"\\n  ğŸ¯ é«˜ç½®ä¿¡åº¦æ­£ç¡®é¢„æµ‹ (æ ·æœ¬ {idx}):")
        print(f"     çœŸå®ç±»åˆ«: {class_names[y_test[idx]]}")
        print(f"     é¢„æµ‹ç±»åˆ«: {class_names[pred_labels[idx]]}")
        print(f"     ç½®ä¿¡åº¦: {max_probs[idx]:.4f}")
        show_sample_features(X_test[idx], feature_names)
    
    # ä½ç½®ä¿¡åº¦é¢„æµ‹
    low_conf_indices = np.where(max_probs < 0.7)[0]
    if len(low_conf_indices) > 0:
        idx = low_conf_indices[0]
        print(f"\\n  ğŸ¤” ä½ç½®ä¿¡åº¦é¢„æµ‹ (æ ·æœ¬ {idx}):")
        print(f"     çœŸå®ç±»åˆ«: {class_names[y_test[idx]]}")
        print(f"     é¢„æµ‹ç±»åˆ«: {class_names[pred_labels[idx]]}")
        print(f"     ç½®ä¿¡åº¦: {max_probs[idx]:.4f}")
        print(f"     å„ç±»åˆ«æ¦‚ç‡: {[f'{p:.3f}' for p in pred_probs[idx]]}")
        show_sample_features(X_test[idx], feature_names)
    
    # é”™è¯¯é¢„æµ‹
    error_indices = np.where(~correct_mask)[0]
    if len(error_indices) > 0:
        idx = error_indices[0]
        print(f"\\n  âŒ é”™è¯¯é¢„æµ‹æ¡ˆä¾‹ (æ ·æœ¬ {idx}):")
        print(f"     çœŸå®ç±»åˆ«: {class_names[y_test[idx]]}")
        print(f"     é¢„æµ‹ç±»åˆ«: {class_names[pred_labels[idx]]}")
        print(f"     ç½®ä¿¡åº¦: {max_probs[idx]:.4f}")
        show_sample_features(X_test[idx], feature_names)


def show_sample_features(sample, feature_names):
    """æ˜¾ç¤ºæ ·æœ¬çš„ç‰¹å¾å€¼"""
    print("     ç‰¹å¾å€¼:")
    for i, (name, value) in enumerate(zip(feature_names, sample)):
        print(f"       {name}: {value:.3f}")


def analyze_feature_importance(model, X_test, feature_names, class_names):
    """åˆ†æç‰¹å¾é‡è¦æ€§"""
    
    if hasattr(model, '_get_feature_importance'):
        importance = model._get_feature_importance()
        if importance is not None:
            print("\\nç‰¹å¾é‡è¦æ€§æ’åº:")
            
            # æŒ‰é‡è¦æ€§æ’åº
            sorted_indices = np.argsort(importance)[::-1]
            
            for i, idx in enumerate(sorted_indices):
                print(f"   {i+1}. {feature_names[idx]}: {importance[idx]:.4f}")
            
            # è§£é‡Šæœ€é‡è¦çš„ç‰¹å¾
            most_important = feature_names[sorted_indices[0]]
            print(f"\\nğŸ’¡ æœ€é‡è¦çš„ç‰¹å¾æ˜¯ '{most_important}'")
            print("   è¿™ä¸ªç‰¹å¾å¯¹åŒºåˆ†ä¸åŒé¸¢å°¾èŠ±ç§ç±»æœ€æœ‰å¸®åŠ©ã€‚")
        else:
            print("\\nç‰¹å¾é‡è¦æ€§ä¿¡æ¯æš‚ä¸å¯ç”¨")
    
    # åŸºäºåŸŸçŸ¥è¯†çš„ç‰¹å¾è§£é‡Š
    print("\\nğŸŒ¸ é¸¢å°¾èŠ±ç‰¹å¾çš„ç”Ÿç‰©å­¦æ„ä¹‰:")
    feature_meanings = {
        'sepal length (cm)': 'èŠ±è¼é•¿åº¦ - ä¿æŠ¤èŠ±æœµçš„å¤–å±‚ç»“æ„',
        'sepal width (cm)': 'èŠ±è¼å®½åº¦ - å½±å“èŠ±æœµçš„æ•´ä½“å½¢çŠ¶',
        'petal length (cm)': 'èŠ±ç“£é•¿åº¦ - æœ€æ˜¾è‘—çš„åŒºåˆ†ç‰¹å¾',
        'petal width (cm)': 'èŠ±ç“£å®½åº¦ - èŠ±æœµçš„è§†è§‰ç‰¹å¾'
    }
    
    for feature, meaning in feature_meanings.items():
        print(f"   â€¢ {feature}: {meaning}")


def analyze_errors(X_test, y_test, predictions, feature_names, class_names, scaler):
    """åˆ†æé”™è¯¯é¢„æµ‹"""
    
    error_mask = y_test != predictions
    error_count = error_mask.sum()
    
    if error_count == 0:
        print("\\nğŸ‰ å®Œç¾é¢„æµ‹ï¼æ²¡æœ‰é”™è¯¯æ¡ˆä¾‹ã€‚")
        return
    
    print(f"\\né”™è¯¯é¢„æµ‹åˆ†æ (å…± {error_count} ä¸ªé”™è¯¯):")
    
    error_indices = np.where(error_mask)[0]
    
    for i, idx in enumerate(error_indices):
        if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯æ¡ˆä¾‹
            print(f"   ... è¿˜æœ‰ {len(error_indices) - 3} ä¸ªé”™è¯¯æ¡ˆä¾‹")
            break
        
        true_class = class_names[y_test[idx]]
        pred_class = class_names[predictions[idx]]
        
        print(f"\\n   é”™è¯¯æ¡ˆä¾‹ {i+1}:")
        print(f"     çœŸå®ç±»åˆ«: {true_class}")
        print(f"     é¢„æµ‹ç±»åˆ«: {pred_class}")
        
        # åæ ‡å‡†åŒ–ç‰¹å¾å€¼ä»¥ä¾¿ç†è§£
        original_features = scaler.inverse_transform([X_test[idx]])[0]
        print(f"     ç‰¹å¾å€¼:")
        for name, value in zip(feature_names, original_features):
            print(f"       {name}: {value:.2f} cm")
        
        # åˆ†æä¸ºä»€ä¹ˆä¼šè¯¯åˆ†ç±»
        print(f"     å¯èƒ½åŸå› : {true_class} å’Œ {pred_class} åœ¨æŸäº›ç‰¹å¾ä¸Šç›¸ä¼¼")


def demo_real_world_prediction(model, scaler, feature_names, class_names):
    """æ¼”ç¤ºçœŸå®ä¸–ç•Œé¢„æµ‹"""
    
    print("\\nå‡è®¾æ‚¨åœ¨é‡å¤–å‘ç°äº†ä¸€æœµé¸¢å°¾èŠ±ï¼Œæµ‹é‡äº†ä»¥ä¸‹æ•°æ®:")
    
    # åˆ›å»ºä¸€ä¸ªå‡è®¾çš„æ–°æ ·æœ¬
    new_flower = np.array([[5.8, 3.2, 4.5, 1.4]])  # ä¸€ä¸ªä¸­ç­‰å¤§å°çš„é¸¢å°¾èŠ±
    
    print("\\nğŸŒ¸ æ–°å‘ç°çš„é¸¢å°¾èŠ±ç‰¹å¾:")
    for name, value in zip(feature_names, new_flower[0]):
        print(f"   {name}: {value:.1f} cm")
    
    # æ ‡å‡†åŒ–
    new_flower_scaled = scaler.transform(new_flower)
    
    # é¢„æµ‹
    pred_label, pred_probs = model.predict(new_flower_scaled, return_probabilities=True)
    pred_label = pred_label[0]
    pred_probs = pred_probs[0]
    
    print(f"\\nğŸ”® CausalQwen çš„é¢„æµ‹ç»“æœ:")
    print(f"   æœ€å¯èƒ½çš„ç§ç±»: {class_names[pred_label]}")
    print(f"   ç½®ä¿¡åº¦: {pred_probs[pred_label]:.4f}")
    
    print(f"\\nğŸ“Š å„ç§ç±»çš„å¯èƒ½æ€§:")
    for i, (class_name, prob) in enumerate(zip(class_names, pred_probs)):
        bar = "â–ˆ" * int(prob * 20)  # ç®€å•çš„æ¡å½¢å›¾
        print(f"   {class_name:15}: {prob:.4f} {bar}")
    
    # ç»™å‡ºå»ºè®®
    confidence = pred_probs[pred_label]
    if confidence > 0.8:
        print(f"\\nğŸ’¡ å»ºè®®: è¿™å¾ˆå¯èƒ½æ˜¯ {class_names[pred_label]}ï¼Œç½®ä¿¡åº¦å¾ˆé«˜ã€‚")
    elif confidence > 0.6:
        print(f"\\nğŸ’¡ å»ºè®®: å¯èƒ½æ˜¯ {class_names[pred_label]}ï¼Œä½†å»ºè®®å†æµ‹é‡å‡ ä¸ªæ ·æœ¬ç¡®è®¤ã€‚")
    else:
        print(f"\\nğŸ’¡ å»ºè®®: åˆ†ç±»ä¸ç¡®å®šï¼Œå»ºè®®å¯»æ±‚ä¸“å®¶å¸®åŠ©æˆ–ä½¿ç”¨å…¶ä»–ç‰¹å¾ã€‚")


def plot_feature_distributions(X, y, feature_names, class_names):
    """ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾"""
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    axes = axes.ravel()
    
    colors = ['red', 'green', 'blue']
    
    for i, feature_name in enumerate(feature_names):
        ax = axes[i]
        
        for j, class_name in enumerate(class_names):
            mask = y == j
            ax.hist(X[mask, i], alpha=0.6, label=class_name, color=colors[j], bins=15)
        
        ax.set_xlabel(feature_name)
        ax.set_ylabel('é¢‘æ¬¡')
        ax.set_title(f'{feature_name} çš„åˆ†å¸ƒ')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("\\nğŸ“Š ç‰¹å¾åˆ†å¸ƒå›¾è¯´æ˜:")
    print("   - ä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒçš„é¸¢å°¾èŠ±ç§ç±»")
    print("   - é‡å å°‘çš„ç‰¹å¾åŒºåˆ†æ€§æ›´å¥½")
    print("   - èŠ±ç“£é•¿åº¦å’Œå®½åº¦é€šå¸¸æœ€å…·åŒºåˆ†æ€§")


if __name__ == "__main__":
    # è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # è¿è¡Œä¸»ç¨‹åº
    main()