"""
å›å½’ä»»åŠ¡å®æˆ˜ - ä½¿ç”¨åˆæˆæ•°æ®
=========================

è¿™ä¸ªæ•™ç¨‹å°†æ·±å…¥æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ CausalQwen å¤„ç†å›å½’ä»»åŠ¡ã€‚
æˆ‘ä»¬å°†ä½¿ç”¨ scikit-learn ç”Ÿæˆçš„åˆæˆæ•°æ®ï¼Œæ¨¡æ‹ŸçœŸå®çš„ä¸šåŠ¡åœºæ™¯ã€‚

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£å›å½’ä»»åŠ¡çš„ç‰¹ç‚¹
2. æŒæ¡æ•°æ®é¢„å¤„ç†æŠ€å·§
3. å­¦ä¼šè°ƒèŠ‚æ¨¡å‹å‚æ•°
4. ç†è§£ä¸ç¡®å®šæ€§é‡åŒ–
5. æŒæ¡ç»“æœè§£é‡Šæ–¹æ³•
"""

import sys
import os
import numpy as np
import matplotlib
# å¦‚æœæ˜¯éäº¤äº’æ¨¡å¼ï¼Œä½¿ç”¨éäº¤äº’åç«¯
if len(sys.argv) > 1:
    matplotlib.use('Agg')
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from utils.simple_models import SimpleCausalRegressor, compare_with_sklearn
from utils.data_helpers import (
    generate_regression_data,
    prepare_data_for_training,
    explore_data,
    visualize_predictions,
    save_results
)


def main():
    """ä¸»å‡½æ•°ï¼šå®Œæ•´çš„å›å½’ä»»åŠ¡æµç¨‹"""
    
    print("ğŸ“ˆ CausalQwen å›å½’ä»»åŠ¡å®æˆ˜æ•™ç¨‹")
    print("=" * 50)
    
    # æ¼”ç¤ºå¤šä¸ªä¸åŒçš„å›å½’åœºæ™¯
    scenarios = [
        {
            'name': 'é”€å”®é¢„æµ‹',
            'description': 'æ ¹æ®å¸‚åœºæŒ‡æ ‡é¢„æµ‹é”€å”®é¢',
            'n_samples': 1000,
            'n_features': 12,
            'noise_level': 0.1,
            'difficulty': 'easy'
        },
        {
            'name': 'èƒ½è€—é¢„æµ‹', 
            'description': 'æ ¹æ®å»ºç­‘ç‰¹å¾é¢„æµ‹èƒ½è€—',
            'n_samples': 800,
            'n_features': 15,
            'noise_level': 0.2,
            'difficulty': 'medium'
        },
        {
            'name': 'è‚¡ä»·é¢„æµ‹',
            'description': 'æ ¹æ®æŠ€æœ¯æŒ‡æ ‡é¢„æµ‹è‚¡ä»·å˜åŒ–',
            'n_samples': 600,
            'n_features': 20,
            'noise_level': 0.3,
            'difficulty': 'hard'
        }
    ]
    
    print("\\nå¯ç”¨çš„å›å½’åœºæ™¯:")
    for i, scenario in enumerate(scenarios):
        print(f"{i+1}. {scenario['name']} - {scenario['description']}")
    
    # è®©ç”¨æˆ·é€‰æ‹©åœºæ™¯
    choice = None
    if len(sys.argv) > 1:
        try:
            arg = int(sys.argv[1]) - 1
            if 0 <= arg < len(scenarios):
                choice = arg
                print(f"\\nè‡ªåŠ¨é€‰æ‹©åœºæ™¯: {arg + 1}")
        except ValueError:
            pass
    
    if choice is None:
        while True:
            try:
                choice = int(input("\\nè¯·é€‰æ‹©ä¸€ä¸ªåœºæ™¯ (1-3): ")) - 1
                if 0 <= choice < len(scenarios):
                    break
                else:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„é€‰æ‹© (1-3)")
            except (ValueError, EOFError, KeyboardInterrupt):
                print("\\né»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªåœºæ™¯...")
                choice = 0
                break
    
    selected_scenario = scenarios[choice]
    print(f"\\nğŸ¯ æ‚¨é€‰æ‹©äº†: {selected_scenario['name']}")
    print(f"åœºæ™¯æè¿°: {selected_scenario['description']}")
    
    # è¿è¡Œé€‰æ‹©çš„åœºæ™¯
    run_regression_scenario(selected_scenario)
    
    print("\\nğŸ‰ å›å½’ä»»åŠ¡æ•™ç¨‹å®Œæˆï¼")
    print("\\nğŸ“– æ¥ä¸‹æ¥æ‚¨å¯ä»¥ï¼š")
    print("  - å°è¯•å…¶ä»–å›å½’åœºæ™¯")
    print("  - è°ƒèŠ‚æ¨¡å‹å‚æ•°çœ‹æ•ˆæœå˜åŒ–")
    print("  - ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®")
    print("  - æŸ¥çœ‹ tips_and_tricks.py å­¦ä¹ è¿›é˜¶æŠ€å·§")


def run_regression_scenario(scenario):
    """è¿è¡Œç‰¹å®šçš„å›å½’åœºæ™¯"""
    
    print(f"\\nğŸš€ å¼€å§‹ {scenario['name']} åœºæ™¯")
    print("-" * 40)
    
    # 1. ç”Ÿæˆæ•°æ®
    print("\\nğŸ“Š æ­¥éª¤ 1: ç”Ÿæˆæ•°æ®")
    X, y, info = generate_regression_data(
        n_samples=scenario['n_samples'],
        n_features=scenario['n_features'],
        noise_level=scenario['noise_level'],
        difficulty=scenario['difficulty'],
        random_state=42
    )
    
    # ä¸ºäº†æ›´å¥½çš„æ¼”ç¤ºï¼Œç»™ç‰¹å¾æ·»åŠ æœ‰æ„ä¹‰çš„åç§°
    feature_names = generate_feature_names(scenario['name'], scenario['n_features'])
    
    print(f"\\nç‰¹å¾è¯´æ˜ï¼ˆ{scenario['name']}åœºæ™¯ï¼‰:")
    for i, name in enumerate(feature_names[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  ç‰¹å¾ {i+1}: {name}")
    if len(feature_names) > 5:
        print(f"  ... è¿˜æœ‰ {len(feature_names)-5} ä¸ªç‰¹å¾")
    
    # 2. æ•°æ®æ¢ç´¢
    print("\\nğŸ” æ­¥éª¤ 2: æ•°æ®æ¢ç´¢")
    explore_data(X, y, info, show_plots=True)
    
    # 3. æ•°æ®å‡†å¤‡
    print("\\nğŸ”§ æ­¥éª¤ 3: æ•°æ®å‡†å¤‡")
    data = prepare_data_for_training(X, y, test_size=0.2, validation_size=0.2)
    
    # 4. è®­ç»ƒåŸºç¡€æ¨¡å‹
    print("\\nğŸš€ æ­¥éª¤ 4: è®­ç»ƒ CausalQwen æ¨¡å‹")
    print("ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒ...")
    
    model_basic = SimpleCausalRegressor(random_state=42)
    model_basic.fit(
        data['X_train'], data['y_train'], 
        epochs=40, 
        verbose=True
    )
    
    # 5. è®­ç»ƒä¼˜åŒ–æ¨¡å‹
    print("\\nâš™ï¸ æ­¥éª¤ 5: å‚æ•°ä¼˜åŒ–")
    print("è®©æˆ‘ä»¬å°è¯•ä¸åŒçš„è®­ç»ƒå‚æ•°...")
    
    model_optimized = SimpleCausalRegressor(random_state=42)
    model_optimized.fit(
        data['X_train'], data['y_train'],
        epochs=60,
        validation_split=0.25,
        verbose=True
    )
    
    # 6. æ¨¡å‹å¯¹æ¯”
    print("\\nğŸ“Š æ­¥éª¤ 6: æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    
    models = {
        'CausalQwen (åŸºç¡€)': model_basic,
        'CausalQwen (ä¼˜åŒ–)': model_optimized
    }
    
    results = {}
    
    for name, model in models.items():
        # é¢„æµ‹
        pred = model.predict(data['X_test'])
        
        # å¦‚æœæ•°æ®è¢«æ ‡å‡†åŒ–ï¼Œéœ€è¦åæ ‡å‡†åŒ–
        if 'y' in data['scalers']:
            pred_original = data['scalers']['y'].inverse_transform(pred.reshape(-1, 1)).flatten()
            y_test_original = data['scalers']['y'].inverse_transform(data['y_test'].reshape(-1, 1)).flatten()
        else:
            pred_original = pred
            y_test_original = data['y_test']
        
        # è®¡ç®—æŒ‡æ ‡
        r2 = r2_score(y_test_original, pred_original)
        mae = mean_absolute_error(y_test_original, pred_original)
        mse = mean_squared_error(y_test_original, pred_original)
        rmse = np.sqrt(mse)
        
        results[name] = {
            'r2': r2,
            'mae': mae,
            'mse': mse,
            'rmse': rmse,
            'predictions': pred_original,
            'actual': y_test_original
        }
        
        print(f"\\n{name}:")
        print(f"  RÂ² åˆ†æ•°: {r2:.4f}")
        print(f"  å¹³å‡ç»å¯¹è¯¯å·®: {mae:.4f}")
        print(f"  å‡æ–¹æ ¹è¯¯å·®: {rmse:.4f}")
    
    # 7. ä¸ç¡®å®šæ€§åˆ†æ
    print("\\nğŸ” æ­¥éª¤ 7: ä¸ç¡®å®šæ€§åˆ†æ")
    print("CausalQwen çš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼šé‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§")
    
    # é€‰æ‹©æœ€ä½³æ¨¡å‹è¿›è¡Œä¸ç¡®å®šæ€§åˆ†æ
    best_model_name = max(results.keys(), key=lambda k: results[k]['r2'])
    best_model = models[best_model_name]
    
    print(f"ä½¿ç”¨æœ€ä½³æ¨¡å‹: {best_model_name}")
    
    # è·å–å¸¦ä¸ç¡®å®šæ€§çš„é¢„æµ‹
    test_sample_indices = np.random.choice(len(data['X_test']), 10, replace=False)
    X_sample = data['X_test'][test_sample_indices]
    y_sample = data['y_test'][test_sample_indices]
    
    pred_mean, pred_std = best_model.predict(X_sample, return_uncertainty=True)
    
    print("\\næ ·æœ¬é¢„æµ‹ç»“æœ (å¸¦ä¸ç¡®å®šæ€§):")
    print("  æ ·æœ¬  |   çœŸå®å€¼   |   é¢„æµ‹å€¼   |  ä¸ç¡®å®šæ€§  |   çŠ¶æ€")
    print("  -----|-----------|-----------|-----------|----------")
    
    for i in range(len(pred_mean)):
        true_val = y_sample[i]
        pred_val = pred_mean[i]
        uncertainty = pred_std[i]
        
        # åˆ¤æ–­é¢„æµ‹æ˜¯å¦åœ¨ä¸ç¡®å®šæ€§èŒƒå›´å†…
        in_range = abs(true_val - pred_val) <= uncertainty
        status = "âœ… å‡†ç¡®" if in_range else "âš ï¸ åå·®"
        
        print(f"   {i+1:2d}   | {true_val:8.3f}  | {pred_val:8.3f}  | Â±{uncertainty:7.3f}  | {status}")
    
    # 8. ç‰¹å¾é‡è¦æ€§åˆ†æ
    print("\\nğŸ§  æ­¥éª¤ 8: é¢„æµ‹è§£é‡Š")
    analyze_feature_importance(best_model, X_sample, feature_names, scenario['name'])
    
    # 9. ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”
    print("\\nâš–ï¸ æ­¥éª¤ 9: ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ å¯¹æ¯”")
    
    # ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆæœªæ ‡å‡†åŒ–ï¼‰è¿›è¡Œå…¬å¹³å¯¹æ¯”
    comparison_results = compare_with_sklearn(X, y, task_type='regression')
    
    # 10. ç»“æœå¯è§†åŒ–
    print("\\nğŸ“Š æ­¥éª¤ 10: ç»“æœå¯è§†åŒ–")
    
    # ä½¿ç”¨æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ç»“æœ
    best_pred = results[best_model_name]['predictions']
    best_actual = results[best_model_name]['actual']
    
    visualize_predictions(best_actual, best_pred, 'regression', f'{scenario["name"]} - CausalQwen ç»“æœ')
    
    # ç»˜åˆ¶ä¸ç¡®å®šæ€§å›¾
    plot_uncertainty_analysis(y_sample, pred_mean, pred_std, scenario['name'])
    
    # 11. ä¿å­˜ç»“æœ
    print("\\nğŸ’¾ æ­¥éª¤ 11: ä¿å­˜ç»“æœ")
    
    final_results = {
        'scenario': scenario,
        'model_comparison': results,
        'sklearn_comparison': comparison_results,
        'feature_names': feature_names,
        'best_model': best_model_name
    }
    
    filename = f"user_tutorials/results/{scenario['name']}_regression_results.json"
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    save_results(final_results, filename)
    
    print(f"\\nâœ¨ {scenario['name']} åœºæ™¯å®Œæˆï¼")
    print("\\nğŸ¯ å…³é”®æ”¶è·:")
    print(f"  1. æœ€ä½³ RÂ² åˆ†æ•°: {results[best_model_name]['r2']:.4f}")
    print("  2. æˆåŠŸé‡åŒ–äº†é¢„æµ‹ä¸ç¡®å®šæ€§")
    print("  3. ç†è§£äº†ç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“")
    print("  4. éªŒè¯äº†ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•çš„ä¼˜åŠ¿")


def generate_feature_names(scenario_name, n_features):
    """ä¸ºä¸åŒåœºæ™¯ç”Ÿæˆæœ‰æ„ä¹‰çš„ç‰¹å¾åç§°"""
    
    feature_sets = {
        'é”€å”®é¢„æµ‹': [
            'å¹¿å‘ŠæŠ•å…¥', 'å­£èŠ‚æŒ‡æ•°', 'ç«äº‰å¯¹æ‰‹ä»·æ ¼', 'å®¢æˆ·æ»¡æ„åº¦', 'äº§å“è¯„åˆ†',
            'åº“å­˜æ°´å¹³', 'ä¿ƒé”€æ´»åŠ¨', 'ç»æµæŒ‡æ•°', 'å¤©æ°”å› ç´ ', 'èŠ‚å‡æ—¥å½±å“',
            'ç¤¾äº¤åª’ä½“çƒ­åº¦', 'å®¢æˆ·å›è´­ç‡', 'æ–°å®¢æˆ·è·å–', 'ä»·æ ¼æ•æ„Ÿåº¦', 'æ¸ é“æ•ˆç‡'
        ],
        'èƒ½è€—é¢„æµ‹': [
            'å»ºç­‘é¢ç§¯', 'æ¥¼å±‚æ•°é‡', 'å»ºé€ å¹´ä»½', 'çª—æˆ·é¢ç§¯', 'ä¿æ¸©ç­‰çº§',
            'ä¾›æš–ç±»å‹', 'é€šé£ç³»ç»Ÿ', 'ç…§æ˜ç±»å‹', 'è®¾å¤‡æ•°é‡', 'ä½¿ç”¨æ—¶é—´',
            'å¤–éƒ¨æ¸©åº¦', 'æ¹¿åº¦æ°´å¹³', 'å»ºç­‘æœå‘', 'ç»¿åŒ–ç¨‹åº¦', 'ç»´æŠ¤æ°´å¹³'
        ],
        'è‚¡ä»·é¢„æµ‹': [
            'RSIæŒ‡æ ‡', 'MACD', 'æˆäº¤é‡', 'å¸‚ç›ˆç‡', 'å¸‚å‡€ç‡',
            'èµ„äº§è´Ÿå€ºç‡', 'å‡€åˆ©æ¶¦å¢é•¿', 'æ”¶å…¥å¢é•¿', 'è¡Œä¸šæŒ‡æ•°', 'å¸‚åœºæƒ…ç»ª',
            'å®è§‚ç»æµ', 'æ”¿ç­–å½±å“', 'å›½é™…å› ç´ ', 'æŠ€æœ¯åˆ›æ–°', 'ç«äº‰åœ°ä½',
            'ç®¡ç†å±‚å˜åŠ¨', 'åˆ†æå¸ˆè¯„çº§', 'æœºæ„æŒä»“', 'æ•£æˆ·æƒ…ç»ª', 'åª’ä½“å…³æ³¨åº¦'
        ]
    }
    
    base_features = feature_sets.get(scenario_name, [])
    
    # å¦‚æœéœ€è¦æ›´å¤šç‰¹å¾ï¼Œæ·»åŠ é€šç”¨ç‰¹å¾
    while len(base_features) < n_features:
        base_features.append(f'ç‰¹å¾_{len(base_features)+1}')
    
    return base_features[:n_features]


def analyze_feature_importance(model, X_sample, feature_names, scenario_name):
    """åˆ†æç‰¹å¾é‡è¦æ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    
    print(f"\\nåˆ†æ {scenario_name} ä¸­æœ€é‡è¦çš„ç‰¹å¾:")
    
    # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„ç‰¹å¾é‡è¦æ€§åˆ†æ
    # åœ¨å®é™…çš„CausalEngineä¸­ï¼Œä¼šæœ‰æ›´sophisticatedçš„æ–¹æ³•
    
    if hasattr(model, '_get_feature_importance'):
        importance = model._get_feature_importance()
        if importance is not None:
            # è·å–æœ€é‡è¦çš„5ä¸ªç‰¹å¾
            top_indices = np.argsort(importance)[-5:][::-1]
            
            print("\\næœ€é‡è¦çš„5ä¸ªç‰¹å¾:")
            for i, idx in enumerate(top_indices):
                feature_name = feature_names[idx] if idx < len(feature_names) else f"ç‰¹å¾_{idx}"
                importance_score = importance[idx]
                print(f"  {i+1}. {feature_name}: {importance_score:.4f}")
        else:
            print("  ç‰¹å¾é‡è¦æ€§ä¿¡æ¯æš‚ä¸å¯ç”¨")
    else:
        print("  ç‰¹å¾é‡è¦æ€§åˆ†æåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­")
    
    # å±•ç¤ºå‡ ä¸ªæ ·æœ¬çš„é¢„æµ‹è§£é‡Š
    print("\\næ ·æœ¬é¢„æµ‹è§£é‡Š:")
    if hasattr(model, 'predict_with_explanation'):
        try:
            explanations = model.predict_with_explanation(X_sample[:3], feature_names)
            
            for i, exp in enumerate(explanations):
                print(f"\\n  æ ·æœ¬ {i+1}:")
                print(f"    é¢„æµ‹å€¼: {exp.get('prediction', 'N/A'):.3f}")
                print(f"    ç½®ä¿¡åº¦: {exp.get('confidence', 0):.3f}")
                
                top_features = exp.get('top_features', [])
                if top_features:
                    print("    å…³é”®å½±å“å› ç´ :")
                    for j, feature in enumerate(top_features):
                        print(f"      {j+1}. {feature['feature']}: {feature['value']:.3f}")
        except Exception as e:
            print(f"  é¢„æµ‹è§£é‡ŠåŠŸèƒ½é‡åˆ°é—®é¢˜: {e}")
    else:
        print("  è¯¦ç»†çš„é¢„æµ‹è§£é‡ŠåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­")


def plot_uncertainty_analysis(y_true, y_pred, y_std, scenario_name):
    """ç»˜åˆ¶ä¸ç¡®å®šæ€§åˆ†æå›¾"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # é¢„æµ‹å€¼ vs çœŸå®å€¼ï¼Œå¸¦è¯¯å·®æ£’
    ax1.errorbar(range(len(y_true)), y_pred, yerr=y_std, fmt='o', capsize=5, alpha=0.7, label='é¢„æµ‹Â±ä¸ç¡®å®šæ€§')
    ax1.scatter(range(len(y_true)), y_true, color='red', alpha=0.8, label='çœŸå®å€¼')
    ax1.set_xlabel('æ ·æœ¬ç´¢å¼•')
    ax1.set_ylabel('å€¼')
    ax1.set_title(f'{scenario_name} - é¢„æµ‹ä¸ç¡®å®šæ€§åˆ†æ')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # ä¸ç¡®å®šæ€§åˆ†å¸ƒ
    ax2.hist(y_std, bins=10, alpha=0.7, edgecolor='black')
    ax2.axvline(np.mean(y_std), color='red', linestyle='--', label=f'å¹³å‡ä¸ç¡®å®šæ€§: {np.mean(y_std):.3f}')
    ax2.set_xlabel('ä¸ç¡®å®šæ€§')
    ax2.set_ylabel('é¢‘æ¬¡')
    ax2.set_title('ä¸ç¡®å®šæ€§åˆ†å¸ƒ')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\\nğŸ“Š ä¸ç¡®å®šæ€§ç»Ÿè®¡:")
    print(f"  å¹³å‡ä¸ç¡®å®šæ€§: {np.mean(y_std):.4f}")
    print(f"  ä¸ç¡®å®šæ€§èŒƒå›´: [{np.min(y_std):.4f}, {np.max(y_std):.4f}]")
    print(f"  ä¸ç¡®å®šæ€§æ ‡å‡†å·®: {np.std(y_std):.4f}")


if __name__ == "__main__":
    # è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs("user_tutorials/results", exist_ok=True)
    
    # è¿è¡Œä¸»ç¨‹åº
    main()