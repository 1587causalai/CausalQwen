"""
æ•°æ®å¤„ç†è¾…åŠ©å‡½æ•°
================

è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†å¸¸ç”¨çš„æ•°æ®å¤„ç†å’Œå¯è§†åŒ–å‡½æ•°ï¼Œ
è®©ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°å‡†å¤‡æ•°æ®å’ŒæŸ¥çœ‹ç»“æœã€‚
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification, make_regression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from typing import Tuple, Optional, Dict, Any
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def generate_classification_data(
    n_samples: int = 1000,
    n_features: int = 20,
    n_classes: int = 3,
    difficulty: str = 'medium',
    random_state: int = 42
) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
    """
    ç”Ÿæˆåˆ†ç±»æ•°æ®é›†
    
    Args:
        n_samples: æ ·æœ¬æ•°é‡
        n_features: ç‰¹å¾æ•°é‡
        n_classes: ç±»åˆ«æ•°é‡
        difficulty: æ•°æ®éš¾åº¦ ('easy', 'medium', 'hard')
        random_state: éšæœºç§å­
    
    Returns:
        X, y, info: ç‰¹å¾çŸ©é˜µï¼Œæ ‡ç­¾å‘é‡ï¼Œæ•°æ®é›†ä¿¡æ¯
    """
    print(f"ğŸ“Š ç”Ÿæˆåˆ†ç±»æ•°æ®é›†...")
    
    # æ ¹æ®éš¾åº¦è®¾ç½®å‚æ•°
    if difficulty == 'easy':
        n_informative = int(n_features * 0.9)
        n_redundant = int(n_features * 0.1)
        n_clusters_per_class = 1
        class_sep = 1.5
    elif difficulty == 'medium':
        n_informative = int(n_features * 0.7)
        n_redundant = int(n_features * 0.2)
        n_clusters_per_class = 2
        class_sep = 1.0
    else:  # hard
        n_informative = int(n_features * 0.5)
        n_redundant = int(n_features * 0.3)
        n_clusters_per_class = 3
        class_sep = 0.7
    
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=n_informative,
        n_redundant=n_redundant,
        n_classes=n_classes,
        n_clusters_per_class=n_clusters_per_class,
        class_sep=class_sep,
        random_state=random_state
    )
    
    # æ•°æ®é›†ä¿¡æ¯
    info = {
        'task_type': 'classification',
        'n_samples': n_samples,
        'n_features': n_features,
        'n_classes': n_classes,
        'difficulty': difficulty,
        'class_distribution': dict(zip(*np.unique(y, return_counts=True)))
    }
    
    print(f"âœ… ç”Ÿæˆå®Œæˆ: {n_samples} æ ·æœ¬, {n_features} ç‰¹å¾, {n_classes} ç±»åˆ«")
    print(f"   éš¾åº¦: {difficulty}")
    print(f"   ç±»åˆ«åˆ†å¸ƒ: {info['class_distribution']}")
    
    return X, y, info


def generate_regression_data(
    n_samples: int = 1000,
    n_features: int = 15,
    noise_level: float = 0.1,
    difficulty: str = 'medium',
    random_state: int = 42
) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
    """
    ç”Ÿæˆå›å½’æ•°æ®é›†
    
    Args:
        n_samples: æ ·æœ¬æ•°é‡
        n_features: ç‰¹å¾æ•°é‡
        noise_level: å™ªå£°æ°´å¹³ (0-1)
        difficulty: æ•°æ®éš¾åº¦ ('easy', 'medium', 'hard')
        random_state: éšæœºç§å­
    
    Returns:
        X, y, info: ç‰¹å¾çŸ©é˜µï¼Œç›®æ ‡å‘é‡ï¼Œæ•°æ®é›†ä¿¡æ¯
    """
    print(f"ğŸ“Š ç”Ÿæˆå›å½’æ•°æ®é›†...")
    
    # æ ¹æ®éš¾åº¦è®¾ç½®å‚æ•°
    if difficulty == 'easy':
        n_informative = int(n_features * 0.9)
        noise = noise_level * 0.5
    elif difficulty == 'medium':
        n_informative = int(n_features * 0.7)
        noise = noise_level
    else:  # hard
        n_informative = int(n_features * 0.5)
        noise = noise_level * 2
    
    X, y = make_regression(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=n_informative,
        noise=noise,
        random_state=random_state
    )
    
    # æ•°æ®é›†ä¿¡æ¯
    info = {
        'task_type': 'regression',
        'n_samples': n_samples,
        'n_features': n_features,
        'noise_level': noise,
        'difficulty': difficulty,
        'target_range': (y.min(), y.max()),
        'target_std': y.std()
    }
    
    print(f"âœ… ç”Ÿæˆå®Œæˆ: {n_samples} æ ·æœ¬, {n_features} ç‰¹å¾")
    print(f"   éš¾åº¦: {difficulty}, å™ªå£°æ°´å¹³: {noise:.3f}")
    print(f"   ç›®æ ‡èŒƒå›´: [{y.min():.2f}, {y.max():.2f}]")
    
    return X, y, info


def load_sample_dataset(dataset_name: str) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
    """
    åŠ è½½ç¤ºä¾‹æ•°æ®é›†
    
    Args:
        dataset_name: æ•°æ®é›†åç§° ('iris', 'wine', 'boston', 'diabetes')
    
    Returns:
        X, y, info: ç‰¹å¾çŸ©é˜µï¼Œæ ‡ç­¾/ç›®æ ‡å‘é‡ï¼Œæ•°æ®é›†ä¿¡æ¯
    """
    print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {dataset_name}")
    
    if dataset_name == 'iris':
        from sklearn.datasets import load_iris
        data = load_iris()
        info = {
            'task_type': 'classification',
            'description': 'é¸¢å°¾èŠ±åˆ†ç±»ï¼šæ ¹æ®èŠ±ç“£å’ŒèŠ±è¼å°ºå¯¸é¢„æµ‹é¸¢å°¾èŠ±å“ç§',
            'features': list(data.feature_names),
            'classes': list(data.target_names)
        }
        
    elif dataset_name == 'wine':
        from sklearn.datasets import load_wine
        data = load_wine()
        info = {
            'task_type': 'classification',
            'description': 'è‘¡è„é…’åˆ†ç±»ï¼šæ ¹æ®åŒ–å­¦æˆåˆ†é¢„æµ‹è‘¡è„é…’ç±»å‹',
            'features': list(data.feature_names),
            'classes': list(data.target_names)
        }
        
    elif dataset_name == 'boston':
        # ä½¿ç”¨åŠ åˆ©ç¦å°¼äºšæˆ¿ä»·æ•°æ®æ›¿ä»£æ³¢å£«é¡¿æˆ¿ä»·
        from sklearn.datasets import fetch_california_housing
        data = fetch_california_housing()
        info = {
            'task_type': 'regression',
            'description': 'åŠ åˆ©ç¦å°¼äºšæˆ¿ä»·é¢„æµ‹ï¼šæ ¹æ®åœ°ç†å’Œæˆ¿å±‹ä¿¡æ¯é¢„æµ‹æˆ¿ä»·',
            'features': list(data.feature_names),
            'target_name': 'house_value'
        }
        
    elif dataset_name == 'diabetes':
        from sklearn.datasets import load_diabetes
        data = load_diabetes()
        info = {
            'task_type': 'regression',
            'description': 'ç³–å°¿ç—…è¿›å±•é¢„æµ‹ï¼šæ ¹æ®åŸºç¡€æŒ‡æ ‡é¢„æµ‹ç–¾ç—…è¿›å±•',
            'features': list(data.feature_names),
            'target_name': 'disease_progression'
        }
        
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset_name}")
    
    print(f"âœ… åŠ è½½å®Œæˆ: {data.data.shape[0]} æ ·æœ¬, {data.data.shape[1]} ç‰¹å¾")
    print(f"   æè¿°: {info['description']}")
    
    return data.data, data.target, info


def explore_data(X, y, info: Dict[str, Any], show_plots: bool = True):
    """
    æ•°æ®æ¢ç´¢å’Œå¯è§†åŒ–
    
    Args:
        X: ç‰¹å¾çŸ©é˜µ
        y: æ ‡ç­¾/ç›®æ ‡å‘é‡
        info: æ•°æ®é›†ä¿¡æ¯
        show_plots: æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨
    """
    print("\nğŸ” æ•°æ®æ¢ç´¢åˆ†æ")
    print("=" * 40)
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print(f"ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
    print(f"   æ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"   ä»»åŠ¡ç±»å‹: {info['task_type']}")
    print(f"   ç¼ºå¤±å€¼: {np.isnan(X).sum()}")
    
    if info['task_type'] == 'classification':
        unique_classes, counts = np.unique(y, return_counts=True)
        print(f"   ç±»åˆ«æ•°é‡: {len(unique_classes)}")
        print(f"   ç±»åˆ«åˆ†å¸ƒ: {dict(zip(unique_classes, counts))}")
        
        if show_plots:
            # ç±»åˆ«åˆ†å¸ƒå›¾
            plt.figure(figsize=(10, 4))
            
            plt.subplot(1, 2, 1)
            plt.bar(range(len(unique_classes)), counts)
            plt.xlabel('ç±»åˆ«')
            plt.ylabel('æ ·æœ¬æ•°é‡')
            plt.title('ç±»åˆ«åˆ†å¸ƒ')
            plt.xticks(range(len(unique_classes)), unique_classes)
            
            # ç‰¹å¾åˆ†å¸ƒï¼ˆé€‰æ‹©å‰å‡ ä¸ªç‰¹å¾ï¼‰
            plt.subplot(1, 2, 2)
            n_features_to_show = min(5, X.shape[1])
            for i in range(n_features_to_show):
                plt.hist(X[:, i], alpha=0.5, label=f'ç‰¹å¾{i+1}')
            plt.xlabel('ç‰¹å¾å€¼')
            plt.ylabel('é¢‘æ¬¡')
            plt.title('ç‰¹å¾åˆ†å¸ƒ')
            plt.legend()
            
            plt.tight_layout()
            plt.show()
    
    else:  # regression
        print(f"   ç›®æ ‡èŒƒå›´: [{y.min():.3f}, {y.max():.3f}]")
        print(f"   ç›®æ ‡å‡å€¼: {y.mean():.3f}")
        print(f"   ç›®æ ‡æ ‡å‡†å·®: {y.std():.3f}")
        
        if show_plots:
            plt.figure(figsize=(12, 4))
            
            # ç›®æ ‡åˆ†å¸ƒ
            plt.subplot(1, 3, 1)
            plt.hist(y, bins=30, alpha=0.7)
            plt.xlabel('ç›®æ ‡å€¼')
            plt.ylabel('é¢‘æ¬¡')
            plt.title('ç›®æ ‡å€¼åˆ†å¸ƒ')
            
            # ç‰¹å¾åˆ†å¸ƒ
            plt.subplot(1, 3, 2)
            n_features_to_show = min(5, X.shape[1])
            for i in range(n_features_to_show):
                plt.hist(X[:, i], alpha=0.5, label=f'ç‰¹å¾{i+1}')
            plt.xlabel('ç‰¹å¾å€¼')
            plt.ylabel('é¢‘æ¬¡')
            plt.title('ç‰¹å¾åˆ†å¸ƒ')
            plt.legend()
            
            # ç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³æ€§ï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªç‰¹å¾ï¼‰
            plt.subplot(1, 3, 3)
            plt.scatter(X[:, 0], y, alpha=0.5)
            plt.xlabel('ç‰¹å¾1')
            plt.ylabel('ç›®æ ‡å€¼')
            plt.title('ç‰¹å¾1 vs ç›®æ ‡å€¼')
            
            plt.tight_layout()
            plt.show()


def prepare_data_for_training(
    X, y, 
    test_size: float = 0.2,
    validation_size: float = 0.2,
    scale_features: bool = True,
    random_state: int = 42
) -> Dict[str, Any]:
    """
    ä¸ºè®­ç»ƒå‡†å¤‡æ•°æ®
    
    Args:
        X: ç‰¹å¾çŸ©é˜µ
        y: æ ‡ç­¾/ç›®æ ‡å‘é‡
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        validation_size: éªŒè¯é›†æ¯”ä¾‹ï¼ˆä»è®­ç»ƒé›†ä¸­åˆ’åˆ†ï¼‰
        scale_features: æ˜¯å¦æ ‡å‡†åŒ–ç‰¹å¾
        random_state: éšæœºç§å­
    
    Returns:
        å‡†å¤‡å¥½çš„æ•°æ®å­—å…¸
    """
    print("ğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state,
        stratify=y if len(np.unique(y)) < 20 else None  # åˆ†ç±»ä»»åŠ¡æ—¶ä½¿ç”¨åˆ†å±‚é‡‡æ ·
    )
    
    # ä»è®­ç»ƒé›†ä¸­åˆ’åˆ†éªŒè¯é›†
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=validation_size, random_state=random_state,
        stratify=y_train if len(np.unique(y_train)) < 20 else None
    )
    
    # ç‰¹å¾æ ‡å‡†åŒ–
    scalers = {}
    if scale_features:
        scaler_X = StandardScaler()
        X_train = scaler_X.fit_transform(X_train)
        X_val = scaler_X.transform(X_val)
        X_test = scaler_X.transform(X_test)
        scalers['X'] = scaler_X
        
        # å¦‚æœæ˜¯å›å½’ä»»åŠ¡ï¼Œä¹Ÿæ ‡å‡†åŒ–ç›®æ ‡å˜é‡
        if len(np.unique(y)) > 20:  # å‡è®¾è¶…è¿‡20ä¸ªä¸åŒå€¼å°±æ˜¯å›å½’
            scaler_y = StandardScaler()
            y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
            y_val = scaler_y.transform(y_val.reshape(-1, 1)).flatten()
            y_test = scaler_y.transform(y_test.reshape(-1, 1)).flatten()
            scalers['y'] = scaler_y
    
    data = {
        'X_train': X_train,
        'X_val': X_val,
        'X_test': X_test,
        'y_train': y_train,
        'y_val': y_val,
        'y_test': y_test,
        'scalers': scalers
    }
    
    print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    print(f"   ç‰¹å¾æ ‡å‡†åŒ–: {'æ˜¯' if scale_features else 'å¦'}")
    
    return data


def visualize_predictions(y_true, y_pred, task_type: str, title: str = "é¢„æµ‹ç»“æœ"):
    """
    å¯è§†åŒ–é¢„æµ‹ç»“æœ
    
    Args:
        y_true: çœŸå®å€¼
        y_pred: é¢„æµ‹å€¼
        task_type: ä»»åŠ¡ç±»å‹ ('classification' æˆ– 'regression')
        title: å›¾è¡¨æ ‡é¢˜
    """
    plt.figure(figsize=(10, 4))
    
    if task_type == 'classification':
        from sklearn.metrics import confusion_matrix, classification_report
        
        # æ··æ·†çŸ©é˜µ
        plt.subplot(1, 2, 1)
        cm = confusion_matrix(y_true, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.xlabel('é¢„æµ‹ç±»åˆ«')
        plt.ylabel('çœŸå®ç±»åˆ«')
        plt.title(f'{title} - æ··æ·†çŸ©é˜µ')
        
        # é¢„æµ‹å‡†ç¡®æ€§
        plt.subplot(1, 2, 2)
        accuracy = (y_true == y_pred).mean()
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡å‡†ç¡®ç‡
        unique_classes = np.unique(y_true)
        class_accuracies = []
        for cls in unique_classes:
            mask = y_true == cls
            if mask.sum() > 0:
                acc = (y_true[mask] == y_pred[mask]).mean()
                class_accuracies.append(acc)
            else:
                class_accuracies.append(0)
        
        plt.bar(range(len(unique_classes)), class_accuracies)
        plt.xlabel('ç±»åˆ«')
        plt.ylabel('å‡†ç¡®ç‡')
        plt.title(f'{title} - å„ç±»åˆ«å‡†ç¡®ç‡')
        plt.xticks(range(len(unique_classes)), unique_classes)
        plt.ylim(0, 1)
        
        # åœ¨æ§åˆ¶å°æ˜¾ç¤ºè¯¦ç»†æŠ¥å‘Š
        print(f"\nğŸ“Š {title} - åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_true, y_pred))
        
    else:  # regression
        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
        
        # é¢„æµ‹ vs çœŸå®å€¼æ•£ç‚¹å›¾
        plt.subplot(1, 2, 1)
        plt.scatter(y_true, y_pred, alpha=0.6)
        
        # ç†æƒ³é¢„æµ‹çº¿
        min_val = min(y_true.min(), y_pred.min())
        max_val = max(y_true.max(), y_pred.max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)
        
        plt.xlabel('çœŸå®å€¼')
        plt.ylabel('é¢„æµ‹å€¼')
        plt.title(f'{title} - é¢„æµ‹ vs çœŸå®')
        
        # æ®‹å·®å›¾
        plt.subplot(1, 2, 2)
        residuals = y_true - y_pred
        plt.scatter(y_pred, residuals, alpha=0.6)
        plt.axhline(y=0, color='r', linestyle='--', alpha=0.8)
        plt.xlabel('é¢„æµ‹å€¼')
        plt.ylabel('æ®‹å·® (çœŸå®å€¼ - é¢„æµ‹å€¼)')
        plt.title(f'{title} - æ®‹å·®åˆ†æ')
        
        # åœ¨æ§åˆ¶å°æ˜¾ç¤ºæŒ‡æ ‡
        r2 = r2_score(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        
        print(f"\nğŸ“Š {title} - å›å½’æŒ‡æ ‡:")
        print(f"   RÂ² åˆ†æ•°: {r2:.4f}")
        print(f"   å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}")
        print(f"   å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")
        print(f"   å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")
    
    plt.tight_layout()
    plt.show()


def save_results(results: Dict[str, Any], filename: str):
    """
    ä¿å­˜å®éªŒç»“æœ
    
    Args:
        results: ç»“æœå­—å…¸
        filename: ä¿å­˜æ–‡ä»¶å
    """
    import json
    
    # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ï¼ˆJSONåºåˆ—åŒ–ï¼‰
    def convert_numpy(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.number):
            return obj.item()
        elif isinstance(obj, dict):
            return {k: convert_numpy(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy(v) for v in obj]
        else:
            return obj
    
    results_json = convert_numpy(results)
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results_json, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")


def create_quick_demo():
    """
    åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„å¿«é€Ÿæ¼”ç¤º
    """
    print("ğŸš€ å¿«é€Ÿæ¼”ç¤ºï¼šCausalQwen çš„å¨åŠ›")
    print("=" * 50)
    
    # ç”Ÿæˆæ•°æ®
    X, y, info = generate_classification_data(
        n_samples=500, 
        n_features=10, 
        difficulty='medium'
    )
    
    # æ¢ç´¢æ•°æ®
    explore_data(X, y, info, show_plots=False)
    
    # å‡†å¤‡æ•°æ®
    data = prepare_data_for_training(X, y)
    
    # ä¸sklearnå¯¹æ¯”
    try:
        from simple_models import compare_with_sklearn
        results = compare_with_sklearn(X, y, task_type='classification')
    except ImportError:
        print("âš ï¸ æ¨¡å‹å¯¹æ¯”åŠŸèƒ½éœ€è¦ simple_models æ¨¡å—")
        results = {}
    
    print("\nğŸ‰ å¿«é€Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("è¿™å°±æ˜¯ CausalQwen çš„å¼ºå¤§ä¹‹å¤„ - ç®€å•æ˜“ç”¨ï¼Œæ•ˆæœå‡ºè‰²ï¼")
    
    return results


if __name__ == "__main__":
    # è¿è¡Œå¿«é€Ÿæ¼”ç¤º
    create_quick_demo()