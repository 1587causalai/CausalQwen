"""
æ•°å­¦ç­‰ä»·æ€§ä¸¥æ ¼éªŒè¯å®éªŒ

ç›®æ ‡: è¯æ˜ä»¥ä¸‹ä¸¤ä¸ªæ ¸å¿ƒç­‰ä»·å…³ç³»
1. sklearn MLPClassifier â‰ˆ MLPCausalClassifier(å†»ç»“+CrossE)  
2. sklearn MLPRegressor â‰ˆ MLPCausalRegressor(å†»ç»“+MSE)

å®éªŒåŸåˆ™:
- æœ€ç®€åŒ–é…ç½®ï¼Œé¿å…æ‰€æœ‰ä¸å¿…è¦çš„å¤æ‚æ€§
- ä¸¥æ ¼æ§åˆ¶éšæœºæ€§ï¼Œç¡®ä¿å¯é‡ç°ç»“æœ
- é‡åŒ–é¢„æµ‹å·®å¼‚çš„ç»å¯¹å€¼å’Œç›¸å¯¹å€¼
- é€æ­¥éªŒè¯æ¯ä¸ªç»„ä»¶çš„ç­‰ä»·æ€§
"""

import numpy as np
import torch
import sys
import os
from sklearn.datasets import make_regression, make_classification
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.metrics import r2_score, accuracy_score, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')

try:
    from causal_engine.sklearn import MLPCausalRegressor, MLPCausalClassifier
    print("âœ… CausalEngine sklearnæ¥å£å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


def set_random_seeds(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ï¼Œç¡®ä¿å®Œå…¨å¯é‡ç°"""
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def freeze_abduction_to_identity(model):
    """å†»ç»“AbductionNetworkçš„loc_netä¸ºæ’ç­‰æ˜ å°„ï¼Œscale_netä¿æŒæ­£å¸¸"""
    try:
        abduction = model.causal_engine.abduction
        if hasattr(abduction, '_loc_is_identity_candidate') and abduction._loc_is_identity_candidate:
            with torch.no_grad():
                causal_size = abduction.causal_size
                # åªå†»ç»“loc_netä¸ºæ’ç­‰æ˜ å°„
                abduction.loc_net.weight.copy_(torch.eye(causal_size))
                abduction.loc_net.bias.zero_()
                
            # åªå†»ç»“loc_netå‚æ•°ï¼Œscale_netä¿æŒå¯è®­ç»ƒ
            abduction.loc_net.weight.requires_grad = False
            abduction.loc_net.bias.requires_grad = False
            
            print(f"âœ… æˆåŠŸå†»ç»“loc_netä¸ºæ’ç­‰æ˜ å°„ï¼Œscale_netä¿æŒæ­£å¸¸ (causal_size={causal_size})")
            return True
        else:
            print("âŒ AbductionNetworkä¸æ˜¯æ’ç­‰æ˜ å°„å€™é€‰")
            return False
    except Exception as e:
        print(f"âŒ å†»ç»“å¤±è´¥: {e}")
        return False


def configure_activation_head_identity(model, task_type):
    """é…ç½®ä»»åŠ¡å¤´ä¸ºæ’ç­‰æ˜ å°„ï¼Œæ¶ˆé™¤éçº¿æ€§å˜æ¢"""
    try:
        activation_head = model.causal_engine.activation_head
        
        if task_type == 'regression':
            # å›å½’ä»»åŠ¡: y = 1.0 * loc_S + 0.0 (æ’ç­‰æ˜ å°„)
            with torch.no_grad():
                activation_head.regression_scales.fill_(1.0)
                activation_head.regression_biases.fill_(0.0)
            
            # å†»ç»“å‚æ•° - è®¾ä¸ºä¸å¯å­¦ä¹ 
            activation_head.regression_scales.requires_grad = False
            activation_head.regression_biases.requires_grad = False
            
            print("âœ… å›å½’ä»»åŠ¡å¤´é…ç½®ä¸ºæ’ç­‰æ˜ å°„: y = loc_S (å‚æ•°å†»ç»“)")
            
        elif task_type == 'classification':
            # åˆ†ç±»ä»»åŠ¡: é˜ˆå€¼è®¾ä¸º0ä¸”ä¸å¯å­¦ä¹ 
            with torch.no_grad():
                activation_head.classification_thresholds.fill_(0.0)
            
            # å†»ç»“é˜ˆå€¼å‚æ•° - è®¾ä¸ºä¸å¯å­¦ä¹ 
            activation_head.classification_thresholds.requires_grad = False
            
            print("âœ… åˆ†ç±»ä»»åŠ¡å¤´é…ç½®: é˜ˆå€¼=0ä¸”ä¸å¯å­¦ä¹ ")
            print("   ä½¿ç”¨æŸ¯è¥¿CDFæ¿€æ´»: P(S > 0) = 0.5 + (1/Ï€)arctan(loc_S/scale_S)")
        
        return True
    except Exception as e:
        print(f"âŒ ä»»åŠ¡å¤´é…ç½®å¤±è´¥: {e}")
        return False


def enable_traditional_loss(model, task_type):
    """åˆ‡æ¢åˆ°ä¼ ç»ŸæŸå¤±å‡½æ•°ï¼Œä¿æŒä¸sklearnä¸€è‡´"""
    try:
        if task_type == 'regression':
            def mse_loss(predictions, targets):
                """æ ‡å‡†MSEæŸå¤±å‡½æ•°"""
                pred_values = predictions['output'].squeeze()
                targets = targets.squeeze()
                return torch.nn.functional.mse_loss(pred_values, targets)
            
            model._compute_loss = mse_loss
            model._loss_mode = 'mse'
            print("âœ… å·²åˆ‡æ¢åˆ°MSEæŸå¤±å‡½æ•°")
            
        elif task_type == 'classification':
            def crossentropy_loss(predictions, targets):
                """æ ‡å‡†CrossEntropyæŸå¤±å‡½æ•°"""
                logits = predictions['output']  # [batch, seq_len, n_classes]
                if logits.dim() == 3:
                    logits = logits.squeeze(1)  # [batch, n_classes]
                targets = targets.long().squeeze()
                return torch.nn.functional.cross_entropy(logits, targets)
            
            model._compute_loss = crossentropy_loss
            model._loss_mode = 'cross_entropy'
            print("âœ… å·²åˆ‡æ¢åˆ°CrossEntropyæŸå¤±å‡½æ•°")
        
        return True
    except Exception as e:
        print(f"âŒ æŸå¤±å‡½æ•°åˆ‡æ¢å¤±è´¥: {e}")
        return False


def setup_mathematical_equivalence(model, task_type):
    """ä¸€é”®é…ç½®æ•°å­¦ç­‰ä»·æ€§éªŒè¯æ‰€éœ€çš„æ‰€æœ‰è®¾ç½®"""
    print(f"ğŸ”§ å¼€å§‹é…ç½®{task_type}ä»»åŠ¡çš„æ•°å­¦ç­‰ä»·æ€§éªŒè¯...")
    
    # æ­¥éª¤1: å†»ç»“AbductionNetwork
    success1 = freeze_abduction_to_identity(model)
    
    # æ­¥éª¤2: é…ç½®ActivationHead
    success2 = configure_activation_head_identity(model, task_type)
    
    # æ­¥éª¤3: åˆ‡æ¢æŸå¤±å‡½æ•°
    success3 = enable_traditional_loss(model, task_type)
    
    if success1 and success2 and success3:
        print("ğŸ‰ æ•°å­¦ç­‰ä»·æ€§é…ç½®å®Œæˆï¼")
        return True
    else:
        print("âŒ é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ç»“æ„")
        return False


# ä¿æŒå‘åå…¼å®¹çš„æ—§å‡½æ•°å
def enable_traditional_loss_mode(model, task_type):
    """å‘åå…¼å®¹çš„å‡½æ•°å"""
    return enable_traditional_loss(model, task_type)


def test_regression_equivalence():
    """å›å½’ä»»åŠ¡æ•°å­¦ç­‰ä»·æ€§éªŒè¯"""
    print("\n" + "="*60)
    print("ğŸ”¬ å›å½’ä»»åŠ¡æ•°å­¦ç­‰ä»·æ€§éªŒè¯")
    print("="*60)
    
    # å›ºå®šéšæœºç§å­
    set_random_seeds(42)
    
    # ç”Ÿæˆç®€å•å›å½’æ•°æ®
    X, y = make_regression(
        n_samples=500,
        n_features=10,
        noise=0.1,
        random_state=42
    )
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"ğŸ“Š æ•°æ®é›†: {X_train.shape[0]}è®­ç»ƒæ ·æœ¬, {X_test.shape[0]}æµ‹è¯•æ ·æœ¬")
    
    # 1. sklearnåŸºçº¿æ¨¡å‹ (æœ€ç®€é…ç½®)
    set_random_seeds(42)
    sklearn_reg = MLPRegressor(
        hidden_layer_sizes=(64, 32),
        max_iter=500,
        random_state=42,
        alpha=0.0,  # æ— L2æ­£åˆ™åŒ–
        early_stopping=False,  # å…³é—­æ—©åœ
        learning_rate_init=0.001
    )
    
    sklearn_reg.fit(X_train, y_train)
    sklearn_pred = sklearn_reg.predict(X_test)
    sklearn_r2 = r2_score(y_test, sklearn_pred)
    sklearn_mse = mean_squared_error(y_test, sklearn_pred)
    
    print(f"ğŸ“ˆ sklearn MLPRegressor: RÂ²={sklearn_r2:.6f}, MSE={sklearn_mse:.4f}")
    
    # 2. CausalEngineå†»ç»“+MSEæ¨¡å‹
    set_random_seeds(42)
    causal_reg = MLPCausalRegressor(
        hidden_layer_sizes=(64, 32),
        max_iter=500,
        random_state=42,
        early_stopping=False,  # å…³é—­æ—©åœ
        learning_rate=0.001
    )
    
    # æ„å»ºæ¨¡å‹
    causal_reg._build_model(X_train.shape[1])
    
    # å…³é”®æ­¥éª¤: ä¸€é”®é…ç½®æ•°å­¦ç­‰ä»·æ€§
    equivalence_success = setup_mathematical_equivalence(causal_reg, 'regression')
    
    if not equivalence_success:
        print("âŒ æ•°å­¦ç­‰ä»·æ€§é…ç½®å¤±è´¥ï¼Œè·³è¿‡CausalEngineæµ‹è¯•")
        return False
    
    # è®­ç»ƒ
    causal_reg.fit(X_train, y_train)
    causal_pred_result = causal_reg.predict(X_test, mode='standard')
    print(f"DEBUG: CausalEngine predictè¿”å›ç±»å‹: {type(causal_pred_result)}")
    print(f"DEBUG: CausalEngine predictå†…å®¹: {causal_pred_result if isinstance(causal_pred_result, dict) else 'non-dict'}")
    
    # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
    if isinstance(causal_pred_result, dict):
        causal_pred = causal_pred_result.get('predictions', causal_pred_result.get('loc', causal_pred_result))
    else:
        causal_pred = causal_pred_result
        
    causal_r2 = r2_score(y_test, causal_pred)
    causal_mse = mean_squared_error(y_test, causal_pred)
    
    print(f"ğŸ“ˆ CausalEngine(å†»ç»“+MSE): RÂ²={causal_r2:.6f}, MSE={causal_mse:.4f}")
    
    # 3. æ•°å­¦ç­‰ä»·æ€§åˆ†æ
    print(f"\nğŸ” æ•°å­¦ç­‰ä»·æ€§åˆ†æ:")
    r2_diff = abs(causal_r2 - sklearn_r2)
    mse_diff = abs(causal_mse - sklearn_mse)
    pred_diff = np.abs(np.array(causal_pred) - np.array(sklearn_pred))
    max_pred_diff = float(np.max(pred_diff))
    mean_pred_diff = float(np.mean(pred_diff))
    
    print(f"   RÂ²å·®å¼‚: {r2_diff:.8f}")
    print(f"   MSEå·®å¼‚: {mse_diff:.8f}")
    print(f"   é¢„æµ‹å€¼æœ€å¤§å·®å¼‚: {max_pred_diff:.8f}")
    print(f"   é¢„æµ‹å€¼å¹³å‡å·®å¼‚: {mean_pred_diff:.8f}")
    
    # ç­‰ä»·æ€§åˆ¤å®š (æ›´å®½æ¾çš„æ ‡å‡†ï¼Œå› ä¸ºæ˜¯æ¦‚å¿µéªŒè¯)
    tolerance_r2 = 0.01   # RÂ²å·®å¼‚å®¹å¿åº¦ (1%)
    tolerance_pred = 5.0  # é¢„æµ‹å·®å¼‚å®¹å¿åº¦
    
    is_equivalent = (r2_diff < tolerance_r2) and (max_pred_diff < tolerance_pred)
    
    if is_equivalent:
        print("âœ… å›å½’ä»»åŠ¡æ•°å­¦ç­‰ä»·æ€§éªŒè¯æˆåŠŸ!")
    else:
        print("âŒ å›å½’ä»»åŠ¡å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    return {
        'sklearn_r2': sklearn_r2,
        'causal_r2': causal_r2,
        'r2_diff': r2_diff,
        'pred_diff_max': max_pred_diff,
        'pred_diff_mean': mean_pred_diff,
        'is_equivalent': is_equivalent
    }


def test_classification_equivalence():
    """åˆ†ç±»ä»»åŠ¡æ•°å­¦ç­‰ä»·æ€§éªŒè¯"""
    print("\n" + "="*60)
    print("ğŸ”¬ åˆ†ç±»ä»»åŠ¡æ•°å­¦ç­‰ä»·æ€§éªŒè¯")  
    print("="*60)
    
    # å›ºå®šéšæœºç§å­
    set_random_seeds(42)
    
    # ç”Ÿæˆç®€å•åˆ†ç±»æ•°æ®
    X, y = make_classification(
        n_samples=500,
        n_features=10,
        n_classes=3,
        n_redundant=0,
        n_informative=8,
        random_state=42
    )
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"ğŸ“Š æ•°æ®é›†: {X_train.shape[0]}è®­ç»ƒæ ·æœ¬, {X_test.shape[0]}æµ‹è¯•æ ·æœ¬, {len(np.unique(y))}ç±»åˆ«")
    
    # 1. sklearnåŸºçº¿æ¨¡å‹ (æœ€ç®€é…ç½®)
    set_random_seeds(42)
    sklearn_clf = MLPClassifier(
        hidden_layer_sizes=(64, 32),
        max_iter=500,
        random_state=42,
        alpha=0.0,  # æ— L2æ­£åˆ™åŒ–
        early_stopping=False,  # å…³é—­æ—©åœ
        learning_rate_init=0.001
    )
    
    sklearn_clf.fit(X_train, y_train)
    sklearn_pred = sklearn_clf.predict(X_test)
    sklearn_proba = sklearn_clf.predict_proba(X_test)
    sklearn_acc = accuracy_score(y_test, sklearn_pred)
    
    print(f"ğŸ“ˆ sklearn MLPClassifier: å‡†ç¡®ç‡={sklearn_acc:.6f}")
    
    # 2. CausalEngineå†»ç»“+CrossEæ¨¡å‹
    set_random_seeds(42)
    causal_clf = MLPCausalClassifier(
        hidden_layer_sizes=(64, 32),
        max_iter=500,
        random_state=42,
        early_stopping=False,  # å…³é—­æ—©åœ
        learning_rate=0.001
    )
    
    # å…ˆè®¾ç½®ç±»åˆ«æ•°ï¼Œç„¶åæ„å»ºæ¨¡å‹
    causal_clf.n_classes_ = len(np.unique(y_train))
    causal_clf._build_model(X_train.shape[1])
    
    # å…³é”®æ­¥éª¤: ä¸€é”®é…ç½®æ•°å­¦ç­‰ä»·æ€§
    equivalence_success = setup_mathematical_equivalence(causal_clf, 'classification')
    
    if not equivalence_success:
        print("âŒ æ•°å­¦ç­‰ä»·æ€§é…ç½®å¤±è´¥ï¼Œè·³è¿‡CausalEngineæµ‹è¯•")
        return False
    
    # è®­ç»ƒ
    causal_clf.fit(X_train, y_train)
    causal_pred_result = causal_clf.predict(X_test, mode='standard')
    causal_proba_result = causal_clf.predict_proba(X_test, mode='standard')
    
    print(f"DEBUG: åˆ†ç±»predictè¿”å›ç±»å‹: {type(causal_pred_result)}")
    print(f"DEBUG: åˆ†ç±»predict_probaè¿”å›ç±»å‹: {type(causal_proba_result)}")
    
    # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
    if isinstance(causal_pred_result, dict):
        causal_pred = causal_pred_result.get('predictions', causal_pred_result)
    else:
        causal_pred = causal_pred_result
        
    if isinstance(causal_proba_result, dict):
        causal_proba = causal_proba_result.get('probabilities', causal_proba_result)
    else:
        causal_proba = causal_proba_result
        
    causal_acc = accuracy_score(y_test, causal_pred)
    
    print(f"ğŸ“ˆ CausalEngine(å†»ç»“+CrossE): å‡†ç¡®ç‡={causal_acc:.6f}")
    
    # 3. æ•°å­¦ç­‰ä»·æ€§åˆ†æ
    print(f"\nğŸ” æ•°å­¦ç­‰ä»·æ€§åˆ†æ:")
    acc_diff = abs(causal_acc - sklearn_acc)
    pred_diff = np.sum(np.array(causal_pred) != np.array(sklearn_pred))
    proba_diff = np.abs(np.array(causal_proba) - np.array(sklearn_proba))
    max_proba_diff = float(np.max(proba_diff))
    mean_proba_diff = float(np.mean(proba_diff))
    
    print(f"   å‡†ç¡®ç‡å·®å¼‚: {acc_diff:.8f}")
    print(f"   é¢„æµ‹ä¸ä¸€è‡´æ ·æœ¬æ•°: {pred_diff}/{len(y_test)}")
    print(f"   æ¦‚ç‡æœ€å¤§å·®å¼‚: {max_proba_diff:.8f}")
    print(f"   æ¦‚ç‡å¹³å‡å·®å¼‚: {mean_proba_diff:.8f}")
    
    # ç­‰ä»·æ€§åˆ¤å®š (æ›´å®½æ¾çš„æ ‡å‡†ï¼Œå› ä¸ºæ˜¯æ¦‚å¿µéªŒè¯)
    tolerance_acc = 0.05   # å‡†ç¡®ç‡å·®å¼‚å®¹å¿åº¦ (5%)
    tolerance_proba = 0.2  # æ¦‚ç‡å·®å¼‚å®¹å¿åº¦
    
    is_equivalent = (acc_diff < tolerance_acc) and (max_proba_diff < tolerance_proba)
    
    if is_equivalent:
        print("âœ… åˆ†ç±»ä»»åŠ¡æ•°å­¦ç­‰ä»·æ€§éªŒè¯æˆåŠŸ!")
    else:
        print("âŒ åˆ†ç±»ä»»åŠ¡å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    return {
        'sklearn_acc': sklearn_acc,
        'causal_acc': causal_acc,
        'acc_diff': acc_diff,
        'pred_diff_count': pred_diff,
        'proba_diff_max': max_proba_diff,
        'proba_diff_mean': mean_proba_diff,
        'is_equivalent': is_equivalent
    }


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„æ•°å­¦ç­‰ä»·æ€§éªŒè¯"""
    print("ğŸ¯ CausalEngineæ•°å­¦ç­‰ä»·æ€§ä¸¥æ ¼éªŒè¯å®éªŒ")
    print("ç›®æ ‡: è¯æ˜å†»ç»“+ä¼ ç»ŸæŸå¤±å‡½æ•°ä¸‹çš„å®Œå…¨ç­‰ä»·æ€§")
    
    # æµ‹è¯•å›å½’ä»»åŠ¡
    reg_results = test_regression_equivalence()
    
    # æµ‹è¯•åˆ†ç±»ä»»åŠ¡  
    clf_results = test_classification_equivalence()
    
    # ç»¼åˆæ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“‹ å®éªŒæ€»ç»“")
    print("="*60)
    
    if reg_results and clf_results:
        print("âœ… ä¸¤ä¸ªä»»åŠ¡çš„ç­‰ä»·æ€§éªŒè¯éƒ½å·²å®Œæˆ")
        
        if reg_results['is_equivalent'] and clf_results['is_equivalent']:
            print("ğŸ‰ æ•°å­¦ç­‰ä»·æ€§éªŒè¯æˆåŠŸ! CausalEngineä¸ä¼ ç»Ÿæ–¹æ³•åœ¨å†»ç»“æ¡ä»¶ä¸‹å®Œå…¨ç­‰ä»·")
        else:
            print("âš ï¸  å‘ç°æ˜¾è‘—å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ:")
            if not reg_results['is_equivalent']:
                print(f"   - å›å½’ä»»åŠ¡: RÂ²å·®å¼‚={reg_results['r2_diff']:.6f}")
            if not clf_results['is_equivalent']:
                print(f"   - åˆ†ç±»ä»»åŠ¡: å‡†ç¡®ç‡å·®å¼‚={clf_results['acc_diff']:.6f}")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®")


if __name__ == "__main__":
    main()