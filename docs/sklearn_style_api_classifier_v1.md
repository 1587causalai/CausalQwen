# MLPCausalClassifier Sklearn-Style API è®¾è®¡æ–¹æ¡ˆ V1

> **ç›®æ ‡**: ä¸“æ³¨åˆ†ç±»ä»»åŠ¡ï¼ŒåŸºäºCausalEngineçš„è¯å…ƒæ¿€æ´»æœºåˆ¶ï¼Œå®ç°ç±»ä¼¼sklearn MLPClassifieré‚£æ ·æ˜“ç”¨çš„åˆ†ç±»å™¨ï¼Œæä¾›å®Œæ•´çš„å¤šåˆ†ç±»é¢„æµ‹èƒ½åŠ›ã€‚

## 1. åˆ†ç±»ä»»åŠ¡çš„ç‹¬ç‰¹æŒ‘æˆ˜

### 1.1 ä¸å›å½’ä»»åŠ¡çš„æ ¹æœ¬å·®å¼‚

| ç‰¹æ€§ | MLPCausalRegressor | MLPCausalClassifier |
|------|-------------------|-------------------|
| **è¾“å‡ºæ€§è´¨** | è¿ç»­æ•°å€¼ | ç¦»æ•£ç±»åˆ« |
| **æ¿€æ´»å‡½æ•°** | æ’ç­‰æ¿€æ´» `Y = S` | è¯å…ƒæ¿€æ´» `f_k(s_k) = I(s_k > C_k)` |
| **æŸå¤±å‡½æ•°** | Cauchy NLLæŸå¤± | äºŒå…ƒäº¤å‰ç†µæŸå¤± |
| **å†³ç­–æœºåˆ¶** | åˆ†å¸ƒä¸­å¿ƒå€¼ | OvR (One-vs-Rest) ç­–ç•¥ |
| **è¾“å‡ºåˆ†å¸ƒ** | `Cauchy(Î¼, Î³)` | ç‹¬ç«‹æ¿€æ´»æ¦‚ç‡ `P_k` |

### 1.2 CausalEngineåˆ†ç±»çš„æ•°å­¦åŸç†

#### è¯å…ƒæ¿€æ´»å‡½æ•°
å¯¹äºå†³ç­–å¾—åˆ†å‘é‡ $\mathbf{S} = [S_1, S_2, \ldots, S_K]^T \in \mathbb{R}^K$ï¼Œå®šä¹‰ç¬¬Kä¸ªç±»åˆ«çš„æ¿€æ´»å‡½æ•°ä¸ºï¼š

**V1.0 ç®€åŒ–è®¾è®¡**ï¼š
$$f_k(S_k) = \mathbb{I}(S_k > 0)$$
å…¶ä¸­ $\mathbb{I}(\cdot)$ æ˜¯æŒ‡ç¤ºå‡½æ•°ï¼Œæ¿€æ´»é˜ˆå€¼å›ºå®šä¸º 0ã€‚

**V2.0+ æ‰©å±•**ï¼š
$$f_k(S_k) = \mathbb{I}(S_k > C_k)$$
å…¶ä¸­ $C_k \in \mathbb{R}$ æ˜¯ç¬¬$k$ä¸ªç±»åˆ«çš„å¯å­¦ä¹ é˜ˆå€¼å‚æ•°ã€‚

#### æ¿€æ´»æ¦‚ç‡è®¡ç®—
ç”±äº $S_k \sim \text{Cauchy}(\text{loc}_{S_k}, \text{scale}_{S_k})$ï¼Œåˆ©ç”¨Cauchyåˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼š

**V1.0 é˜ˆå€¼ä¸º0çš„æƒ…å†µ**ï¼š
$$P_k = P(S_k > 0) = \int_{0}^{\infty} \frac{1}{\pi \text{scale}_{S_k}} \cdot \frac{1}{1 + \left(\frac{s - \text{loc}_{S_k}}{\text{scale}_{S_k}}\right)^2} ds$$

è§£æç»“æœä¸ºï¼š
$$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k}}{\text{scale}_{S_k}}\right)$$

**V2.0+ å¯å­¦ä¹ é˜ˆå€¼**ï¼š
$$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k} - C_k}{\text{scale}_{S_k}}\right)$$

#### OvRå†³ç­–ç­–ç•¥
å„ç±»åˆ«ç‹¬ç«‹åˆ¤æ–­ï¼Œæœ€ç»ˆé¢„æµ‹ï¼š
$$\hat{y} = \arg\max_{k \in \{1,2,\ldots,K\}} P_k$$

## 2. CausalEngineåˆ†ç±»å·¥ä½œæµç¨‹å›¾

### 2.1 æ ¸å¿ƒç®—æ³•æµç¨‹

```mermaid
graph LR
    %% è¾“å…¥æ•°æ®
    Input["ğŸ“Š è¾“å…¥æ•°æ®<br/>X, y"]
    
    %% è®­ç»ƒé˜¶æ®µ - æ°´å¹³å¸ƒå±€
    subgraph Training ["ğŸ”§ è®­ç»ƒé˜¶æ®µ (.fitæ–¹æ³•)"]
        direction LR
        Stage1["ğŸ” å½’å› æ¨æ–­<br/>Abduction<br/>E â†’ U"]
        Stage2["âš¡ è¡ŒåŠ¨å†³ç­–<br/>Action<br/>U â†’ S[K]"]
        Stage3["ğŸ¯ è¯å…ƒæ¿€æ´»<br/>Token Activation<br/>S â†’ P[K]"]
        Loss["ğŸ“‰ OvRæŸå¤±<br/>BCE Loss"]
        
        Stage1 --> Stage2 --> Stage3 --> Loss
    end
    
    %% é¢„æµ‹é˜¶æ®µ - åˆ†å±‚å¸ƒå±€
    subgraph Prediction ["ğŸ”® é¢„æµ‹é˜¶æ®µ"]
        direction TB
        
        %% predictæ–¹æ³•
        subgraph PredictMethod ["predict() æ–¹æ³•"]
            direction LR
            Compatible_pred["ğŸ”„ Compatible<br/>argmax(Pâ‚–)"]
            Standard_pred["ğŸ“Š Standard<br/>{P, S}"]  
            Causal_pred["âš–ï¸ Causal<br/>çº¯å› æœ"]
            Sampling_pred["ğŸ² Sampling<br/>æ¢ç´¢æ€§"]
        end
        
        %% predict_probaæ–¹æ³•
        subgraph ProbaMethod ["predict_proba() æ–¹æ³•"]
            direction LR
            Compatible_proba["ğŸ”„ Softmax<br/>å½’ä¸€åŒ–"]
            OvR_proba["ğŸ“Š OvR<br/>ç‹¬ç«‹æ¦‚ç‡"]
        end
        
        PredictMethod ~~~ ProbaMethod
    end
    
    %% OvRç­–ç•¥æ ¸å¿ƒ - å³ä¾§ç‹¬ç«‹æ˜¾ç¤º
    subgraph OvRCore ["ğŸ¯ OvRæ ¸å¿ƒç­–ç•¥"]
        direction TB
        OvRFormula["Pâ‚– = Â½ + (1/Ï€)Â·arctan(Î¼â‚›â‚–/Î³â‚›â‚–)"]
        OvRDecision["Å· = argmax(Pâ‚–)"]
        OvRFormula --> OvRDecision
    end
    
    %% æ•°æ®æµ
    Input --> Training
    Training --> Prediction
    Prediction --> OvRCore
    
    %% æ ·å¼ä¼˜åŒ–
    style Input fill:#e8f5e9,stroke:#2e7d32,stroke-width:3px
    style Training fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    style Prediction fill:#e1f5fe,stroke:#0277bd,stroke-width:3px
    style OvRCore fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    
    style Stage1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Stage2 fill:#fff8e1,stroke:#ffa000,stroke-width:2px  
    style Stage3 fill:#e0f2f1,stroke:#00796b,stroke-width:2px
    style Loss fill:#ffebee,stroke:#d32f2f,stroke-width:2px
    
    style Compatible_pred fill:#e3f2fd,stroke:#1976d2
    style Standard_pred fill:#e8f5e9,stroke:#388e3c
    style Causal_pred fill:#fce4ec,stroke:#c2185b
    style Sampling_pred fill:#f3e5f5,stroke:#7b1fa2
    
    style Compatible_proba fill:#fff3e0,stroke:#f57c00
    style OvR_proba fill:#e0f7fa,stroke:#00acc1
```

### 2.2 æ•°å­¦å…¬å¼æ€»è§ˆ

**é˜¶æ®µ1 - å½’å› æ¨æ–­**ï¼š
$$\mu_U = \text{loc\_net}(E), \quad \gamma_U = \text{softplus}(\text{scale\_net}(E))$$
$$U \sim \text{Cauchy}(\mu_U, \gamma_U)$$

**é˜¶æ®µ2 - è¡ŒåŠ¨å†³ç­–**ï¼š
$$\mathbf{S} = [S_1, S_2, \ldots, S_K]^T, \quad S_k \sim \text{Cauchy}(\mu_{S_k}, \gamma_{S_k})$$

**é˜¶æ®µ3 - è¯å…ƒæ¿€æ´»**ï¼š
$$P_k = P(S_k > 0) = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\mu_{S_k}}{\gamma_{S_k}}\right)$$

**OvRæŸå¤±å‡½æ•°**ï¼š
$$\mathcal{L} = -\sum_{k=1}^K [y_k \log(P_k) + (1-y_k) \log(1-P_k)]$$

**æœ€ç»ˆåˆ†ç±»å†³ç­–**ï¼š
$$\hat{y} = \arg\max_{k \in \{1,2,\ldots,K\}} P_k$$

## 3. sklearn MLPClassifier å¯¹æ ‡åˆ†æ

### 3.1 sklearnåˆ†ç±»å™¨çš„æˆåŠŸæ¨¡å¼
```python
# sklearnç»å…¸ç”¨æ³•
from sklearn.neural_network import MLPClassifier

clf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)
clf.fit(X_train, y_train)
predictions = clf.predict(X_test)           # ç±»åˆ«é¢„æµ‹
probabilities = clf.predict_proba(X_test)   # æ¦‚ç‡é¢„æµ‹
```

### 2.2 CausalEngineåˆ†ç±»å™¨çš„è®¾è®¡ç›®æ ‡
```python
# ç›®æ ‡APIè®¾è®¡
from causal_engine.sklearn import MLPCausalClassifier

clf = MLPCausalClassifier(hidden_layer_sizes=(100, 50))
clf.fit(X_train, y_train)
predictions = clf.predict(X_test)                    # ç±»åˆ«é¢„æµ‹
probabilities = clf.predict_proba(X_test)            # æ¦‚ç‡é¢„æµ‹
distributions = clf.predict(X_test, mode='standard') # ç‹¬ç‰¹ï¼šåˆ†å¸ƒé¢„æµ‹
```

## 3. MLPCausalClassifieræ ¸å¿ƒè®¾è®¡ï¼šsklearné£æ ¼ + CausalEngineä¼˜åŠ¿

### 3.1 å®ç°ç­–ç•¥ï¼šå°†CausalEngineé›†æˆä¸ºåˆ†ç±»å™¨è¾“å‡ºå±‚

**æ ¸å¿ƒç†å¿µ**ï¼šä¿æŒsklearnçš„æ˜“ç”¨æ€§ï¼ŒåŒæ—¶å¼•å…¥CausalEngineçš„è¯å…ƒæ¿€æ´»æœºåˆ¶å’ŒOvRç­–ç•¥

```python
# æ ‡å‡†sklearnæ¶æ„ + CausalEngineåˆ†ç±»è¾“å‡ºå±‚
class MLPCausalClassifier:
    def __init__(self):
        # 1. æ ‡å‡†MLPéšè—å±‚ï¼ˆä¸sklearnç›¸åŒï¼‰
        self.hidden_layers = MLPLayers(hidden_layer_sizes)
        
        # 2. CausalEngineåˆ†ç±»è¾“å‡ºå±‚ï¼ˆæ›¿ä»£softmaxå±‚ï¼‰
        self.causal_engine = CausalEngine(
            abduction_net=AbductionNetwork(),     # è¯æ®â†’ä¸ªä½“å› æœè¡¨å¾
            action_net=ActionNetwork(),           # ä¸ªä½“â†’å¤šç±»å†³ç­–å¾—åˆ†
            activation_head=TokenActivationHead() # å¾—åˆ†â†’OvRæ¿€æ´»æ¦‚ç‡
        )
    
    def forward(self, X):
        # å‰å‘ä¼ æ’­ï¼šéšè—å±‚ç‰¹å¾ â†’ CausalEngineä¸‰é˜¶æ®µ â†’ ç±»åˆ«æ¦‚ç‡
        hidden_features = self.hidden_layers(X)
        class_probabilities = self.causal_engine(hidden_features)
        return class_probabilities
```

**æ¶æ„å¯¹æ¯”ä¸æ•°å­¦åˆ›æ–°**ï¼š

| ç»„ä»¶ | MLPClassifier | MLPCausalClassifier |
|------|--------------|-------------------|
| **è¾“å…¥å±‚** | X âˆˆ â„â¿Ë£áµˆ | X âˆˆ â„â¿Ë£áµˆ (ç›¸åŒ) |
| **éšè—å±‚** | h = Ïƒ(Wx + b) | h = Ïƒ(Wx + b) (ç›¸åŒ) |
| **è¾“å‡ºå±‚** | Softmax: P_k = exp(z_k)/Î£_j exp(z_j) | OvR: P_k = Â½ + (1/Ï€)arctan(Î¼_k/Î³_k) |
| **æŸå¤±å‡½æ•°** | Cross Entropy | Binary Cross Entropy (OvR) |
| **å†³ç­–ç­–ç•¥** | ç«äº‰æ€§å½’ä¸€åŒ– | ç‹¬ç«‹æ€§åˆ¤æ–­ + argmax |

**æ•°å­¦åˆ›æ–°çš„å®ç”¨ä»·å€¼**ï¼š
$$\text{ä¼ ç»ŸSoftmax}: \quad P_k = \frac{\exp(z_k)}{\sum_{j=1}^K \exp(z_j)} \quad \text{(å¼ºåˆ¶å½’ä¸€åŒ–çº¦æŸ)}$$
$$\text{CausalEngine OvR}: \quad P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\mu_{S_k}}{\gamma_{S_k}}\right) \quad \text{(ç‹¬ç«‹æ¿€æ´»åˆ¤æ–­)}$$

è¿™ç§è®¾è®¡çš„ä¼˜åŠ¿ï¼šç±»åˆ«é—´ç‹¬ç«‹æ€§ä½¿å¾—æ¨¡å‹å¯¹æ ‡ç­¾å™ªå£°æ›´åŠ é²æ£’ï¼ŒåŒæ—¶ä¿æŒsklearnçš„ç®€å•æ˜“ç”¨æ¥å£ã€‚

### 3.2 ç»Ÿä¸€çš„predict()æ¥å£è®¾è®¡

```python
class MLPCausalClassifier(BaseEstimator, ClassifierMixin):
    """MLPå› æœåˆ†ç±»å™¨ - sklearné£æ ¼æ¥å£"""
    
    def predict(self, X, mode='compatible'):
        """ç»Ÿä¸€åˆ†ç±»é¢„æµ‹æ¥å£
        
        Parameters:
        -----------
        X : array-like
            è¾“å…¥ç‰¹å¾
        mode : str, default='compatible'
            é¢„æµ‹æ¨¡å¼:
            - 'compatible': è¿”å›ç±»åˆ«æ ‡ç­¾ - sklearnå…¼å®¹
            - 'standard': è¿”å›æ¿€æ´»æ¦‚ç‡åˆ†å¸ƒ - æ ‡å‡†CausalEngineæ¨ç†  
            - 'causal': è¿”å›çº¯å› æœæ¿€æ´»æ¦‚ç‡ - æ— å¤–ç”Ÿå™ªå£°
            - 'sampling': è¿”å›æ¢ç´¢æ€§æ¿€æ´»æ¦‚ç‡ - ä¸ªä½“å¤šæ ·æ€§è¾¹ç•Œ
            
        Returns:
        --------
        predictions : array-like or dict
            - mode='compatible': é¢„æµ‹ç±»åˆ«æ ‡ç­¾æ•°ç»„
            - å…¶ä»–mode: {'probabilities': P_kæ•°ç»„, 'distributions': S_kåˆ†å¸ƒåˆ—è¡¨}
        """
        return predictions
    
    def predict_proba(self, X, mode='compatible'):
        """æ¦‚ç‡é¢„æµ‹ - æ”¯æŒå¤šæ¨¡å¼æ¦‚ç‡è®¡ç®—
        
        Parameters:
        -----------
        X : array-like
            è¾“å…¥ç‰¹å¾
        mode : str, default='compatible'
            æ¦‚ç‡è®¡ç®—æ¨¡å¼:
            - 'compatible': Softmaxå½’ä¸€åŒ–æ¦‚ç‡ - sklearnå…¼å®¹
            - 'standard': OvRåŸç”Ÿæ¦‚ç‡ + ç®€å•å½’ä¸€åŒ–
            - 'causal': OvRçº¯å› æœæ¦‚ç‡ + ç®€å•å½’ä¸€åŒ–  
            - 'sampling': OvRæ¢ç´¢æ€§æ¦‚ç‡ + ç®€å•å½’ä¸€åŒ–
            
        Returns:
        --------
        probabilities : array-like, shape (n_samples, n_classes)
            æ¯ä¸ªæ ·æœ¬å¯¹å„ç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒ
        """
        return probabilities
```

### 3.2 æ•°å­¦ç»Ÿä¸€æ€§ï¼šä»å†³ç­–å¾—åˆ†åˆ°åˆ†ç±»æ¦‚ç‡

#### å†…éƒ¨æ•°å­¦æ¡†æ¶
æ‰€æœ‰é¢„æµ‹æ¨¡å¼éƒ½åŸºäºç»Ÿä¸€çš„å†³ç­–å¾—åˆ†åˆ†å¸ƒï¼š
$$S_k \sim \text{Cauchy}(\text{loc}_{S_k}, \text{scale}_{S_k}), \quad k = 1, 2, \ldots, K$$

æ¿€æ´»æ¦‚ç‡è®¡ç®—ï¼ˆæ‰€æœ‰æ¨¡å¼å…±äº«ï¼‰ï¼š

**V1.0 ç®€åŒ–ç‰ˆæœ¬** ($C_k = 0$)ï¼š
$$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k}}{\text{scale}_{S_k}}\right)$$

#### ä¸åŒæ¨¡å¼çš„å®ç°

**predict() æ–¹æ³•**:
- **`compatible`**: $\hat{y} = \arg\max_{k} P_k$ï¼Œè¿”å›ç±»åˆ«æ ‡ç­¾
- **`standard`**: è¿”å› $(\{P_k\}_{k=1}^K, \{S_k\}_{k=1}^K)$ï¼Œå®Œæ•´æ¿€æ´»ä¿¡æ¯
- **`causal`**: è¿”å› $(\{P_k'\}_{k=1}^K, \{S_k'\}_{k=1}^K)$ where $T=0$ï¼Œçº¯å› æœå‚æ•°
- **`sampling`**: è¿”å› $(\{P_k''\}_{k=1}^K, \{S_k''\}_{k=1}^K)$ where $T>0, \text{do\_sample}=\text{True}$ï¼Œæ¢ç´¢æ€§å‚æ•°

**predict_proba() æ¦‚ç‡è®¡ç®—ç­–ç•¥**:
- **`compatible`**: Softmaxå½’ä¸€åŒ– $\tilde{P}_k = \frac{\exp(S_k)}{\sum_{j=1}^K \exp(S_j)}$
- **`standard`**: OvRç®€å•å½’ä¸€åŒ– $\tilde{P}_k = \frac{P_k}{\sum_{j=1}^K P_j}$  
- **`causal`**: OvRç®€å•å½’ä¸€åŒ– $\tilde{P}_k = \frac{P_k'}{\sum_{j=1}^K P_j'}$
- **`sampling`**: OvRç®€å•å½’ä¸€åŒ– $\tilde{P}_k = \frac{P_k''}{\sum_{j=1}^K P_j''}$

### 3.3 æ¦‚ç‡è®¡ç®—ç­–ç•¥çš„æ·±åº¦åˆ†æ

#### 3.3.1 Compatibleæ¨¡å¼ï¼šSoftmaxå½’ä¸€åŒ–

**æ•°å­¦åŸç†**:
$$\tilde{P}_k^{\text{(softmax)}} = \frac{\exp(S_k)}{\sum_{j=1}^K \exp(S_j)}$$

**è®¾è®¡åŠ¨æœº**: ç¡®ä¿ä¸sklearn MLPClassifierçš„å®Œå…¨å…¼å®¹æ€§ï¼Œæ»¡è¶³æ¦‚ç‡å…¬ç† $\sum_{k=1}^K \tilde{P}_k = 1$

**é€‚ç”¨åœºæ™¯**: 
- ä¼ ç»Ÿå¤šåˆ†ç±»ä»»åŠ¡
- éœ€è¦ä¸¥æ ¼æ¦‚ç‡è§£é‡Šçš„åœºæ™¯
- ä¸ç°æœ‰sklearnå·¥ä½œæµçš„æ— ç¼é›†æˆ

#### 3.3.2 å…¶ä»–æ¨¡å¼ï¼šOvRç®€å•å½’ä¸€åŒ–

**æ•°å­¦åŸç†**:
$$\tilde{P}_k^{\text{(OvR)}} = \frac{P_k}{\sum_{j=1}^K P_j}$$

å…¶ä¸­ $P_k$ æ˜¯CausalEngineçš„åŸç”Ÿæ¿€æ´»æ¦‚ç‡ï¼š
$$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k}}{\text{scale}_{S_k}}\right)$$

**è®¾è®¡åŠ¨æœº**: ä¿æŒCausalEngine OvRç­–ç•¥çš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼ŒåŒæ—¶æä¾›å½’ä¸€åŒ–æ¦‚ç‡

**å…³é”®ä¼˜åŠ¿**:
1. **ä¿æŒç‹¬ç«‹æ€§**: æ¯ä¸ªç±»åˆ«çš„æ¿€æ´»æ¦‚ç‡ç‹¬ç«‹è®¡ç®—ï¼Œæ— å¼ºåˆ¶çº¦æŸ
2. **ä¸ç¡®å®šæ€§ä¿æŒ**: ä¿ç•™äº†åŸç”Ÿæ¿€æ´»æ¦‚ç‡ä¸­çš„ä¸ç¡®å®šæ€§ä¿¡æ¯
3. **å¤šæ ‡ç­¾å‹å¥½**: è‡ªç„¶æ”¯æŒ"å¤šä¸ªç±»åˆ«åŒæ—¶æ¿€æ´»"çš„æƒ…å†µ

#### 3.3.3 ä¸¤ç§ç­–ç•¥çš„å¯¹æ¯”åˆ†æ

| ç‰¹æ€§ | Softmaxå½’ä¸€åŒ– | OvRç®€å•å½’ä¸€åŒ– |
|------|--------------|--------------|
| **æ•°å­¦çº¦æŸ** | ä¸¥æ ¼æ¦‚ç‡åˆ†å¸ƒ $\sum P_k = 1$ | è¿‘ä¼¼æ¦‚ç‡åˆ†å¸ƒ $\sum P_k \approx 1$ |
| **ç‹¬ç«‹æ€§** | ç±»åˆ«é—´ç›¸äº’ä¾èµ– | ç±»åˆ«é—´ç‹¬ç«‹è®¡ç®— |
| **å¤šæ ‡ç­¾æ”¯æŒ** | ä¸è‡ªç„¶ï¼ˆç«äº‰æ€§ï¼‰ | å¤©ç„¶æ”¯æŒ |
| **sklearnå…¼å®¹** | å®Œå…¨å…¼å®¹ | åŠŸèƒ½å…¼å®¹ï¼Œæ•°å€¼ç•¥æœ‰å·®å¼‚ |
| **ä¸ç¡®å®šæ€§è¡¨è¾¾** | é—´æ¥ | ç›´æ¥ä¿ç•™ |
| **è®¡ç®—å¤æ‚åº¦** | $O(K)$ expè®¡ç®— | $O(K)$ ç®€å•è¿ç®— |

#### 3.3.4 å®é™…ä½¿ç”¨å»ºè®®

```python
# ä¼ ç»Ÿå•æ ‡ç­¾åˆ†ç±» - ä½¿ç”¨compatibleæ¨¡å¼
clf = MLPCausalClassifier()
probas = clf.predict_proba(X_test)  # é»˜è®¤compatibleï¼ŒSoftmaxå½’ä¸€åŒ–

# å¤šæ ‡ç­¾åˆ†ç±»æˆ–ä¸ç¡®å®šæ€§åˆ†æ - ä½¿ç”¨å…¶ä»–æ¨¡å¼  
probas_ovr = clf.predict_proba(X_test, mode='standard')  # OvRåŸç”Ÿæ¦‚ç‡
probas_causal = clf.predict_proba(X_test, mode='causal')  # çº¯å› æœæ¦‚ç‡

# å¯¹æ¯”åˆ†æ
print("Softmaxæ¦‚ç‡:", probas[0])       # [0.1, 0.3, 0.6] - ä¸¥æ ¼å½’ä¸€åŒ–
print("OvRæ¦‚ç‡:", probas_ovr[0])       # [0.12, 0.31, 0.57] - è¿‘ä¼¼å½’ä¸€åŒ–
print("å› æœæ¦‚ç‡:", probas_causal[0])    # [0.15, 0.28, 0.57] - å› æœæ¨ç†
```

### 3.4 æŸå¤±å‡½æ•°ï¼šäºŒå…ƒäº¤å‰ç†µ vs Cauchy NLL

#### åˆ†ç±»æŸå¤±çš„ç‰¹æ®Šæ€§
å¯¹äºå¤šç±»åˆ«åˆ†ç±»ï¼Œè®¾çœŸå®æ ‡ç­¾ä¸º one-hot ç¼–ç  $\mathbf{y} = [y_1, y_2, \ldots, y_K]^T$ï¼Œå…¶ä¸­ $y_k \in \{0, 1\}$ ä¸” $\sum_{k=1}^K y_k = 1$ã€‚

å¯¹æ¯ä¸ªç±»åˆ« $k$ï¼Œä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±ï¼š
$$\mathcal{L}_k = -[y_k \log(P_k) + (1-y_k) \log(1-P_k)]$$

æ€»æŸå¤±ï¼ˆOvR ç­–ç•¥ï¼‰ï¼š
$$\mathcal{L}_{\text{total}} = \sum_{k=1}^K \mathcal{L}_k = -\sum_{k=1}^K [y_k \log(P_k) + (1-y_k) \log(1-P_k)]$$

#### ä¸å›å½’æŸå¤±çš„å¯¹æ¯”

**å›å½’**: ç›´æ¥å¯¹åˆ†å¸ƒä¼¼ç„¶å»ºæ¨¡
$$\mathcal{L}_{\text{reg}} = \log(\pi \cdot \gamma_Y) + \log\left(1 + \left(\frac{y_{\text{true}} - \mu_Y}{\gamma_Y}\right)^2\right)$$

**åˆ†ç±»**: å¯¹æ¿€æ´»æ¦‚ç‡å»ºæ¨¡
$$\mathcal{L}_{\text{clf}} = -\sum_{k=1}^K [y_k \log(P_k) + (1-y_k) \log(1-P_k)]$$

## 4. å®ç°è·¯çº¿å›¾

### 4.1 æ•°å­¦ç­‰ä»·æ€§ä¸æ¶ˆèå®éªŒåŸºç¡€

**é‡è¦ç†è®ºå‘ç°**ï¼šCausalEngineåˆ†ç±»å™¨åœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¯å®ç°ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ§åˆ¶å¯¹æ¯”ï¼Œä¸ºæ¶ˆèå®éªŒæä¾›ç†è®ºåŸºç¡€ã€‚

#### 4.1.1 å†»ç»“æœºåˆ¶ç”¨äºåˆ†ç±»ä»»åŠ¡

```python
def freeze_abduction_to_identity(causal_classifier):
    """
    å†»ç»“AbductionNetworkä¸ºæ’ç­‰æ˜ å°„ï¼Œç”¨äºåˆ†ç±»ä»»åŠ¡çš„æ¶ˆèå®éªŒ
    
    è¿™å…è®¸æˆ‘ä»¬éªŒè¯å› æœåˆ†ç±»ç›¸æ¯”ä¼ ç»ŸSoftmaxçš„çœŸå®è´¡çŒ®
    """
    abduction = causal_classifier.causal_engine.abduction
    
    if hasattr(abduction, '_loc_is_identity_candidate') and abduction._loc_is_identity_candidate:
        with torch.no_grad():
            causal_size = abduction.causal_size
            abduction.loc_net.weight.copy_(torch.eye(causal_size))
            abduction.loc_net.bias.zero_()
            
        abduction.loc_net.weight.requires_grad = False
        abduction.loc_net.bias.requires_grad = False
        return True
    return False

# æ¶ˆèå®éªŒè®¾è®¡
baseline_classifier = MLPCausalClassifier(causal_size=input_size)
freeze_success = freeze_abduction_to_identity(baseline_classifier)

if freeze_success:
    # ä½¿ç”¨OvRå†³ç­–å‡½æ•°ï¼Œä½†Abductionä¸ºæ’ç­‰
    # å¯ä»¥ä¸å®Œæ•´CausalEngineè¿›è¡Œå…¬å¹³çš„ç»“æ„åŒ–å¯¹æ¯”
    pass
```

#### 4.1.2 åˆ†ç±»ä»»åŠ¡çš„æ•°å­¦å·®å¼‚

**ä¼ ç»ŸSoftmaxåˆ†ç±»**:
```
P_k = exp(z_k) / Î£_j exp(z_j)    # å…¨å±€ç«äº‰å½’ä¸€åŒ–
```

**CausalEngine OvRåˆ†ç±»ï¼ˆå†»ç»“æ¨¡å¼ï¼‰**:
```
U = I(x) = x                     # æ’ç­‰Abduction  
S_k = W_k Ã— U + b_k              # æ¯ç±»ç‹¬ç«‹Action
P_k = 1/2 + (1/Ï€)arctan(S_k/Î³_k) # ç‹¬ç«‹OvRæ¿€æ´»
```

**æ ¸å¿ƒå·®å¼‚**: å³ä½¿åœ¨å†»ç»“æ¨¡å¼ä¸‹ï¼ŒOvRç­–ç•¥ä»ä¿æŒç±»åˆ«ç‹¬ç«‹æ€§ï¼Œè¿™æ˜¯å™ªå£°é²æ£’æ€§çš„æ ¹æœ¬æ¥æºã€‚

#### 4.1.3 æ¶ˆèå®éªŒçš„æ„ä¹‰

1. **ç­–ç•¥åˆ†ç¦»**: å°†å› æœæ¨ç†èƒ½åŠ›ä¸OvRå†³ç­–ç­–ç•¥åˆ†å¼€éªŒè¯
2. **å™ªå£°é²æ£’æ€§æºå¤´**: ç¡®è®¤é²æ£’æ€§æ¥è‡ªOvRè€Œéå¤æ‚çš„å› æœå»ºæ¨¡
3. **å…¬å¹³åŸºå‡†**: åœ¨ç›¸åŒç½‘ç»œç»“æ„ä¸‹å¯¹æ¯”ä¸åŒå†³ç­–ç­–ç•¥çš„æ•ˆæœ

### 4.2 V1.0 æ ¸å¿ƒåˆ†ç±»å™¨å®ç°
**é‡ç‚¹**: ä¸“æ³¨å¤šåˆ†ç±»ä»»åŠ¡ï¼Œå®ç°å®Œæ•´çš„sklearné£æ ¼æ¥å£

- [x] å®ç° `MLPCausalClassifier` åŸºç¡€ç±»
- [x] é›†æˆCausalEngineæ ¸å¿ƒåŠŸèƒ½ï¼ˆAbductionNetwork + ActionNetworkï¼‰
- [x] å®ç°è¯å…ƒæ¿€æ´»å‡½æ•°ï¼ˆå›ºå®šé˜ˆå€¼ $C_k = 0$ï¼‰
- [x] å®ç°OvRåˆ†ç±»ç­–ç•¥å’ŒBCEæŸå¤±
- [x] æ ‡å‡†sklearnæ¥å£ï¼š`predict()`, `predict_proba()`, `score()`
- [x] åŸºç¡€å‚æ•°éªŒè¯å’Œé”™è¯¯å¤„ç†
- [x] **æ–°å¢**: å†»ç»“æœºåˆ¶æ”¯æŒï¼Œä¸ºæ¶ˆèå®éªŒæä¾›ç†è®ºåŸºç¡€

### 4.2 V1.1 å¢å¼ºåŠŸèƒ½
- [ ] å¤šåˆ†ç±»ç­–ç•¥ä¼˜åŒ–ï¼ˆOvR vs OvO vs Softmaxå¯¹æ¯”ï¼‰
- [ ] ç±»åˆ«ä¸å¹³è¡¡å¤„ç†
- [ ] **V2.0 ç‰¹æ€§**: å¯å­¦ä¹ åˆ†ç±»é˜ˆå€¼ $C_k$ çš„å®ç°
- [ ] sklearnå…¼å®¹æ€§å…¨é¢æµ‹è¯•

### 4.3 V1.2 é«˜çº§ç‰¹æ€§
- [ ] ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆåˆ†ç±»ç‰¹åŒ–ï¼‰
- [ ] å†³ç­–è¾¹ç•Œå¯è§†åŒ–
- [ ] ç±»åˆ«ç½®ä¿¡åº¦åˆ†æ
- [ ] æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Šé›†æˆ

## 5. MLPCausalClassifierçš„æ ¸å¿ƒç«äº‰ä¼˜åŠ¿ï¼šæ ‡ç­¾å™ªå£°é²æ£’æ€§ ğŸ›¡ï¸

**ä¸ºä»€ä¹ˆè¿™å¯¹sklearné£æ ¼æ¨¡å—åŒ–è‡³å…³é‡è¦ï¼Ÿ**ï¼šåœ¨ç°å®çš„åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæ ‡ç­¾è´¨é‡å¾€å¾€æ˜¯æœ€å¤§çš„ç—›ç‚¹ã€‚ä¼ ç»ŸMLPClassifierå¯¹å™ªå£°æ ‡ç­¾æå…¶æ•æ„Ÿï¼Œé€šå¸¸éœ€è¦å¤§é‡äººå·¥æ£€æŸ¥å’Œæ¸…æ´—å·¥ä½œã€‚MLPCausalClassifieré€šè¿‡æ•°å­¦åˆ›æ–°å®ç°äº†å¼€ç®±å³ç”¨çš„å™ªå£°é²æ£’æ€§ï¼Œè®©ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨"è„æ•°æ®"è®­ç»ƒå‡ºé«˜è´¨é‡æ¨¡å‹ã€‚

### 5.1 OvRç­–ç•¥çš„å¤©ç„¶æŠ—å™ªå£°ä¼˜åŠ¿

#### 5.1.1 æ•°å­¦åŸç†ï¼šç‹¬ç«‹æ¿€æ´» vs ç«äº‰æ€§å½’ä¸€åŒ–

**CausalEngine OvRçš„ç‹¬ç«‹æ€§**ï¼š
$$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k}}{\text{scale}_{S_k}}\right) \quad \text{(æ¯ä¸ªç±»åˆ«ç‹¬ç«‹åˆ¤æ–­)}$$

**ä¼ ç»ŸSoftmaxçš„ç«äº‰æ€§**ï¼š
$$P_k^{\text{softmax}} = \frac{\exp(z_k)}{\sum_{j=1}^K \exp(z_j)} \quad \text{(å¼ºåˆ¶å½’ä¸€åŒ–çº¦æŸ)}$$

**å…³é”®å·®å¼‚çš„å®ç”¨å½±å“**ï¼š
```python
# å™ªå£°åœºæ™¯ç¤ºä¾‹ï¼šçœŸå®æ ‡ç­¾[Cat]è¢«é”™è¯¯æ ‡è®°ä¸º[Dog]

# âŒ ä¼ ç»ŸSoftmaxï¼šå™ªå£°ä¼ æ’­åˆ°æ‰€æœ‰ç±»åˆ«
# é”™è¯¯è®­ç»ƒæ ·æœ¬å½±å“æ•´ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å½’ä¸€åŒ–
softmax_probs = [0.1, 0.7, 0.2]  # [Cat, Dog, Bird] - Dogæ¦‚ç‡è¢«é”™è¯¯æå‡

# âœ… CausalEngine OvRï¼šå™ªå£°å±€é™åœ¨å•ä¸ªç±»åˆ«  
# é”™è¯¯æ ‡ç­¾åªå½±å“å¯¹åº”ç±»åˆ«ï¼Œå…¶ä»–ç±»åˆ«ä¿æŒç‹¬ç«‹
ovr_probs = [0.8, 0.3, 0.2]  # [Cat, Dog, Bird] - Catæ¦‚ç‡ä¿æŒå‡†ç¡®
```

**æ•°å­¦ä¿è¯**ï¼š
- **å™ªå£°éš”ç¦»**: $P_{\text{cat}}$ çš„è®¡ç®—å®Œå…¨ç‹¬ç«‹äº $P_{\text{dog}}$ çš„è®­ç»ƒå™ªå£°
- **å› æœæœ¬è´¨**: å­¦ä¹ çš„æ˜¯ä¸ªä½“å› æœè¡¨å¾ $U$ï¼Œè€Œéè¡¨å±‚æ ‡ç­¾å…³è”
- **åˆ†å¸ƒç¨³å®š**: Cauchyåˆ†å¸ƒçš„é‡å°¾ç‰¹æ€§å¤©ç„¶æŠ—å¼‚å¸¸å€¼

#### 5.1.2 sklearnå·¥ä½œæµçš„é©å‘½æ€§ç®€åŒ–

**ä¼ ç»ŸMLPClassifierå·¥ä½œæµ vs CausalEngineå·¥ä½œæµ**ï¼š

```python
# âŒ ä¼ ç»ŸMLPClassifierï¼šå¤æ‚çš„æ ‡ç­¾æ¸…æ´—æµç¨‹
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score

# ç¬¬1æ­¥ï¼šäººå·¥æ£€æŸ¥æ ‡ç­¾è´¨é‡ï¼ˆè€—æ—¶è€—åŠ›ï¼‰
suspicious_indices = detect_label_anomalies(X, y)
y_cleaned = manual_label_verification(y, suspicious_indices)

# ç¬¬2æ­¥ï¼šå¤šè½®è®­ç»ƒéªŒè¯ï¼ˆåå¤è¿­ä»£ï¼‰
for attempt in range(max_attempts):
    clf = MLPClassifier().fit(X, y_cleaned)
    if cross_val_score(clf, X, y_cleaned).mean() > threshold:
        break
    else:
        y_cleaned = further_label_cleaning(X, y_cleaned)

# âœ… MLPCausalClassifierï¼šç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
causal_clf = MLPCausalClassifier()
causal_clf.fit(X, y_raw)  # æ— éœ€æ ‡ç­¾æ¸…æ´—ï¼

# æ€§èƒ½å¯¹æ¯”ï¼šåœ¨å¹²å‡€æµ‹è¯•é›†ä¸Šè¯„ä¼°
print(f"ä¼ ç»Ÿæ–¹æ³•ç²¾åº¦: {accuracy_score(y_test_clean, clf.predict(X_test)):.3f}")
print(f"CausalEngineç²¾åº¦: {accuracy_score(y_test_clean, causal_clf.predict(X_test)):.3f}")
```

**æ ‡å‡†å™ªå£°é²æ£’æ€§åŸºå‡†æµ‹è¯•**ï¼š
```python
def sklearn_classification_noise_benchmark(X, y_clean):
    """sklearné£æ ¼çš„åˆ†ç±»å™ªå£°é²æ£’æ€§æµ‹è¯•"""
    # ç°å®æ ‡ç­¾å™ªå£°åœºæ™¯
    noise_scenarios = {
        'random_flip': [0.1, 0.2, 0.3, 0.4, 0.5],        # éšæœºæ ‡ç­¾ç¿»è½¬
        'systematic_bias': [0.15, 0.3],                   # ç³»ç»Ÿæ€§æ ‡æ³¨åå·®
        'annotator_disagreement': [0.2, 0.35],            # æ ‡æ³¨å‘˜åˆ†æ­§
        'temporal_drift': [0.1, 0.25]                     # æ—¶é—´æ¼‚ç§»
    }
    
    results = {}
    for scenario, noise_levels in noise_scenarios.items():
        results[scenario] = []
        for level in noise_levels:
            # åº”ç”¨ç°å®å™ªå£°
            y_noisy = apply_classification_noise(y_clean, scenario, level)
            
            # ç›´æ¥å¯¹æ¯”ï¼šæ— é¢„å¤„ç† vs æœ€ä½³æ¸…æ´—
            causal_clf = MLPCausalClassifier().fit(X, y_noisy)
            traditional_clf = get_best_cleaned_mlp(X, y_noisy)  # æœ€ä½³æ¸…æ´—åçš„ä¼ ç»Ÿæ–¹æ³•
            
            results[scenario].append({
                'noise_level': level,
                'causal_accuracy': causal_clf.score(X_test, y_clean),
                'traditional_accuracy': traditional_clf.score(X_test, y_clean),
                'workflow_advantage': f'CausalEngine: {causal_clf.fit_time:.1f}s vs Traditional: {traditional_clf.total_time:.1f}s'
            })
    
    return results

def apply_classification_noise(y, scenario, level):
    """åº”ç”¨ç°å®çš„åˆ†ç±»æ ‡ç­¾å™ªå£°"""
    if scenario == 'random_flip':
        return random_label_flip(y, level)
    elif scenario == 'systematic_bias':
        return systematic_label_bias(y, level)  
    elif scenario == 'annotator_disagreement':
        return annotator_confusion_matrix(y, level)
    elif scenario == 'temporal_drift':
        return temporal_label_drift(y, level)
```

**é¢„æœŸä¼˜åŠ¿**ï¼š
- **å™ªå£°é²æ£’æ€§**: 50%æ ‡ç­¾å™ªå£°ä¸‹ä»ä¿æŒ80%+åŸå§‹æ€§èƒ½
- **å·¥ä½œæµç®€åŒ–**: ä»20+è¡Œé¢„å¤„ç†ä»£ç ç®€åŒ–ä¸º1è¡Œè®­ç»ƒä»£ç 
- **æ—¶é—´æ•ˆç‡**: è·³è¿‡æ•°æ®æ¸…æ´—ï¼Œç›´æ¥è·å¾—é«˜è´¨é‡æ¨¡å‹

### 5.2 åº”ç”¨ä»·å€¼ä¸åœºæ™¯

**é«˜ä»·å€¼åœºæ™¯**:
1. **åŒ»ç–—è¯Šæ–­**: ä¸åŒåŒ»ç”Ÿçš„è¯Šæ–­å·®å¼‚ï¼Œç–æ¼è¯Šæ–­
2. **æƒ…æ„Ÿåˆ†æ**: äººå·¥æ ‡æ³¨çš„ä¸»è§‚æ€§å’Œä¸ä¸€è‡´æ€§
3. **å†…å®¹å®¡æ ¸**: è¾¹ç•Œå†…å®¹çš„æ ‡æ³¨äº‰è®®
4. **ä¼ æ„Ÿå™¨æ•°æ®**: ç¯å¢ƒå¹²æ‰°å¯¼è‡´çš„è¯¯åˆ¤
5. **é‡‘èé£æ§**: æ•°æ®æºä¸ä¸€è‡´çš„é£é™©æ ‡ç­¾

**ç«äº‰ä¼˜åŠ¿å¯¹æ¯”**:
```python
# ä¼ ç»Ÿæ–¹æ³•éœ€è¦å¤æ‚çš„æ•°æ®æ¸…æ´—
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import IsolationForest

# CausalEngine: ç›´æ¥å¤„ç†å™ªå£°æ•°æ®
clf_causal = MLPCausalClassifier()
clf_causal.fit(X_train, y_noisy)  # ç›´æ¥ä½¿ç”¨å™ªå£°æ•°æ®

# è·å–ä¸ç¡®å®šæ€§ä¿¡æ¯ç”¨äºå™ªå£°æ£€æµ‹
dists = clf_causal.predict(X_test, mode='standard')
uncertainty = [dist.scale.mean() for dist in dists['distributions']]
# é«˜ä¸ç¡®å®šæ€§å¯èƒ½æŒ‡ç¤ºå™ªå£°æ•°æ®
```

## 6. ç‹¬ç‰¹ä»·å€¼ä¸»å¼ 

### 6.1 è¶…è¶Šä¼ ç»Ÿåˆ†ç±»å™¨çš„èƒ½åŠ›

```python
# ä¼ ç»Ÿåˆ†ç±»å™¨ï¼šåªèƒ½å¾—åˆ°æ¦‚ç‡
clf_traditional = MLPClassifier()
probas = clf_traditional.predict_proba(X_test)  # åªæœ‰æ¦‚ç‡

# CausalEngineåˆ†ç±»å™¨ï¼šæ¦‚ç‡ + åˆ†å¸ƒ + å› æœæ¨ç†
clf_causal = MLPCausalClassifier()
labels = clf_causal.predict(X_test)                    # ç±»åˆ«æ ‡ç­¾
probas = clf_causal.predict_proba(X_test)              # æ¿€æ´»æ¦‚ç‡
dists = clf_causal.predict(X_test, mode='standard')    # å†³ç­–å¾—åˆ†åˆ†å¸ƒ

# æ·±åº¦åˆ†æèƒ½åŠ›
for i, (prob, dist) in enumerate(zip(probas, dists['distributions'])):
    print(f"æ ·æœ¬{i}: é¢„æµ‹æ¦‚ç‡={prob.max():.3f}")
    print(f"  å†³ç­–å¾—åˆ†: Î¼={dist.loc:.2f}, Î³={dist.scale:.3f}")
    print(f"  å†³ç­–ç½®ä¿¡åº¦: {dist.scale:.3f}")  # å°ºåº¦å‚æ•°åæ˜ ç½®ä¿¡åº¦
```

### 6.2 OvRç­–ç•¥çš„ä¼˜åŠ¿

**æ•°å­¦å¯¹æ¯”**:

ä¼ ç»Ÿ Softmax çº¦æŸï¼š
$$\sum_{k=1}^K P_k = 1, \quad P_k = \frac{\exp(z_k)}{\sum_{j=1}^K \exp(z_j)}$$

CausalEngine OvR ç­–ç•¥ï¼ˆV1.0ï¼‰ï¼š
$$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k}}{\text{scale}_{S_k}}\right) \quad \text{(ç‹¬ç«‹è®¡ç®—ï¼Œé˜ˆå€¼=0)}$$

**ä¼˜åŠ¿ç¤ºä¾‹**:
```python
# ç‹¬ç«‹ç±»åˆ«åˆ¤æ–­ï¼Œæ— å½’ä¸€åŒ–çº¦æŸ
P_1 = 0.8  # ç±»åˆ«1çš„æ¿€æ´»æ¦‚ç‡
P_2 = 0.7  # ç±»åˆ«2çš„æ¿€æ´»æ¦‚ç‡  
P_3 = 0.1  # ç±»åˆ«3çš„æ¿€æ´»æ¦‚ç‡

# æ•°å­¦ç‰¹æ€§:
# ä¼ ç»Ÿ: Î£P_k = 1 (å¼ºåˆ¶çº¦æŸ)
# CausalEngine: Î£P_k â‰  1 (çµæ´»æ€§)
# å…è®¸è¡¨è¾¾: "å¤šä¸ªç±»åˆ«éƒ½æ¿€æ´»" æˆ– "æ‰€æœ‰ç±»åˆ«éƒ½ä¸æ¿€æ´»"
```

## 7. æŠ€æœ¯å®ç°è¦ç‚¹

### 7.1 å…³é”®æŒ‘æˆ˜

1. **é˜ˆå€¼è®¾è®¡**: V1.0 ä½¿ç”¨å›ºå®šé˜ˆå€¼ $C_k = 0$ï¼Œç®€åŒ–å®ç°
   $$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k}}{\text{scale}_{S_k}}\right)$$
   
   **V2.0+ å¯å­¦ä¹ é˜ˆå€¼**: æ¯ä¸ªç±»åˆ«çš„æ¿€æ´»é˜ˆå€¼ $C_k$ çš„è‡ªåŠ¨å­¦ä¹ 
   $$\frac{\partial \mathcal{L}}{\partial C_k} = \frac{\partial \mathcal{L}}{\partial P_k} \cdot \frac{\partial P_k}{\partial C_k}$$
   
2. **ç±»åˆ«å¹³è¡¡**: å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†çš„æ¿€æ´»æ¦‚ç‡åå·®
   $$\text{weighted\_loss} = \sum_{k=1}^K w_k \mathcal{L}_k, \quad w_k = \frac{N}{K \cdot N_k}$$
   
3. **æ¢¯åº¦è®¡ç®—**: $\arctan$ å‡½æ•°çš„é«˜æ•ˆåå‘ä¼ æ’­
   
   **V1.0 ç®€åŒ–ç‰ˆæœ¬** ($C_k = 0$)ï¼š
   $$\frac{\partial P_k}{\partial \text{loc}_{S_k}} = \frac{1}{\pi} \cdot \frac{\text{scale}_{S_k}}{\text{scale}_{S_k}^2 + \text{loc}_{S_k}^2}$$
   
4. **æ•°å€¼ç¨³å®šæ€§**: æ¦‚ç‡è®¡ç®—çš„æ•°å€¼ç²¾åº¦ä¿è¯
   $$P_k \in [0, 1], \quad \text{clamp}(\arctan(\cdot), -\pi/2, \pi/2)$$
   
5. **å¤šç±»åˆ«ç­–ç•¥**: OvR vs OvO vs åŸç”Ÿå¤šç±»åˆ«çš„æ€§èƒ½å¯¹æ¯”

### 7.2 æ¶æ„è®¾è®¡
```python
causal_engine/sklearn/
â”œâ”€â”€ __init__.py           # å¯¼å‡ºæ‰€æœ‰åˆ†ç±»å™¨
â”œâ”€â”€ classifier.py         # MLPCausalClassifieræ ¸å¿ƒå®ç°
â”œâ”€â”€ _classification.py    # åˆ†ç±»ç‰¹æœ‰çš„å·¥å…·å‡½æ•°
â”œâ”€â”€ _activation.py        # è¯å…ƒæ¿€æ´»å‡½æ•°å®ç°
â”œâ”€â”€ _thresholds.py        # é˜ˆå€¼å­¦ä¹ å’Œä¼˜åŒ–
â””â”€â”€ _metrics.py           # åˆ†ç±»è¯„ä¼°æŒ‡æ ‡
```

## 8. ä¸å›å½’å™¨çš„ååŒ

### 8.1 å…±äº«åŸºç¡€æ¶æ„
```python
# å…±äº«çš„åŸºç¡€ç»„ä»¶
from causal_engine.sklearn._base import CausalBase
from causal_engine.sklearn._config import AutoConfig

# åˆ†ç±»å™¨ç‰¹åŒ–
class MLPCausalClassifier(CausalBase, ClassifierMixin):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.task_type = 'classification'
```

### 8.2 ç»Ÿä¸€çš„ç”¨æˆ·ä½“éªŒ
```python
# å›å½’å’Œåˆ†ç±»çš„ä¸€è‡´æ€§API
reg = MLPCausalRegressor()
clf = MLPCausalClassifier()

# ç›¸åŒçš„è®­ç»ƒæ¥å£
reg.fit(X_train, y_reg)
clf.fit(X_train, y_clf)

# ç›¸åŒçš„é¢„æµ‹æ¨¡å¼
reg_preds = reg.predict(X_test, mode='standard')
clf_preds = clf.predict(X_test, mode='standard')
```

---

## 9. åç»­å¼€å‘è®¡åˆ’ä¸è€ƒè™‘

### 9.1 V1.1 æ ¸å¿ƒåŠŸèƒ½å¢å¼º

#### 9.1.1 å¤šåˆ†ç±»ç­–ç•¥ä¼˜åŒ–
**å¼€å‘åŠ¨æœº**: å½“å‰V1.0ä½¿ç”¨OvRç­–ç•¥ï¼Œä½†æŸäº›ä»»åŠ¡å¯èƒ½éœ€è¦å…¶ä»–ç­–ç•¥
**æŠ€æœ¯æ–¹æ¡ˆ**: 
- **OvO (One-vs-One)**: $\binom{K}{2}$ ä¸ªäºŒå…ƒåˆ†ç±»å™¨ï¼Œé€‚åˆç±»åˆ«æ•°è¾ƒå°‘çš„åœºæ™¯
- **åŸç”Ÿå¤šç±»åˆ«**: ç›´æ¥å¯¹æ•°æ®é›†è¿›è¡Œ $K$ ç±»åˆ†ç±»ï¼Œéœ€è¦é‡æ–°è®¾è®¡æŸå¤±å‡½æ•°
- **åˆ†å±‚åˆ†ç±»**: åˆ©ç”¨ç±»åˆ«é—´çš„å±‚æ¬¡å…³ç³»ï¼Œé€‚åˆæ ‘å½¢ç»“æ„çš„åˆ†ç±»
**æ•°å­¦æ¡†æ¶**: 
- OvO: $\text{vote}(\{\arg\max_{i,j} P_{ij}\})$
- åŸç”Ÿ: $\text{softmax}(\mathbf{S}) = \frac{\exp(S_k)}{\sum_{j=1}^K \exp(S_j)}$

#### 9.1.2 ç±»åˆ«ä¸å¹³è¡¡å¤„ç†
**éœ€æ±‚èƒŒæ™¯**: å®é™…æ•°æ®é›†ä¸­ç±»åˆ«åˆ†å¸ƒå¸¸å¸¸ä¸å‡è¡¡ï¼Œå½±å“æ¿€æ´»æ¦‚ç‡çš„å…¬å¹³æ€§
**æŠ€æœ¯æ–¹æ¡ˆ**: 
1. **åŠ æƒæŸå¤±**: $w_k = \frac{N}{K \cdot N_k}$ å¯¹å°‘æ•°ç±»å¢åŠ æƒé‡
2. **é˜ˆå€¼è°ƒæ•´**: è‡ªåŠ¨è°ƒæ•´æ¿€æ´»é˜ˆå€¼ä»¥å¹³è¡¡ç±»åˆ«åˆ†å¸ƒ
3. **é‡‡æ ·ç­–ç•¥**: SMOTEç­‰æ•°æ®å¢å¼ºæ–¹æ³•çš„é›†æˆ
**æ•°å­¦åŸç†**: 
$$\mathcal{L}_{\text{balanced}} = \sum_{k=1}^K w_k \sum_{i \in \text{class}_k} \mathcal{L}_k^{(i)}$$

#### 9.1.3 æ ‡ç­¾å™ªå£°é²æ£’æ€§éªŒè¯å’Œå±•ç¤º
**å¼€å‘åŠ¨æœº**: éªŒè¯å’Œå±•ç¤ºCausalEngineåœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„æ ¸å¿ƒç†è®ºä¼˜åŠ¿
**æŠ€æœ¯å®ç°**: 
- å»ºç«‹åˆ†ç±»ç‰¹æœ‰çš„å™ªå£°æ¨¡æ‹Ÿå·¥å…·ï¼ˆæ ‡ç­¾ç¿»è½¬ã€ç¼ºå¤±æ ‡ç­¾ç­‰ï¼‰
- å¼€å‘OvRç­–ç•¥ä¸Softmaxçš„ç›´æ¥å¯¹æ¯”å®éªŒ
- å®ç°å¤šæ ‡ç­¾åœºæ™¯ä¸‹çš„é²æ£’æ€§æµ‹è¯•
**æ•°å­¦æ¡†æ¶**: 
- **å™ªå£°ä¼ æ’­åˆ†æ**: $\frac{\partial \mathcal{L}}{\partial \eta}$ å¯¹ä¸åŒç­–ç•¥çš„å½±å“
- **é²æ£’æ€§æŒ‡æ ‡**: $\text{robustness} = 1 - \frac{\text{performance\_drop}}{\text{noise\_level}}$
**é¢„æœŸæ”¶ç›Š**: 
- è¯æ˜CausalEngineåœ¨çœŸå®ä¸–ç•Œå™ªå£°ç¯å¢ƒä¸­çš„ä¼˜åŠ¿
- å¸å¼•é¢ä¸´æ•°æ®è´¨é‡æŒ‘æˆ˜çš„ä¼ä¸šç”¨æˆ·

#### 9.1.4 æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Šé›†æˆ
**äº§å“ä»·å€¼**: æä¾›ä¸sklearnä¸€è‡´çš„è¯„ä¼°æŠ¥å‘Šå’Œå¯è§†åŒ–
**æŠ€æœ¯å®ç°**: 
- ä¸sklearn.metricsçš„æ— ç¼é›†æˆ
- CausalEngineç‰¹æœ‰çš„æŒ‡æ ‡ï¼šå†³ç­–ä¸ç¡®å®šæ€§åˆ†æ
- å¯è§†åŒ–å·¥å…·ï¼šæ¿€æ´»æ¦‚ç‡åˆ†å¸ƒã€å†³ç­–è¾¹ç•Œç­‰
**ç‹¬ç‰¹æŒ‡æ ‡**: 
- **æ¿€æ´»ç¨³å®šæ€§**: $\text{stability} = 1 - \frac{\text{std}(P_k)}{\text{mean}(P_k)}$
- **å†³ç­–ç½®ä¿¡åº¦**: $\text{confidence} = \max_k P_k - \text{median}(\{P_j\}_{j \neq k})$

### 9.2 V1.2 é«˜çº§ç‰¹æ€§å¼€å‘

#### 9.2.1 ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆåˆ†ç±»ç‰¹åŒ–ï¼‰
**æŠ€æœ¯æŒ‘æˆ˜**: ä¼ ç»Ÿæ–¹æ³•ä¸»è¦é’ˆå¯¹è¿ç»­è¾“å‡ºï¼Œéœ€è¦é€‚é…ç¦»æ•£æ¦‚ç‡è¾“å‡º
**åˆ›æ–°æ–¹æ¡ˆ**: 
1. **æ¿€æ´»æ¦‚ç‡æ¢…åº¦**: $\frac{\partial P_k}{\partial x_i}$ å¯¹ç‰¹å¾é‡è¦æ€§çš„ç›´æ¥è¡¡é‡
2. **å†³ç­–è¾¹ç•Œåˆ†æ**: åˆ©ç”¨CausalEngineçš„åˆ†å¸ƒè¾“å‡ºåˆ†æç‰¹å¾å¯¹å†³ç­–è¾¹ç•Œçš„å½±å“
3. **å› æœç‰¹å¾é‡è¦æ€§**: ç»“åˆä¸åŒæ¨ç†æ¨¡å¼åˆ†æç‰¹å¾çš„å› æœä½œç”¨
**æ•°å­¦å®šä¹‰**: 
$$\text{importance}_i = \mathbb{E}\left[\left|\frac{\partial P_{\text{true}}}{\partial x_i}\right|\right]$$

#### 9.2.2 å†³ç­–è¾¹ç•Œå¯è§†åŒ–
**äº§å“ä»·å€¼**: å¸®åŠ©ç”¨æˆ·ç†è§£CausalEngineçš„å†³ç­–æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯OvRç­–ç•¥çš„ç‹¬ç‰¹æ€§
**æŠ€æœ¯å®ç°**: 
- 2D/3Dç©ºé—´ä¸­çš„æ¿€æ´»æ¦‚ç‡ç­‰é«˜çº¿
- ä¸åŒæ¨ç†æ¨¡å¼ä¸‹çš„å†³ç­–è¾¹ç•Œå¯¹æ¯”
- äº’åŠ¨å¼æ¿€æ´»æ¦‚ç‡æ¢ç´¢å·¥å…·
**ç‹¬ç‰¹ä»·å€¼**: å±•ç¤ºCausalEngineåœ¨è¡¨è¾¾å¤šæ ‡ç­¾æ¿€æ´»å’Œä¸ç¡®å®šæ€§æ–¹é¢çš„ä¼˜åŠ¿

#### 9.2.3 ç±»åˆ«ç½®ä¿¡åº¦åˆ†æ
**ç†è®ºåŸºç¡€**: åˆ©ç”¨Cauchyåˆ†å¸ƒçš„å°ºåº¦å‚æ•°è¡¡é‡å†³ç­–ä¸ç¡®å®šæ€§
**æ•°å­¦æ¡†æ¶**: 
$$\text{confidence}_k = f(\gamma_{S_k}, P_k) = P_k \cdot \exp(-\alpha \gamma_{S_k})$$
å…¶ä¸­ $\alpha$ æ˜¯å¯è°ƒå‚æ•°ï¼Œæ§åˆ¶ä¸ç¡®å®šæ€§çš„å½±å“ç¨‹åº¦
**åº”ç”¨åœºæ™¯**: 
- åŒ»ç–—è¯Šæ–­ä¸­çš„é£é™©è¯„ä¼°
- é‡‘èå†³ç­–ä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–
- è‡ªåŠ¨é©¾é©¶ä¸­çš„å®‰å…¨è¯„ä¼°

### 9.3 å®éªŒæ€§åŠŸèƒ½æ¢ç´¢

#### 9.3.1 å¯å­¦ä¹ æ¿€æ´»é˜ˆå€¼ç ”ç©¶
**ç ”ç©¶é—®é¢˜**: å¯å­¦ä¹ é˜ˆå€¼ $C_k$ åœ¨ä»€ä¹ˆæƒ…å†µä¸‹èƒ½æ˜¾è‘—æå‡æ€§èƒ½ï¼Ÿ
**å®éªŒè®¾è®¡**: 
1. **æ•°æ®é›†ç‰¹æ€§åˆ†æ**: ä¸åŒç±»å‹æ•°æ®é›†ä¸Šçš„æ•ˆæœå¯¹æ¯”
2. **é˜ˆå€¼åˆå§‹åŒ–ç­–ç•¥**: é›¶åˆå§‹åŒ– vs æ•°æ®é©±åŠ¨åˆå§‹åŒ–
3. **æ”¶æ•›æ€§åˆ†æ**: é˜ˆå€¼å­¦ä¹ çš„ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§
**æ•°å­¦æ¨¡å‹**: 
$$C_k^{(t+1)} = C_k^{(t)} - \eta \frac{\partial \mathcal{L}}{\partial C_k}$$
å…¶ä¸­ $\frac{\partial \mathcal{L}}{\partial C_k} = \sum_i \frac{\partial \mathcal{L}}{\partial P_k^{(i)}} \cdot \frac{-1}{\pi} \cdot \frac{\text{scale}_{S_k}^{(i)}}{(\text{scale}_{S_k}^{(i)})^2 + (\text{loc}_{S_k}^{(i)} - C_k)^2}$

#### 9.3.2 åˆ†å±‚åˆ†ç±»æ¶æ„
**æŠ€æœ¯æ„¿æ™¯**: åˆ©ç”¨ç±»åˆ«é—´çš„å±‚æ¬¡å…³ç³»ï¼Œå®ç°æ›´é«˜æ•ˆçš„åˆ†ç±»
**æ¶æ„è®¾è®¡**: 
1. **ç²—ç²’åº¦åˆ†ç±»**: é¡¶å±‚CausalEngineåˆ†è¾¨å¤§ç±»
2. **ç»†ç²’åº¦åˆ†ç±»**: åº•å±‚CausalEngineåœ¨å¤§ç±»å†…éƒ¨è¿›ä¸€æ­¥åˆ†ç±»
3. **è‡ªé€‚åº”æ·±åº¦**: æ ¹æ®æ•°æ®å¤æ‚åº¦åŠ¨æ€è°ƒæ•´å±‚æ¬¡æ·±åº¦
**æ•°å­¦æ¡†æ¶**: 
$$P(y = c_{ij}) = P(\text{coarse} = c_i) \cdot P(\text{fine} = c_{ij} | \text{coarse} = c_i)$$

#### 9.3.3 å¤šæ¨¡æ€åˆ†ç±»æ”¯æŒ
**åº”ç”¨éœ€æ±‚**: å›¾åƒ+æ–‡æœ¬ã€è¯­éŸ³+æ–‡æœ¬ç­‰å¤šæ¨¡æ€æ•°æ®çš„åˆ†ç±»
**æŠ€æœ¯è·¯çº¿**: 
1. **æ¨¡æ€èåˆ**: åœ¨CausalEngineå±‚é¢èåˆä¸åŒæ¨¡æ€çš„ç‰¹å¾
2. **æ¨¡æ€ç‰¹åŒ–**: æ¯ä¸ªæ¨¡æ€ä½¿ç”¨ç‹¬ç«‹çš„AbductionNetwork
3. **ä¸ç¡®å®šæ€§ä¼ æ’­**: åˆ©ç”¨Cauchyåˆ†å¸ƒä¼ æ’­å’Œèåˆä¸åŒæ¨¡æ€çš„ä¸ç¡®å®šæ€§

### 9.4 é•¿æœŸæŠ€æœ¯è·¯çº¿å›¾

#### 9.4.1 ç†è®ºç ”ç©¶æ–¹å‘
1. **OvR vs Softmax çš„ç†è®ºå¯¹æ¯”**: ä»ä¿¡æ¯è®ºè§’åº¦åˆ†æä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ£
2. **æŸ¥ç§åˆ†å¸ƒåœ¨åˆ†ç±»ä¸­çš„åº”ç”¨**: æ¢ç´¢å…¶ä»–é‡å°¾åˆ†å¸ƒçš„æ½œåŠ›
3. **å¤šæ ‡ç­¾å­¦ä¹ çš„æ•°å­¦åŸºç¡€**: å‘å±•é’ˆå¯¹å¤šæ ‡ç­¾ä»»åŠ¡çš„ç†è®ºæ¡†æ¶

#### 9.4.2 å·¥ç¨‹å®ç°ä¼˜åŒ–
1. **æ¦‚ç‡è®¡ç®—ä¼˜åŒ–**: é«˜æ•ˆçš„ $\arctan$ å’ŒæŸ¯è¥¿åˆ†å¸ƒè®¡ç®—
2. **å†…å­˜ç®¡ç†**: å¤§è§„æ¨¡å¤šç±»åˆ«åˆ†ç±»çš„å†…å­˜ä¼˜åŒ–
3. **å¹¶è¡Œè®¡ç®—**: ç‹¬ç«‹ç±»åˆ«æ¿€æ´»çš„å¹¶è¡ŒåŒ–ä¼˜åŠ¿

#### 9.4.3 äº§ä¸šåº”ç”¨æ–¹å‘
1. **é‡‘èé£æ§**: ä¿¡ç”¨è¯„çº§ä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–
2. **åŒ»ç–—è¯Šæ–­**: å¤šç—…å¹¶å‘çš„æ¦‚ç‡è¯„ä¼°
3. **æ¨èç³»ç»Ÿ**: ç”¨æˆ·å…´è¶£çš„å¤šæ ‡ç­¾å»ºæ¨¡
4. **è‡ªç„¶è¯­è¨€å¤„ç†**: æƒ…æ„Ÿåˆ†æä¸­çš„å¤šç±»åˆ«æƒ…æ„Ÿè¯†åˆ«

#### 9.4.4 ç”Ÿæ€ç³»ç»Ÿå»ºè®¾
1. **æ•°æ®é›†å’ŒåŸºå‡†**: å»ºç«‹é’ˆå¯¹å¤šæ ‡ç­¾åˆ†ç±»çš„æ ‡å‡†æ•°æ®é›†
2. **ç«èµ›å’ŒæŒ‘æˆ˜**: ç»„ç»‡CausalEngineåˆ†ç±»ç«èµ›
3. **å­¦æœ¯åˆä½œ**: ä¸é¡¶çº§é™¢æ ¡çš„æœºå™¨å­¦ä¹ å®éªŒå®¤åˆä½œ
4. **å¼€æºç¤¾åŒº**: å»ºè®¾å¼€å‘è€…å’Œç ”ç©¶è€…çš„æ´»è·ƒç¤¾åŒº

## 10. äº§å“å®šä½ä¸å¸‚åœºç«äº‰

### 10.1 å·®å¼‚åŒ–ä»·å€¼ä¸»å¼ 

**æŠ€æœ¯å·®å¼‚åŒ–**:
- **æ•°å­¦åˆ›æ–°**: ç¬¬ä¸€ä¸ªåŸºäºCauchyåˆ†å¸ƒçš„ç”Ÿäº§çº§åˆ†ç±»å™¨
- **è§£æä¼˜åŠ¿**: æ— é‡‡æ ·çš„åˆ†å¸ƒè®¡ç®—ï¼Œæé«˜çš„è®¡ç®—æ•ˆç‡
- **ç‹¬ç‰¹æ¶æ„**: OvRç­–ç•¥å¸¦æ¥çš„çµæ´»æ€§å’Œè¡¨è¾¾èƒ½åŠ›

**ç”¨æˆ·ä½“éªŒä¼˜åŠ¿**:
- **é›¶å­¦ä¹ æˆæœ¬**: å®Œç¾çš„sklearnå…¼å®¹æ€§
- **æ¸è¿›å¼èƒ½åŠ›**: ä»ç®€å•åˆ†ç±»åˆ°å¤æ‚åˆ†å¸ƒåˆ†æ
- **ä¸°å¯Œä¿¡æ¯**: ä¸ä»…æœ‰æ ‡ç­¾ï¼Œè¿˜æœ‰å®Œæ•´çš„ä¸ç¡®å®šæ€§ä¿¡æ¯

### 10.2 ç›®æ ‡å¸‚åœºåˆ†æ

**ä¸»è¦ç«äº‰å¯¹æ‰‹**: 
- **sklearn MLPClassifier**: åŠŸèƒ½å®Œå–„ä½†ç¼ºä¹ä¸ç¡®å®šæ€§ä¿¡æ¯
- **XGBoost/LightGBM**: æ€§èƒ½ä¼˜å¼‚ä½†éš¾ä»¥è§£é‡Š
- **æ·±åº¦å­¦ä¹ æ¨¡å‹**: è¡¨è¾¾èƒ½åŠ›å¼ºä½†è®¡ç®—æˆæœ¬é«˜

**å·®å¼‚åŒ–ä¼˜åŠ¿**:
1. **æ•ˆç‡ + è¡¨è¾¾èƒ½åŠ›**: å…¼å¤‡é«˜æ•ˆè®¡ç®—å’Œå¼ºè¡¨è¾¾èƒ½åŠ›
2. **å¯è§£é‡Šæ€§**: å¤©ç„¶çš„æ¦‚ç‡è§£é‡Šå’Œå› æœåˆ†æ
3. **çµæ´»æ€§**: OvRç­–ç•¥å¯¹å¤šæ ‡ç­¾å’Œä¸å¹³è¡¡æ•°æ®çš„å¤©ç„¶æ”¯æŒ

---

**ğŸ’¡ è¿™ä¸ªæ–¹æ¡ˆçš„ä»·å€¼**:
- ä¿æŒä¸å›å½’å™¨çš„è®¾è®¡ä¸€è‡´æ€§
- å……åˆ†åˆ©ç”¨CausalEngineåœ¨åˆ†ç±»ä»»åŠ¡ä¸Šçš„ç‹¬ç‰¹ä¼˜åŠ¿
- æä¾›è¶…è¶Šä¼ ç»Ÿåˆ†ç±»å™¨çš„åˆ†æèƒ½åŠ›
- ä¸ºå¤šä»»åŠ¡å­¦ä¹ å¥ å®šåŸºç¡€

**ğŸ¯ ä¸‹ä¸€æ­¥**:
å¼€å§‹å®ç°V1.0æ ¸å¿ƒåˆ†ç±»å™¨ï¼Œä¸“æ³¨å¤šåˆ†ç±»ä»»åŠ¡çš„å®Œæ•´åŠŸèƒ½ï¼