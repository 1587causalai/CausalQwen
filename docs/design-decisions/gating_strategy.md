# 门控策略设计决策

## 📋 概述

本文档记录了 CausalQwen 中回归损失门控策略的设计决策过程。

## 🎯 设计目标

1. **理论独立性**：分类和回归任务在逻辑上应该独立优化
2. **实践有效性**：考虑深度学习中的实际训练动态
3. **灵活可调**：支持不同的应用场景和数据特点

## 💡 核心设计：混合门控策略

### 数学表达

$$\mathcal{L}_{\text{reg}} = \sum_{i=1}^S m_i \cdot \left(\alpha + (1-\alpha) \cdot P_{i,\text{<NUM>}}\right) \cdot \ell_{\text{cauchy}}(y_i^{\text{val}}, \text{loc}_{Y,i}, \text{scale}_{Y,i})$$

其中：
- $m_i$：二元掩码，标识位置 $i$ 是否为数值
- $\alpha \in [0, 1]$：门控系数
- $P_{i,\text{<NUM>}}$：模型预测位置 $i$ 为 `<NUM>` 的概率

### 三种模式

1. **无门控（$\alpha = 1$）**：
   - 回归损失独立于分类预测
   - 适合数值密集型任务
   - CausalQwen 的默认选择

2. **完全门控（$\alpha = 0$）**：
   - 回归损失完全由分类概率控制
   - 实现严格的课程学习
   - 适合数值稀疏的任务

3. **混合门控（$0 < \alpha < 1$）**：
   - 平衡独立性和课程学习
   - 保证最小梯度流
   - 适合中等数值密度的任务

## 🔬 理论分析

### 支持无门控的理由

1. **任务独立性**：
   - "这是什么类型？" vs "如果是数值，值是多少？"
   - 两个问题在因果图中是不同路径

2. **优化效率**：
   - 避免早期回归梯度饥饿
   - 加速收敛

3. **数值平等性**：
   - 所有数值位置同等重要
   - 不应因分类不确定性而降权

### 支持门控的理由

1. **课程学习**：
   - 先学简单（分类），后学困难（回归）
   - 更稳定的训练过程

2. **避免干扰**：
   - 防止在文本位置优化回归损失
   - 保护表征学习

3. **自适应注意力**：
   - 模型自主决定学习资源分配
   - 更灵活的优化策略

## 🏭 工程实践

### 默认配置

```python
# CausalQwen 默认使用无门控
reg_loss_gating_alpha = 1.0  # 无门控
```

### 推荐配置

- **数值密集任务**（>30% 数值）：`alpha = 1.0`
- **平衡任务**（10-30% 数值）：`alpha = 0.5`
- **数值稀疏任务**（<10% 数值）：`alpha = 0.1`

### 监控指标

1. **平均门控权重**：监控实际的回归损失权重
2. **数值位置 F1**：评估 `<NUM>` 分类性能
3. **回归 MAE**：评估数值预测精度

## 📊 实验证据

通过 `scripts/experiments/test_gating_strategies.py` 的实验，我们发现：

1. **无门控通常最优**：在大多数任务上，`alpha = 1.0` 表现最佳
2. **任务相关性**：最优 `alpha` 与数据集的数值密度相关
3. **收敛速度**：无门控的收敛速度通常更快

## 🎯 最终决策

**CausalQwen 默认采用无门控策略（`alpha = 1.0`）**，原因如下：

1. **理论纯粹性**：保持任务独立性
2. **实践有效性**：在多数场景下表现最佳
3. **实现简洁性**：减少超参数调优负担
4. **向后兼容**：用户可根据需要调整 `alpha`

## 📚 参考资料

- 原始讨论：项目 Issue #XX
- 实验脚本：`scripts/experiments/test_gating_strategies.py`
- 数学基础：`docs/mathematical_foundations.md`

---

*决策日期：2024-06-12*
*决策者：CausalQwen 团队*
