# CausalQwen 数学实现全面测试指南

本文档提供一个全新的、更加严格的测试框架，专门用于验证 CausalQwen 中每个数学组件的正确实现。

## 🎯 核心测试原则

1. **数学精确性优先**：每个测试必须直接对应数学公式
2. **隔离测试**：每个组件独立测试，避免级联错误
3. **边界条件全覆盖**：特别关注零值、极值、特殊情况
4. **数值稳定性验证**：检查浮点运算的精度和稳定性
5. **维度一致性检查**：确保张量形状在整个流程中保持正确

## 📋 测试清单概览

### 第一部分：基础组件测试
- [x] 数值编码函数 φ(v) 的完整验证
- [x] 增强嵌入计算的精确性测试
- [x] 词汇表扩展的正确性验证

### 第二部分：分布计算测试
- [x] 柯西分布参数的有效性验证
- [x] 线性变换的数学精确性测试
- [x] CDF 计算的数值准确性

### 第三部分：网络组件测试
- [x] 归因网络的初始化验证
- [x] 行动网络的权重迁移测试
- [x] OvR 阈值的影响分析

### 第四部分：损失函数测试
- [x] 柯西负对数似然的精确计算
- [x] 门控机制的边界情况
- [ ] 梯度流的正确性验证

### 第五部分：端到端集成测试
- [x] 完整前向传播的数值验证
- [x] 从文本到分类损失的完整流程验证
- [x] 从文本到回归损失的完整流程验证
- [x] 总损失函数的精确计算验证
- [x] 采样模式的一致性测试
- [x] 批处理的正确性验证

### 第六部分：实验流程验证
- [x] `basic` 实验完整执行
- [x] 评估指标计算逻辑的精确验证
- [ ] 训练、评估、报告流程健全性

### 第七部分：模块化流程图验证
- [x] 数值感知嵌入 (对应图2)
- [x] 因果核心流程 (对应图3)

### 第八部分：合成数据生成与验证 (Synthetic Data Generation & Validation)
- [ ] 面向混合任务的对话数据生成
- [ ] 覆盖复杂数值模式的样本构造
- [ ] 数据分布的统计学验证

### 第九部分：高级评估指标验证 (Advanced Evaluation Metrics)
- [ ] PICP (预测区间覆盖概率) 的数学一致性
- [ ] ECE (预期校准误差) 的精确计算
- [ ] 敏感性与鲁棒性指标

### 第十部分：对话与交互能力测试 (Conversation & Interaction Capabilities)
- [ ] 多轮对话的上下文一致性
- [ ] 独特采样策略在对话生成中的应用
- [ ] 对话流程的逻辑连贯性


## 测试进展


我已经完成了一系列系统性的单元和集成测试，以确保 CausalQwen 模型核心架构的数学正确性。我的测试进展如下：

1.  **验证了数值嵌入层 (`Numerical Aware Embedding`)**：我首先通过 `test_numerical_aware_embedding.py` 脚本，以流程图的方式验证了从原始文本输入到增强嵌入（`enhanced_embeddings`）的完整转换过程。测试结果表明，数值的提取、编码（`φ(v)`）以及与基础词元嵌入的融合完全符合设计，且只在 `<NUM>` token 的位置生效。

2.  **独立验证了核心网络模块**：接着，我通过 `test_abduction_network.py` 和 `test_action_network.py` 这两个独立的验证脚本，分别对归因网络（Abduction Network）和行动网络（Action Network）进行了白盒测试。结果确认了：
    *   **归因网络**的初始化能够正确实现恒等映射，并为因果尺度（`scale_U`）赋予一个符合预期的、具有高不确定性的柯西先验。
    *   **行动网络**能够成功地从预训练的 `lm_head` 继承知识，并正确地将输入的因果尺度（`scale_U`）线性传递到分类和回归的输出尺度（`scale_S`, `scale_Y`）上。

3.  **验证了核心损失函数**：我通过 `scripts/test_classification_loss.py` 脚本，对核心的 `ovr_classification_loss` 函数进行了白盒测试。通过在脚本内精确复现其数学逻辑，我验证了模型从概率计算到最终损失值的整个流程与数学设计完全一致。

4.  **验证了端到端的核心数据流**：我运行了 `test_causal_core.py`，这个脚本将增强嵌入、特征提取、归因和行动网络串联起来，验证了从 `e` -> `z` -> `U` -> `(S, Y)` 的核心数据流。

5.  **验证了端到端分类流程**：我通过 `test_end_to_end_classification.py` 脚本，完整地展示了从原始文本输入 -> 词元化 -> 标签生成 -> 模型前向传播 -> 分类损失计算的整个生命周期，确认了流程的正确性。

6.  **验证了端到端回归流程**：与分类流程类似，我通过 `test_end_to_end_regression.py` 脚本，验证了从原始文本到门控回归损失计算的全过程。测试明确地展示了只有在 `<NUM>` 词元位置，对应的真实数值才会被用作回归目标，从而验证了门控机制的有效性。

7.  **白盒验证了总损失计算**：通过 `test_total_loss.py` 脚本，我们对 `compute_total_loss` 函数进行了精确的白盒测试。这个测试通过手动复现数学公式，验证了模型实现能够正确地对分类损失和回归损失使用不同的分母进行"分离平均"，确保了总损失的计算与我们修正后的数学文档完全一致。这个过程还帮助我们发现并修复了实现中的一个核心bug。

8.  **系统性分析了 OvR 阈值的影响**：我们通过修改 `test_total_loss.py` 脚本，对 OvR 决策阈值（`ovr_threshold`）进行了一系列实验。实验揭示了一个关键的耦合现象：在"软门控"（`alpha < 1`）模式下，分类阈值的改变会通过门的概率（`P_NUM`）间接影响回归损失的大小。这次深刻的分析促使我们做出了一个重要的设计决策：将默认的门控策略更改为"硬门控"（`reg_loss_gating_alpha=1.0`）。最终的验证实验确认，在硬门控下，分类损失和回归损失实现了完全的计算独立性，极大地增强了模型的可解释性和稳定性。

9.  **全面验证了推理模式与批量处理**：我们通过 `test_deterministic_inference.py`, `test_causal_sampling.py`, `test_compatible_sampling.py` 和 `test_batch_processing.py` 等一系列脚本，系统性地验证了模型的核心推理与数据处理能力。测试确认了：1) **确定性推理**、**因果采样**和**传统兼容采样**三种模式均与数学设计一致；2) 模型的**批量处理**逻辑是稳健的，在合理的数值精度范围内，其结果与单个样本处理完全一致，验证了填充和注意力机制的正确性。

10. **白盒验证了评估指标的计算逻辑**：我们通过 `scripts/test_eval_metrics.py` 脚本，对评估流程中的核心指标（`num_precision`, `num_recall`, `num_f1`, `reg_mae`, `reg_mdae`）进行了严格的白盒测试。该测试通过构建覆盖所有情况（TP, FP, FN）的"黄金"测试集，并与手动计算的期望值进行断言比较。这个过程揭示并修正了一个关键的计算逻辑：**回归误差（MAE/MdAE）只应在模型正确识别出 `<NUM>` 词元（即 True Positives）的位置上计算**。在验证了计算逻辑的正确性后，我们将其无误地集成到了 `src/evaluation/evaluator.py` 中，并重构了 `src/training/trainer.py`，将训练循环和评估循环完全分离，确保了评估指标的计算是在独立的验证集上进行的，从而保证了日志的准确性和清晰度。

## 第二阶段开发与测试：打造具备数值能力的对话模型

根据项目进展和战略规划，我们对第二阶段的核心目标进行聚焦：**将 CausalQwen 打造成一个强大的对话模型，其核心优势在于能够无缝地融合文本处理和数值计算。** 虽然其架构受到因果理论的启发，但当前阶段我们并不追求复杂的反事实推理，而是专注于将模型独特的"分类+回归"双通道输出能力打磨到极致。

我们的工作将围绕以下三个核心方向展开，并为每个方向建立严格的测试标准：

1.  **面向混合任务的合成数据设计 (Synthetic Data for Mixed Tasks)**：设计的核心是创造能够充分挑战模型数值-文本综合能力的对话场景。我们将构造包含复杂数值模式、需要多步计算、以及在对话中引用和操作数值的合成数据集。

2.  **高级模型评估指标 (Advanced Evaluation Metrics)**：我们将继续深入研究并实现更高级的评估指标，用以科学地衡量模型预测的质量。这包括精确验证 **PICP** (预测区间覆盖概率) 和 **ECE** (预期校准误差) 的数学实现，以评估模型对其预测不确定性的感知能力。

3.  **具备数值能力的对话系统开发 (Conversational System with Numerical Abilities)**：此阶段的目标是开发一个流畅的多轮对话系统。我们将重点测试模型在对话上下文中理解、推理和生成包含精确数值内容的能力，并探索如何利用其独特的分布输出与采样策略，生成逻辑连贯且风格一致的回复。

