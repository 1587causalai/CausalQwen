# CausalQwen æµ‹è¯•è„šæœ¬å®Œæ•´è§£è¯»æ–‡æ¡£

> **ğŸ“‹ æ–‡æ¡£ç›®æ ‡**: è¯¦ç»†è§£è¯» `comprehensive_component_test.py` æ¯ä¸ªæµ‹è¯•æ­¥éª¤çš„æ•°å­¦å«ä¹‰å’Œä»£ç éªŒè¯
> **ğŸ¯ éªŒè¯æ ¸å¿ƒ**: ç¡®ä¿æµ‹è¯•å¿ å®æ‰§è¡Œäº† `design-docs/causal_qwen.md` ä¸­çš„ç†è®ºè®¾è®¡
> **ğŸ“– ä½¿ç”¨è¯´æ˜**: æ¯ä¸ªæµ‹è¯•éƒ¨åˆ†éƒ½åŒ…å«ç†è®ºåŸºç¡€ã€å®ç°ç»†èŠ‚å’Œé¢„æœŸéªŒè¯ç»“æœ

## æµ‹è¯•è„šæœ¬æ€»ä½“æ¶æ„

### æµ‹è¯•æµç¨‹å›¾

```mermaid
graph TD
    A["ç¯å¢ƒæ£€æŸ¥"] --> B["æ¨¡å—å¯¼å…¥"]
    B --> C["Qwenæ¨¡å‹åŠ è½½"]
    C --> D["CausalQwené…ç½®"]
    D --> E["æ¨¡å‹ç»„ä»¶æµ‹è¯•"]
    E --> F["ç»„ä»¶å†…éƒ¨æµ‹è¯•"]
    F --> G["æ¨ç†æ¨¡å¼æµ‹è¯•"]
    G --> H["è®­ç»ƒç»„ä»¶æµ‹è¯•"]
    H --> I["ç«¯åˆ°ç«¯éªŒè¯"]
    
    style A fill:#f9f9f9
    style E fill:#fff3e0,stroke:#e65100,stroke-width:2px
    style F fill:#fce4ec,stroke:#d81b60,stroke-width:2px
    style G fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style I fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
```

## ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå’Œä¾èµ–æ£€æŸ¥

### æµ‹è¯•ç›®çš„
éªŒè¯è¿è¡ŒCausalQwenæ‰€éœ€çš„åŸºç¡€ç¯å¢ƒé…ç½®ï¼Œç¡®ä¿æ‰€æœ‰ä¾èµ–é¡¹æ­£ç¡®å®‰è£…ä¸”Qwenæ¨¡å‹æ–‡ä»¶å­˜åœ¨ã€‚

### å…³é”®éªŒè¯ç‚¹

#### 1.1 Pythonç¯å¢ƒæ£€æŸ¥
```python
print_info(f"Pythonç‰ˆæœ¬: {sys.version}")
print_info(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print_info(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
```

**éªŒè¯å†…å®¹**ï¼š
- Pythonç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆæ¨è3.8+ï¼‰
- å·¥ä½œç›®å½•æ­£ç¡®è®¾ç½®
- é¡¹ç›®è·¯å¾„æ·»åŠ åˆ°sys.path

#### 1.2 PyTorchæ£€æŸ¥
```python
import torch
print_success(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print_info(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
```

**éªŒè¯å†…å®¹**ï¼š
- PyTorchç‰ˆæœ¬ï¼ˆæ¨è1.10+ï¼‰
- CUDAå¯ç”¨æ€§ï¼ˆå¯é€‰ä½†æ¨èï¼‰
- è®¾å¤‡é…ç½®ç¡®è®¤

#### 1.3 Qwenæ¨¡å‹è·¯å¾„éªŒè¯
```python
qwen_path = os.path.expanduser('~/models/Qwen2.5-0.5B')
config_file = os.path.join(qwen_path, 'config.json')
model_file = os.path.join(qwen_path, 'pytorch_model.bin')
```

**å…³é”®æ–‡ä»¶æ£€æŸ¥**ï¼š
- `config.json`ï¼šæ¨¡å‹é…ç½®æ–‡ä»¶
- `pytorch_model.bin` æˆ– `model.safetensors`ï¼šæƒé‡æ–‡ä»¶
- `tokenizer.json`ï¼šåˆ†è¯å™¨æ–‡ä»¶

**é¢„æœŸç»“æœ**ï¼šæ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œä¸ºåç»­æµ‹è¯•å¥ å®šåŸºç¡€ã€‚

## ç¬¬äºŒéƒ¨åˆ†ï¼šé¡¹ç›®æ¨¡å—å¯¼å…¥æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯CausalQwen MVPæ¨¡å—çš„æ­£ç¡®å¯¼å…¥å’Œç‰ˆæœ¬ä¿¡æ¯ï¼Œç¡®ä¿æ ¸å¿ƒç±»å¯ç”¨ã€‚

### æ ¸å¿ƒæ¨¡å—å¯¼å…¥
```python
from causal_qwen_mvp import (
    CausalQwenMVPForCausalLM,   # ä¸»æ¨¡å‹ç±»
    CausalQwen2Config,          # é…ç½®ç±»
    CausalInferenceEngine,      # æ¨ç†å¼•æ“
    InferenceValidator,         # æ¨ç†éªŒè¯å™¨
    CausalTrainer,              # è®­ç»ƒå™¨
    get_model_info              # æ¨¡å‹ä¿¡æ¯
)
```

### æ•°å­¦ç†è®ºå¯¹åº”
è¿™äº›æ¨¡å—å®ç°äº†ä»¥ä¸‹ç†è®ºç»„ä»¶ï¼š

| æ¨¡å— | æ•°å­¦è¡¨ç¤º | ç†è®ºä½œç”¨ |
|------|----------|----------|
| `CausalQwenMVPForCausalLM` | $Y = f(U, \epsilon)$ | å®Œæ•´å› æœæ¨¡å‹ |
| `CausalQwen2Config` | è¶…å‚æ•° $\theta$ | æ¨¡å‹é…ç½®å‚æ•° |
| `CausalInferenceEngine` | $P(U\|X)$ æ¨æ–­ | æ¨ç†å¼•æ“ |

### é¢„æœŸç»“æœ
```
âœ… æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ
â„¹ï¸  é¡¹ç›®åç§°: CausalQwen
â„¹ï¸  ç‰ˆæœ¬: MVP v0.1.0
â„¹ï¸  çŠ¶æ€: æ ¸å¿ƒæ¡†æ¶éªŒè¯å®Œæˆ
```

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šåŸå§‹Qwenæ¨¡å‹åŠ è½½æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯èƒ½å¦æ­£ç¡®åŠ è½½é¢„è®­ç»ƒçš„Qwen2.5-0.5Bæ¨¡å‹é…ç½®ï¼Œä¸ºCausalQwenç»§æ‰¿å¥ å®šåŸºç¡€ã€‚

### æ ¸å¿ƒé…ç½®åŠ è½½
```python
from transformers import Qwen2Config, Qwen2ForCausalLM, AutoTokenizer
qwen_path = os.path.expanduser('~/models/Qwen2.5-0.5B')
config = Qwen2Config.from_pretrained(qwen_path)
```

### å…³é”®å‚æ•°éªŒè¯
```python
print_info(f"è¯æ±‡è¡¨å¤§å°: {config.vocab_size}")        # V
print_info(f"éšè—å±‚å¤§å°: {config.hidden_size}")       # H  
print_info(f"å±‚æ•°: {config.num_hidden_layers}")       # L
print_info(f"æ³¨æ„åŠ›å¤´æ•°: {config.num_attention_heads}") # num_heads
```

### æ•°å­¦ç»´åº¦å¯¹åº”

æ ¹æ®è®¾è®¡æ–‡æ¡£ï¼Œè¿™äº›å‚æ•°å®šä¹‰äº†åŸºç¡€æ¶æ„ï¼š

| å‚æ•° | ç¬¦å· | å…¸å‹å€¼ (0.5B) | æ•°å­¦ä½œç”¨ |
|------|------|---------------|----------|
| `vocab_size` | $V$ | 151,936 | è¯æ±‡è¡¨å¤§å° |
| `hidden_size` | $H$ | 896 | éšè—å±‚ç»´åº¦ |
| `num_hidden_layers` | $L$ | 24 | Transformerå±‚æ•° |
| `num_attention_heads` | $h$ | 14 | æ³¨æ„åŠ›å¤´æ•° |

### é¢„æœŸç»“æœ
æˆåŠŸåŠ è½½é…ç½®å¹¶æ˜¾ç¤ºå…³é”®å‚æ•°ï¼Œä¸ºCausalQwené…ç½®åˆ›å»ºæä¾›åŸºç¡€ã€‚

## ç¬¬å››éƒ¨åˆ†ï¼šCausalQwenæ¨¡å‹åˆå§‹åŒ–æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯CausalQwenç‰¹æœ‰é…ç½®çš„åˆ›å»ºå’Œæ¨¡å‹åˆå§‹åŒ–ï¼Œç¡®ä¿å› æœæ‰©å±•å‚æ•°æ­£ç¡®è®¾ç½®ã€‚

### å› æœé…ç½®åˆ›å»º

#### 4.1 é…ç½®å‚æ•°æ˜ å°„
```python
causal_config = CausalQwen2Config(
    vocab_size=qwen_config.vocab_size,           # ç»§æ‰¿Qwenå‚æ•°
    hidden_size=qwen_config.hidden_size,         # H 
    # ... å…¶ä»–Qwenå‚æ•°
    # CausalQwenç‰¹æœ‰å‚æ•°
    causal_size=qwen_config.hidden_size,         # C = H (è®¾è®¡å†³ç­–)
    abduction_init_strategy='identity',          # å½’å› ç½‘ç»œåˆå§‹åŒ–
    b_noise_init=0.1,                          # å¤–ç”Ÿå™ªå£°åˆå§‹å€¼
    gamma_init=10.0                             # Cauchyå°ºåº¦åˆå§‹å€¼
)
```

#### 4.2 æ•°å­¦å‚æ•°æ„ä¹‰

**æ ¸å¿ƒè®¾è®¡å†³ç­–**ï¼š`causal_size = hidden_size` (å³ $C = H$)

æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬2.2èŠ‚ï¼š
- $C$ï¼šå› æœè¡¨å¾ç»´åº¦ï¼Œä¸ªä½“é€‰æ‹©å˜é‡ $U$ çš„ç»´åº¦
- $H$ï¼šéšè—å±‚ç»´åº¦ï¼Œç»§æ‰¿è‡ªQwen
- è®¾ç½® $C = H$ ä¿è¯äº†ç»´åº¦å…¼å®¹æ€§å’Œè¡¨å¾èƒ½åŠ›

**åˆå§‹åŒ–ç­–ç•¥**ï¼š
- `abduction_init_strategy='identity'`ï¼šå½’å› ç½‘ç»œåˆå§‹åŒ–ä¸ºæ’ç­‰æ˜ å°„
- `b_noise_init=0.1`ï¼šå¤–ç”Ÿå™ªå£°å‚æ•° $b_{\text{noise}}$ åˆå§‹å€¼
- `gamma_init=10.0`ï¼šCauchyåˆ†å¸ƒå°ºåº¦å‚æ•°åˆå§‹å€¼

### é¢„æœŸç»“æœ
```
âœ… CausalQwené…ç½®åˆ›å»ºæˆåŠŸ
â„¹ï¸  å› æœç»´åº¦: 896 (= hidden_size)
â„¹ï¸  å½’å› åˆå§‹åŒ–ç­–ç•¥: identity
â„¹ï¸  å™ªå£°å‚æ•°: 0.1
```

## ç¬¬äº”éƒ¨åˆ†ï¼šæ¨¡å‹ç»„ä»¶åŠŸèƒ½æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯å®Œæ•´CausalQwenæ¨¡å‹çš„æˆåŠŸåˆå§‹åŒ–ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶æ­£ç¡®æ„å»ºã€‚

### æ¨¡å‹åˆå§‹åŒ–
```python
CausalQwenMVPForCausalLM = modules['CausalQwenMVPForCausalLM']
model = CausalQwenMVPForCausalLM(causal_config)
```

### æ•°å­¦æ¶æ„éªŒè¯

#### 5.1 æ¨¡å‹ç»„ä»¶ç»“æ„
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬2.1èŠ‚ï¼ŒCausalQwenåŒ…å«ï¼š

```mermaid
graph LR
    A["è¯å…ƒåµŒå…¥<br>[B,S] â†’ [B,S,H]"] --> B["ç‰¹å¾æå–<br>QwenTransformer"]
    B --> C["å½’å› æ¨æ–­<br>[B,S,H] â†’ [B,S,C]Ã—2"]
    C --> D["è¡ŒåŠ¨å†³ç­–<br>[B,S,C] â†’ [B,S,V]Ã—2"]
    D --> E["OvRåˆ†ç±»<br>è¾“å‡ºè¯å…ƒ"]
```

#### 5.2 å‚æ•°ç»Ÿè®¡éªŒè¯
```python
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
```

**ç†è®ºå¯¹æ¯”**ï¼š
- æ ‡å‡†Qwen2.5-0.5Bï¼šçº¦500Må‚æ•°
- CausalQwené¢å¤–å‚æ•°ï¼š
  - å½’å› ç½‘ç»œï¼š$2 \times H \times C = 2H^2$ 
  - è¡ŒåŠ¨ç½‘ç»œï¼š$C \times V + C = C(V+1)$
  - æ€»å¢é‡ï¼šçº¦ $2H^2 + C(V+1)$ å‚æ•°

### é¢„æœŸç»“æœ
```
âœ… CausalQwenæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ
â„¹ï¸  æ€»å‚æ•°æ•°é‡: ~500,XXX,XXX
â„¹ï¸  å¯è®­ç»ƒå‚æ•°: ~500,XXX,XXX
```

## ç¬¬å…­éƒ¨åˆ†ï¼šç»„ä»¶å†…éƒ¨åŠŸèƒ½æµ‹è¯•

### æµ‹è¯•ç›®çš„
æ·±å…¥éªŒè¯å„ä¸ªæ ¸å¿ƒç»„ä»¶çš„æ•°å­¦å®ç°ï¼Œç¡®ä¿ç¬¦åˆç†è®ºè®¾è®¡ã€‚

### 6.1 Cauchyæ•°å­¦å·¥å…·æµ‹è¯•

#### æ•°å­¦ç†è®ºåŸºç¡€
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬1.2.3èŠ‚ï¼ŒæŸ¯è¥¿åˆ†å¸ƒçš„çº¿æ€§ç¨³å®šæ€§ï¼š

**çº¿æ€§ç»„åˆç¨³å®šæ€§**ï¼š
$$\sum_{i=1}^n w_i X_i \sim \text{Cauchy}\left(\sum_{i=1}^n w_i \mu_i, \sum_{i=1}^n |w_i| \gamma_i\right)$$

#### ä»£ç éªŒè¯
```python
from causal_qwen_mvp.models import CauchyMath

# æµ‹è¯•ä½ç½®å‚æ•°å˜æ¢
result_loc = CauchyMath.cauchy_linear_stable_loc(loc_input, weight)
# æµ‹è¯•å°ºåº¦å‚æ•°å˜æ¢  
result_scale = CauchyMath.cauchy_linear_stable_scale(scale_input, weight)
```

**ç»´åº¦éªŒè¯**ï¼š
- è¾“å…¥ï¼š`loc_input` $\in \mathbb{R}^{B \times H}$ï¼Œ`weight` $\in \mathbb{R}^{C \times H}$
- è¾“å‡ºï¼š`result_loc` $\in \mathbb{R}^{B \times C}$

### 6.2 å½’å› æ¨æ–­ç½‘ç»œæµ‹è¯•

#### æ•°å­¦ç†è®ºå¯¹åº”
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬3.3èŠ‚ï¼Œå½’å› æ¨æ–­å®ç°ï¼š

$$\text{loc}_{U_i} = W_{\text{loc}} \cdot z_i + b_{\text{loc}}$$
$$\text{scale}_{U_i} = \text{softplus}(W_{\text{scale}} \cdot z_i + b_{\text{scale}})$$

#### ä»£ç éªŒè¯
```python
test_input = torch.randn(batch_size, seq_len, hidden_size)  # [B, S, H]
with torch.no_grad():
    loc_U, scale_U = model.abduction_network(test_input)
```

**ç»´åº¦æ£€æŸ¥**ï¼š
- è¾“å…¥ï¼š`[B, S, H]` ä¸Šä¸‹æ–‡ç‰¹å¾
- è¾“å‡ºï¼š`loc_U` $\in \mathbb{R}^{B \times S \times C}$ï¼Œ`scale_U` $\in \mathbb{R}^{B \times S \times C}$

**æ•°å­¦è¯­ä¹‰**ï¼š
- `loc_U`ï¼šä¸ªä½“ç¾¤ä½“çš„å…¸å‹ä»£è¡¨
- `scale_U`ï¼šç¾¤ä½“å†…éƒ¨å¤šæ ·æ€§ï¼ˆä¸ç¡®å®šæ€§ï¼‰

### 6.3 è¡ŒåŠ¨å†³ç­–ç½‘ç»œæµ‹è¯•

#### æ•°å­¦ç†è®ºå¯¹åº”
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬3.4èŠ‚ï¼Œçº¿æ€§å› æœå¾‹ï¼š

**å¤–ç”Ÿå™ªå£°èåˆ**ï¼š
$$U'_i = U_i + \epsilon \sim \text{Cauchy}(\text{loc}_{U_i}, \text{scale}_{U_i} + |b_{\text{noise}}|)$$

**çº¿æ€§å†³ç­–**ï¼š
$$S_{k,i} = W_{\text{cls},k} \cdot U'_i + b_{\text{cls},k}$$

#### ä»£ç éªŒè¯
```python
with torch.no_grad():
    loc_U, scale_U = model.abduction_network(test_input)
    action_loc, action_scale = model.action_network(loc_U, scale_U)
```

**ç»´åº¦éªŒè¯**ï¼š
- è¾“å…¥ï¼š`loc_U`, `scale_U` $\in \mathbb{R}^{B \times S \times C}$
- è¾“å‡ºï¼š`action_loc`, `action_scale` $\in \mathbb{R}^{B \times S \times V}$

### é¢„æœŸç»“æœ
```
âœ… Cauchyä½ç½®å˜æ¢æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: [B, C]
âœ… Cauchyå°ºåº¦å˜æ¢æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: [B, C]
âœ… å½’å› ç½‘ç»œæµ‹è¯•é€šè¿‡
â„¹ï¸  è¾“å…¥å½¢çŠ¶: [2, 10, 896]
â„¹ï¸  loc_Uè¾“å‡ºå½¢çŠ¶: [2, 10, 896]
â„¹ï¸  scale_Uè¾“å‡ºå½¢çŠ¶: [2, 10, 896]
âœ… è¡ŒåŠ¨ç½‘ç»œæµ‹è¯•é€šè¿‡
â„¹ï¸  loc_Sè¾“å‡ºå½¢çŠ¶: [2, 10, 151936]
â„¹ï¸  scale_Sè¾“å‡ºå½¢çŠ¶: [2, 10, 151936]
```

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ¨ç†æ¨¡å¼æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯CausalQwençš„ä¸‰ç§æ¨ç†æ¨¡å¼æ˜¯å¦ç¬¦åˆè®¾è®¡æ–‡æ¡£ç¬¬5èŠ‚çš„ç†è®ºæ¡†æ¶ã€‚

### 7.1 æ ‡å‡†æ¨ç†æ¨¡å¼

#### æ•°å­¦ç†è®ºåŸºç¡€
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬5.1èŠ‚ï¼Œæ ‡å‡†æ¨ç†åŸºäºåˆ†å¸ƒæœŸæœ›ï¼š

$$P_k = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_k} - C_{\text{ovr}}}{\text{scale}_{S_k}}\right)$$

#### ä»£ç éªŒè¯
```python
with torch.no_grad():
    standard_output = model.inference(test_input_ids, mode='standard')
```

**è¾“å‡ºç»“æ„**ï¼š
- `standard_output.loc_S`ï¼šå†³ç­–åˆ†å¸ƒä½ç½®å‚æ•° $\in \mathbb{R}^{B \times S \times V}$
- `standard_output.scale_S`ï¼šå†³ç­–åˆ†å¸ƒå°ºåº¦å‚æ•° $\in \mathbb{R}^{B \times S \times V}$

**æ•°å­¦è¯­ä¹‰**ï¼šæ¯ä¸ªè¯æ±‡ $k$ çš„å†³ç­–åˆ†å¸ƒ $S_k \sim \text{Cauchy}(\text{loc}_{S_k}, \text{scale}_{S_k})$

### 7.2 å› æœæ¨ç†æ¨¡å¼

#### æ•°å­¦ç†è®ºåŸºç¡€
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬5.2èŠ‚ï¼Œå› æœæ¨ç†è¾“å‡ºä¸ªä½“åéªŒåˆ†å¸ƒï¼š

$$U_i \sim \text{Cauchy}(\text{loc}_{U_i}, \text{scale}_{U_i})$$

#### ä»£ç éªŒè¯
```python
with torch.no_grad():
    causal_output = model.inference(test_input_ids, mode='causal')
```

**è¾“å‡ºç»“æ„**ï¼š
- `causal_output.loc_U`ï¼šä¸ªä½“ç¾¤ä½“ä¸­å¿ƒ $\in \mathbb{R}^{B \times S \times C}$
- `causal_output.scale_U`ï¼šä¸ªä½“ç¾¤ä½“å¤šæ ·æ€§ $\in \mathbb{R}^{B \times S \times C}$

**åº”ç”¨åœºæ™¯**ï¼šä¸ªä½“é‡‡æ ·ã€ä¸€è‡´æ€§ç”Ÿæˆã€åäº‹å®æ¨ç†

### 7.3 å…¼å®¹æ¨ç†æ¨¡å¼

#### æ•°å­¦ç†è®ºåŸºç¡€
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬5.3èŠ‚ï¼Œå…¼å®¹æ¨¡å¼åŒæ—¶è¾“å‡ºæ‰€æœ‰ä¿¡æ¯ï¼š

- ä¸ªä½“åˆ†å¸ƒå‚æ•°ï¼š$(\text{loc}_U, \text{scale}_U)$
- å†³ç­–åˆ†å¸ƒå‚æ•°ï¼š$(\text{loc}_S, \text{scale}_S)$
- ä¼ ç»ŸSoftmaxæ¦‚ç‡ï¼š$P_{\text{softmax}}(k) = \frac{\exp(\text{loc}_{S_k})}{\sum_j \exp(\text{loc}_{S_j})}$

#### ä»£ç éªŒè¯
```python
with torch.no_grad():
    compatible_output = model.inference(test_input_ids, mode='compatible')
```

### æ¨ç†æ¨¡å¼å¯¹æ¯”è¡¨

| æ¨¡å¼ | è¾“å‡ºå†…å®¹ | æ•°å­¦è¡¨ç¤º | åº”ç”¨åœºæ™¯ |
|------|----------|----------|----------|
| `standard` | å†³ç­–åˆ†å¸ƒå‚æ•° | $(\text{loc}_S, \text{scale}_S)$ | é«˜æ•ˆç¡®å®šæ€§æ¨ç† |
| `causal` | ä¸ªä½“åˆ†å¸ƒå‚æ•° | $(\text{loc}_U, \text{scale}_U)$ | å› æœé‡‡æ ·ï¼Œä¸€è‡´æ€§ç”Ÿæˆ |
| `compatible` | å…¨éƒ¨ä¿¡æ¯ | ä¸Šè¿°ä¸¤è€… + ä¼ ç»Ÿæ¦‚ç‡ | æ··åˆæ¨ç†ç­–ç•¥ |

### é¢„æœŸç»“æœ
```
âœ… æ ‡å‡†æ¨ç†æ¨¡å¼æµ‹è¯•é€šè¿‡
â„¹ï¸  è¾“å‡ºloc_Så½¢çŠ¶: [1, 8, 151936]
â„¹ï¸  è¾“å‡ºscale_Så½¢çŠ¶: [1, 8, 151936]
âœ… å› æœæ¨ç†æ¨¡å¼æµ‹è¯•é€šè¿‡  
â„¹ï¸  è¾“å‡ºloc_Uå½¢çŠ¶: [1, 8, 896]
â„¹ï¸  è¾“å‡ºscale_Uå½¢çŠ¶: [1, 8, 896]
âœ… å…¼å®¹æ¨ç†æ¨¡å¼æµ‹è¯•é€šè¿‡
â„¹ï¸  è¾“å‡ºåŒ…å«æ‰€æœ‰å­—æ®µ
```

## ç¬¬å…«éƒ¨åˆ†ï¼šè®­ç»ƒç»„ä»¶æµ‹è¯•

### æµ‹è¯•ç›®çš„
éªŒè¯CausalQwençš„è®­ç»ƒæœºåˆ¶ï¼ŒåŒ…æ‹¬æŸå¤±è®¡ç®—å’Œæ¢¯åº¦ä¼ æ’­ã€‚

### 8.1 æŸå¤±è®¡ç®—æµ‹è¯•

#### æ•°å­¦ç†è®ºåŸºç¡€
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬4.2èŠ‚ï¼Œå®Œæ•´æŸå¤±è®¡ç®—ï¼š

**OvRæ¦‚ç‡è®¡ç®—**ï¼š
$$P_{k,i} = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_{k,i}} - C_{\text{ovr}}}{\text{scale}_{S_{k,i}}}\right)$$

**äºŒå…ƒäº¤å‰ç†µæŸå¤±**ï¼š
$$L_{\text{cls},i} = -\sum_{k=1}^V [y_{k,i} \log P_{k,i} + (1-y_{k,i}) \log(1-P_{k,i})] \cdot \text{mask}_i$$

**æ€»æŸå¤±**ï¼š
$$\mathcal{L} = \frac{\sum_{i=1}^S L_{\text{cls},i}}{\sum_{i=1}^S \text{mask}_i}$$

#### ä»£ç éªŒè¯
```python
input_ids = torch.randint(0, min(model.config.vocab_size, 1000), (batch_size, seq_len))
targets = torch.randint(0, min(model.config.vocab_size, 1000), (batch_size, seq_len))

model.train()
with torch.enable_grad():
    output = model.forward(input_ids, labels=targets)
```

**å…³é”®éªŒè¯ç‚¹**ï¼š
- æŸå¤±å€¼éç©ºä¸”æœ‰é™
- æ”¯æŒæ©ç å¤„ç†ï¼ˆå¿½ç•¥paddingä½ç½®ï¼‰
- OvRåˆ†ç±»æœºåˆ¶æ­£ç¡®å®ç°

### 8.2 æ¢¯åº¦è®¡ç®—æµ‹è¯•

#### æ•°å­¦ç†è®º
éªŒè¯åå‘ä¼ æ’­èƒ½å¦æ­£ç¡®è®¡ç®—æ¢¯åº¦ï¼š

$$\frac{\partial \mathcal{L}}{\partial \theta} = \frac{\partial \mathcal{L}}{\partial P} \frac{\partial P}{\partial S} \frac{\partial S}{\partial \theta}$$

å…¶ä¸­ï¼š
- $\theta$ï¼šæ¨¡å‹å‚æ•°ï¼ˆå½’å› ç½‘ç»œã€è¡ŒåŠ¨ç½‘ç»œæƒé‡ï¼‰
- $S$ï¼šå†³ç­–åˆ†å¸ƒå‚æ•°
- $P$ï¼šOvRæ¦‚ç‡

#### ä»£ç éªŒè¯
```python
if output.loss is not None:
    output.loss.backward()
    
    grad_count = 0
    for name, param in model.named_parameters():
        if param.grad is not None:
            grad_count += 1
```

### é¢„æœŸç»“æœ
```
âœ… æŸå¤±è®¡ç®—æµ‹è¯•é€šè¿‡
â„¹ï¸  æŸå¤±å€¼: 7.234567
âœ… æ¢¯åº¦è®¡ç®—æµ‹è¯•é€šè¿‡ï¼ŒXXXä¸ªå‚æ•°æœ‰æ¢¯åº¦
â„¹ï¸  abduction_network.loc_net.weight: æ¢¯åº¦èŒƒæ•°=0.001234
â„¹ï¸  abduction_network.scale_net.weight: æ¢¯åº¦èŒƒæ•°=0.002345
â„¹ï¸  action_network.lm_head.weight: æ¢¯åº¦èŒƒæ•°=0.003456
```

## ç¬¬ä¹éƒ¨åˆ†ï¼šæ–‡æœ¬ç”Ÿæˆå¯¹æ¯”éªŒè¯

### æµ‹è¯•ç›®çš„
é€šè¿‡çœŸå®æ–‡æœ¬è¾“å…¥ï¼Œå®Œæ•´å±•ç¤ºä»åŸå§‹æ–‡æœ¬åˆ°ä¸ªä½“å› æœè¡¨å¾å†åˆ°ç”Ÿæˆè¾“å‡ºçš„å…¨æµç¨‹ï¼Œå¹¶å¯¹æ¯”CausalQwenä¸‰ç§æ¨ç†æ¨¡å¼ä¸ä¼ ç»ŸQwençš„å·®å¼‚ã€‚

### 9.1 åˆ†è¯å™¨åŠ è½½ä¸æ–‡æœ¬å¤„ç†

#### ä»£ç éªŒè¯
```python
from transformers import AutoTokenizer
qwen_path = os.path.expanduser('~/models/Qwen2.5-0.5B')
tokenizer = AutoTokenizer.from_pretrained(qwen_path)

test_texts = [
    "The quick brown fox",
    "Once upon a time", 
    "In the year 2024",
    "Artificial intelligence is"
]
```

**éªŒè¯å†…å®¹**ï¼š
- æˆåŠŸåŠ è½½Qwenåˆ†è¯å™¨
- æ–‡æœ¬åˆ°token_idsçš„è½¬æ¢
- è¯æ±‡è¡¨å…¼å®¹æ€§æ£€æŸ¥

### 9.2 ä¸ªä½“å› æœè¡¨å¾æ¨æ–­éªŒè¯

#### æ•°å­¦ç†è®ºåŸºç¡€
å®Œæ•´å±•ç¤ºè®¾è®¡æ–‡æ¡£ç¬¬3.3èŠ‚çš„å½’å› æ¨æ–­è¿‡ç¨‹ï¼š

**æ­¥éª¤1ï¼šæ–‡æœ¬ç¼–ç **
$$\text{input\_text} \rightarrow \text{tokenize} \rightarrow \text{input\_ids} \in \mathbb{Z}^S$$

**æ­¥éª¤2ï¼šè¯å…ƒåµŒå…¥**
$$\text{input\_ids} \rightarrow \text{embed\_tokens} \rightarrow e \in \mathbb{R}^{S \times H}$$

**æ­¥éª¤3ï¼šä¸Šä¸‹æ–‡ç‰¹å¾æå–**
$$e \rightarrow \text{QwenTransformer} \rightarrow z \in \mathbb{R}^{S \times H}$$

**æ­¥éª¤4ï¼šä¸ªä½“ç¾¤ä½“æ¨æ–­**
$$z \rightarrow \text{AbductionNetwork} \rightarrow (\text{loc}_U, \text{scale}_U) \in \mathbb{R}^{S \times C} \times \mathbb{R}^{S \times C}$$

#### ä»£ç éªŒè¯
```python
# æ–‡æœ¬è½¬token
input_ids = tokenizer.encode(test_text, return_tensors='pt')
# ä¸ªä½“è¡¨å¾æ¨æ–­
causal_output = mini_model.inference(limited_input_ids, mode='causal')
```

**å…³é”®è§‚å¯Ÿç‚¹**ï¼š
- ä¸ªä½“è¡¨å¾ç»´åº¦ï¼š`[batch_size, seq_len, causal_size]`
- ä½ç½®å‚æ•° `loc_U`ï¼šä¸ªä½“ç¾¤ä½“çš„å…¸å‹ä»£è¡¨
- å°ºåº¦å‚æ•° `scale_U`ï¼šä¸ªä½“ç¾¤ä½“çš„å¤šæ ·æ€§/ä¸ç¡®å®šæ€§
- ä¸åŒæ–‡æœ¬äº§ç”Ÿä¸åŒçš„ä¸ªä½“è¡¨å¾åˆ†å¸ƒ

### 9.3 ä¸‰ç§æ¨ç†æ¨¡å¼å¯¹æ¯”éªŒè¯

#### 9.3.1 æ ‡å‡†æ¨ç†æ¨¡å¼ï¼ˆæœŸæœ›å†³ç­–ï¼‰

è¿™æ˜¯é»˜è®¤çš„ã€æœ€é«˜æ•ˆçš„æ¨ç†æ¨¡å¼ã€‚å®ƒå®Œå…¨åŸºäºè§£æè®¡ç®—ï¼Œä¸æ¶‰åŠä»»ä½•éšæœºé‡‡æ ·ã€‚ç›®æ ‡æ˜¯ç»™å‡ºç»¼åˆè€ƒè™‘æ‰€æœ‰ä¸ç¡®å®šæ€§åçš„æœŸæœ›é¢„æµ‹ã€‚

**æ•°å­¦åŸç†**ï¼šé€‰æ‹©OvRæ¦‚ç‡æœ€é«˜çš„ç±»åˆ«
$$\hat{y}_{\text{cls},i} = \arg\max_k P_{k,i}$$

å…¶ä¸­OvRæ¦‚ç‡é€šè¿‡æ ‡å‡†åŒ–å¾—åˆ†è®¡ç®—ï¼š
$$P_{k,i} = \frac{1}{2} + \frac{1}{\pi} \arctan\left(\frac{\text{loc}_{S_{k,i}} - C_{\text{ovr}}}{\text{scale}_{S_{k,i}}}\right)$$

**æ ¸å¿ƒç‰¹ç‚¹**ï¼šåŸºäºåˆ†å¸ƒæœŸæœ›çš„ç¡®å®šæ€§å†³ç­–ï¼Œæ— éœ€é‡‡æ ·ï¼Œè®¡ç®—é«˜æ•ˆã€‚

#### 9.3.2 å› æœé‡‡æ ·ï¼ˆä¸ªä½“å…·ç°ï¼‰

è¿™æ˜¯ä¸€ç§æ··åˆäº†éšæœºæ€§ä¸ç¡®å®šæ€§çš„é«˜çº§æ¨ç†æ¨¡å¼ï¼Œæ·±åˆ»ä½“ç°äº†æ¨¡å‹çš„å› æœå“²å­¦ã€‚è¿‡ç¨‹åˆ†ä¸ºä¸‰æ­¥ï¼š

1. **é‡‡æ ·ä¸ªä½“**: ä»åéªŒåˆ†å¸ƒ $U_i \sim \text{Cauchy}(\text{loc}_{U_i}, \text{scale}_{U_i})$ ä¸­é‡‡æ ·å…·ä½“çš„ä¸ªä½“è¡¨å¾ $u_i$ã€‚

2. **æ„å»ºå†³ç­–è¾“å…¥åˆ†å¸ƒ**: å°†ç¡®å®šçš„ä¸ªä½“ $u_i$ ä¸å™ªå£°åˆ†å¸ƒç»“åˆï¼š
   $$ U'_{\text{input}, i} \sim \text{Cauchy}(u_i, |b_{\text{noise}}|) $$

3. **è®¡ç®—ç¡®å®šæ€§å†³ç­–**:  $\arg\max_k P_{k,i}$ã€‚

**æ ¸å¿ƒæ€æƒ³**: åªåœ¨"ä¸ªä½“é€‰æ‹©"æ­¥éª¤å¼•å…¥éšæœºæ€§ï¼Œè€Œå°†"ç¯å¢ƒå™ªå£°"ä¿æŒä¸ºåˆ†å¸ƒå½¢å¼ï¼Œå®ç°å¯¹ä¸åŒä¸ªä½“çš„æ¢ç´¢åŒæ—¶ä¿æŒå†³ç­–çš„ç¨³å¥æ€§ã€‚

#### 9.3.3 å…¼å®¹ä¼ ç»Ÿé‡‡æ ·

CausalQwen å®Œå…¨å…¼å®¹ä¼ ç»Ÿè¯­è¨€æ¨¡å‹çš„é‡‡æ ·æ–¹æ³•ï¼š

**å…¼å®¹æ€§å…¬å¼**ï¼š
$$P_{\text{softmax}}(y_i=k|x) = \frac{\exp(\text{loc}_{S_{k,i}})}{\sum_{j=1}^{V} \exp(\text{loc}_{S_{j,i}})}$$

è¿™ç§æ¨¡å¼ä½¿ç”¨æ ‡å‡†çš„Softmaxæ¦‚ç‡åˆ†å¸ƒï¼Œæ”¯æŒTop-k/Top-pé‡‡æ ·ç­–ç•¥ï¼Œå®Œå…¨å…¼å®¹ä¼ ç»Ÿè¯­è¨€æ¨¡å‹çš„ç”Ÿæˆæ–¹å¼ã€‚

#### ä»£ç éªŒè¯ï¼ˆåŸºäºå·²å®ç°çš„inference.pyï¼‰
```python
# ä½¿ç”¨CausalInferenceEngineè¿›è¡Œæ¨ç†
engine = CausalInferenceEngine(mini_model)

# æ ‡å‡†æ¨ç†ï¼ˆç¡®å®šæ€§OvRï¼‰
standard_output = engine.inference(limited_input_ids, mode='standard')
# å†…éƒ¨è‡ªåŠ¨è®¡ç®—OvRæ¦‚ç‡ï¼Œæ— éœ€æ‰‹åŠ¨è®¡ç®—

# å› æœæ¨ç†ï¼ˆä¸ªä½“å…·ç°ä¸‰æ­¥æ³•ï¼‰
causal_output = engine.inference(limited_input_ids, mode='causal', temperature=1.0)
# å†…éƒ¨å®ç°ï¼š
# 1. é‡‡æ ·ä¸ªä½“: u ~ Cauchy(loc_U, temperature * scale_U)
# 2. ActionNetworkå¤„ç†: å™ªå£°èåˆ + çº¿æ€§ç¨³å®šæ€§å˜æ¢
# 3. è¿”å›æ›´æ–°åçš„åˆ†å¸ƒå‚æ•°

# å…¼å®¹æ¨ç†ï¼ˆä¼ ç»ŸSoftmax + Top-k/Top-pé‡‡æ ·ï¼‰
compatible_output = engine.inference(limited_input_ids, mode='compatible', 
                                   do_sample=True, top_k=50, top_p=0.9, temperature=1.0)
# å†…éƒ¨ä½¿ç”¨loc_Sä½œä¸ºlogitsï¼Œåº”ç”¨ä¼ ç»Ÿé‡‡æ ·ç­–ç•¥
```

### 9.4 åºåˆ—ç”Ÿæˆå¯¹æ¯”æµ‹è¯•

#### æ•°å­¦ç†è®ºï¼šè‡ªå›å½’å› æœç”Ÿæˆ
æ ¹æ®è®¾è®¡æ–‡æ¡£ç¬¬6èŠ‚ï¼ŒCausalQwenæ”¯æŒå¤šç§åºåˆ—ç”Ÿæˆæ¨¡å¼ï¼š

**æ ‡å‡†åºåˆ—ç”Ÿæˆ**ï¼š
$$y_t = \arg\max_k P_k(y_t | y_{<t})$$

**å› æœåºåˆ—ç”Ÿæˆ**ï¼ˆå…±äº«ä¸ªä½“ï¼‰ï¼š
$$u \sim P(U | y_{<t}), \quad y_t = f(u, \epsilon_t)$$

**ä¸€è‡´æ€§ç”Ÿæˆ**ï¼ˆå›ºå®šä¸ªä½“ï¼‰ï¼š
$$u = \text{fixed}, \quad \forall t: y_t = f(u, \epsilon_t)$$

#### ä»£ç éªŒè¯ï¼ˆä½¿ç”¨å·²å®ç°çš„ç”Ÿæˆæ–¹æ³•ï¼‰
```python
initial_seq = torch.randint(0, 100, (1, 3))
engine = CausalInferenceEngine(mini_model)

# ä½¿ç”¨å·²å®ç°çš„generate_step_by_stepæ–¹æ³•
generated_standard = engine.generate_step_by_step(
    initial_seq, max_new_tokens=3, mode='standard'
)

generated_causal = engine.generate_step_by_step(
    initial_seq, max_new_tokens=3, mode='causal', temperature=1.0
)

generated_compatible = engine.generate_step_by_step(
    initial_seq, max_new_tokens=3, mode='compatible_sample',
    temperature=1.0, top_k=50, top_p=0.9
)

# åˆ†æå·®å¼‚
print(f"åˆå§‹åºåˆ—: {initial_seq}")
print(f"æ ‡å‡†ç”Ÿæˆ: {generated_standard}")
print(f"å› æœç”Ÿæˆ: {generated_causal}")
print(f"å…¼å®¹ç”Ÿæˆ: {generated_compatible}")
```

### âš ï¸ é‡è¦Bugä¿®å¤è¯´æ˜

åœ¨2025-01-17çš„æµ‹è¯•ä¸­å‘ç°äº†å…¼å®¹æ¨¡å¼çš„ä¸¥é‡å®ç°é”™è¯¯ï¼š

**åŸå§‹Bug**ï¼š`_compatible_sampling` æ–¹æ³•åœ¨ç¬¬79è¡Œç›´æ¥è¿”å›CausalQwenåŸç”Ÿè¾“å‡ºï¼Œå¯¼è‡´ï¼š
- å…¼å®¹æ¨¡å¼å®é™…è¿”å› `loc_S`ï¼ˆCausalQwençš„OvRè¾“å‡ºï¼‰
- ä¼ ç»ŸSoftmax+é‡‡æ ·é€»è¾‘è¢«bypass
- æ ‡å‡†æ¨¡å¼å’Œå…¼å®¹æ¨¡å¼é”™è¯¯åœ°çœ‹èµ·æ¥"ä¸€è‡´"

**ä¿®å¤å†…å®¹**ï¼š
1. ç§»é™¤æ—©æœŸçš„ `return outputs` è¯­å¥
2. å®ç°çœŸæ­£çš„ `softmax(loc_S/temperature)` + top-k/top-pé‡‡æ ·
3. å…¼å®¹æ¨¡å¼ç°åœ¨æ­£ç¡®æ¨¡æ‹Ÿä¼ ç»ŸQwençš„è¡Œä¸º
4. æ·»åŠ  `next_token_ids` å­—æ®µåˆ° `CausalMVPOutput`

**éªŒè¯è¦ç‚¹**ï¼š
- âœ… **å…¼å®¹æ¨¡å¼åº”è¯¥ä¸æ ‡å‡†æ¨¡å¼è¾“å‡ºä¸åŒ**
- âœ… **å…¼å®¹æ¨¡å¼ä½¿ç”¨ä¼ ç»ŸSoftmaxæ¦‚ç‡**
- âœ… **æ ‡å‡†æ¨¡å¼ä½¿ç”¨CausalQwen OvRåˆ†ç±»**

### é¢„æœŸéªŒè¯ç»“æœ

#### 9.4.1 ä¸ªä½“è¡¨å¾éªŒè¯
```
â„¹ï¸  æµ‹è¯•æ–‡æœ¬ 1: 'ä»Šå¤©å¤©æ°”å¾ˆå¥½'
â„¹ï¸  Token IDs: [[4170, 6135, 15823, 26620, 4509]]
â„¹ï¸  ä¸ªä½“è¡¨å¾: [1, 5, 64], å‡å€¼=0.123, ä¸ç¡®å®šæ€§=0.567
```

#### 9.4.2 æ¨ç†æ¨¡å¼å¯¹æ¯”
```
â„¹ï¸  é¢„æµ‹ç»“æœ: æ ‡å‡†='ï¼Œ' | å› æœ='å¾ˆ' | å…¼å®¹='çš„'
âœ… ä¸‰ç§æ¨¡å¼äº§ç”Ÿä¸åŒè¾“å‡ºï¼ˆç†æƒ³çŠ¶æ€ï¼‰
```

#### 9.4.3 åºåˆ—ç”Ÿæˆå¯¹æ¯”
```
â„¹ï¸  åˆå§‹åºåˆ—: [[12, 45, 78]]
â„¹ï¸  ç”Ÿæˆå¯¹æ¯”: æ ‡å‡†[23, 67, 89] vs å› æœ[24, 68, 91] 
â„¹ï¸  åºåˆ—å·®å¼‚: 3/3 ä¸ªä½ç½®
âœ… å› æœæ¨ç†ä½“ç°äº†ä¸ªä½“å·®å¼‚
```

### 9.5 å…³é”®éªŒè¯ç‚¹æ€»ç»“

#### æ¶æ„éªŒè¯
- [ ] æ–‡æœ¬æˆåŠŸè½¬æ¢ä¸ºtoken_ids
- [ ] ä¸ªä½“è¡¨å¾ç»´åº¦æ­£ç¡®ï¼š`[B, S, C]`
- [ ] ä¸‰ç§æ¨ç†æ¨¡å¼éƒ½èƒ½æ­£å¸¸è¿è¡Œ
- [ ] **å…¼å®¹æ¨¡å¼ä¸æ ‡å‡†æ¨¡å¼è¾“å‡ºä¸åŒ**ï¼ˆä½¿ç”¨ä¸åŒçš„æ•°å­¦æ¡†æ¶ï¼‰

#### æ•°å­¦éªŒè¯  
- [ ] ä¸ªä½“è¡¨å¾åˆ†å¸ƒå‚æ•°åˆç†ï¼ˆæœ‰é™å€¼ï¼Œscale > 0ï¼‰
- [ ] å› æœé‡‡æ ·äº§ç”Ÿä¸åŒè¾“å‡ºï¼ˆä½“ç°ä¸ªä½“å·®å¼‚ï¼‰
- [ ] åºåˆ—ç”Ÿæˆä¿æŒè‡ªå›å½’ç‰¹æ€§
- [ ] OvRæ¦‚ç‡åœ¨[0,1]èŒƒå›´å†…

#### è¡Œä¸ºéªŒè¯
- [ ] ä¸åŒæ–‡æœ¬äº§ç”Ÿä¸åŒä¸ªä½“è¡¨å¾
- [ ] å› æœæ¨ç†çš„éšæœºæ€§å¯æ§
- [ ] ç”Ÿæˆåºåˆ—å…·æœ‰åˆç†å¤šæ ·æ€§
- [ ] ä¸ä¼ ç»ŸLMçš„å…¼å®¹æ€§

## ç¬¬åéƒ¨åˆ†ï¼šç«¯åˆ°ç«¯åŠŸèƒ½éªŒè¯

### æµ‹è¯•ç›®çš„
é€šè¿‡åˆ›å»ºæœ€å°æ¨¡å‹è¿›è¡Œå¿«é€Ÿçš„ç«¯åˆ°ç«¯åŠŸèƒ½éªŒè¯ï¼Œç¡®ä¿æ•´ä¸ªæµç¨‹å¯æ­£å¸¸è¿è¡Œã€‚

### 9.1 æœ€å°æ¨¡å‹åˆ›å»º

#### é…ç½®è®¾è®¡
```python
mini_config = CausalQwen2Config(
    vocab_size=100,      # å°è¯æ±‡è¡¨
    hidden_size=64,      # å°éšè—å±‚
    intermediate_size=256,
    num_hidden_layers=2, # å°‘å±‚æ•°
    num_attention_heads=4,
    causal_size=64       # C = H
)
```

**è®¾è®¡ç›®æ ‡**ï¼š
- ä¿æŒæ¶æ„å®Œæ•´æ€§
- é™ä½è®¡ç®—å¼€é”€
- å¿«é€ŸéªŒè¯åŠŸèƒ½

### 9.2 ä¸‰æ¨¡å¼å¿«é€Ÿæµ‹è¯•

#### éªŒè¯æµç¨‹
```python
test_ids = torch.randint(0, 100, (1, 5))  # [1, 5] è¾“å…¥

with torch.no_grad():
    output1 = mini_model.inference(test_ids, mode='standard')   
    output2 = mini_model.inference(test_ids, mode='causal')     
    output3 = mini_model.inference(test_ids, mode='compatible') 
```

#### æ•°å­¦éªŒè¯ç‚¹

1. **ç»´åº¦ä¸€è‡´æ€§**ï¼š
   - `standard`: è¾“å‡º `(loc_S, scale_S)` âˆˆ $\mathbb{R}^{1 \times 5 \times 100}$
   - `causal`: è¾“å‡º `(loc_U, scale_U)` âˆˆ $\mathbb{R}^{1 \times 5 \times 64}$
   - `compatible`: åŒ…å«ä¸Šè¿°æ‰€æœ‰è¾“å‡º

2. **æ•°å€¼åˆç†æ€§**ï¼š
   - æ‰€æœ‰è¾“å‡ºä¸ºæœ‰é™å€¼ï¼ˆæ— NaN/Infï¼‰
   - å°ºåº¦å‚æ•°ä¸ºæ­£å€¼
   - æ¦‚ç‡åœ¨[0,1]èŒƒå›´å†…

### é¢„æœŸç»“æœ
```
âœ… æœ€å°æ¨¡å‹åˆ›å»ºæˆåŠŸ
âœ… ä¸‰ç§æ¨¡å¼éƒ½èƒ½æ­£å¸¸è¿è¡Œ
â„¹ï¸  ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ
```

## æµ‹è¯•æ€»ç»“ä¸éªŒè¯æ¸…å•

### æ ¸å¿ƒæ•°å­¦éªŒè¯æ¸…å•

- [ ] **å› æœæ¡†æ¶**: $Y = f(U, \epsilon)$ æ­£ç¡®å®ç°
- [ ] **å½’å› æ¨æ–­**: $U \sim \text{Cauchy}(\mu, \gamma)$ åˆ†å¸ƒå‚æ•°æ¨æ–­
- [ ] **çº¿æ€§å› æœå¾‹**: $S = W \cdot U + b$ çº¿æ€§å˜æ¢
- [ ] **æŸ¯è¥¿ç¨³å®šæ€§**: çº¿æ€§ç»„åˆä¿æŒåˆ†å¸ƒæ—ä¸å˜
- [ ] **OvRåˆ†ç±»**: ç‹¬ç«‹äºŒå…ƒåˆ¤æ–­æœºåˆ¶
- [ ] **ä¸‰ç§æ¨ç†æ¨¡å¼**: standard/causal/compatible å…¨éƒ¨å¯ç”¨

### æ¶æ„è®¾è®¡éªŒè¯æ¸…å•

- [ ] **ç»´åº¦è®¾è®¡**: $C = H$ å› æœç»´åº¦ç­‰äºéšè—ç»´åº¦
- [ ] **æ¨¡å—åˆ†ç¦»**: å½’å› æ¨æ–­ + è¡ŒåŠ¨å†³ç­–çš„æ¸…æ™°åˆ†å·¥
- [ ] **æƒé‡ç»§æ‰¿**: èƒ½å¤Ÿç»§æ‰¿é¢„è®­ç»ƒQwenæƒé‡
- [ ] **è®­ç»ƒæ”¯æŒ**: æŸå¤±è®¡ç®—å’Œæ¢¯åº¦ä¼ æ’­æ­£å¸¸
- [ ] **ç”Ÿæˆæ”¯æŒ**: è‡ªå›å½’åºåˆ—ç”Ÿæˆèƒ½åŠ›

### å®ç°è´¨é‡éªŒè¯æ¸…å•

- [ ] **æ•°å€¼ç¨³å®šæ€§**: æ— NaN/Infå¼‚å¸¸
- [ ] **æ€§èƒ½æ•ˆç‡**: å‰å‘ä¼ æ’­æ— éœ€é‡‡æ ·
- [ ] **å†…å­˜ç®¡ç†**: å¤§æ¨¡å‹å¯æ­£å¸¸åŠ è½½
- [ ] **é”™è¯¯å¤„ç†**: å¼‚å¸¸æƒ…å†µä¼˜é›…å¤„ç†
- [ ] **å…¼å®¹æ€§**: ä¸transformersåº“å…¼å®¹

## æ•…éšœæ’æŸ¥æŒ‡å—

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. ç¯å¢ƒé—®é¢˜
- **PyTorchç‰ˆæœ¬ä¸å…¼å®¹**: å‡çº§åˆ°1.10+
- **CUDAå†…å­˜ä¸è¶³**: ä½¿ç”¨CPUæ¨¡å¼æˆ–å‡å°batch_size
- **Qwenæ¨¡å‹è·¯å¾„é”™è¯¯**: ç¡®è®¤ `~/models/Qwen2.5-0.5B` å­˜åœ¨

#### 2. æ¨¡å—å¯¼å…¥é—®é¢˜
- **ImportError**: æ£€æŸ¥ `src/` ç›®å½•æ˜¯å¦åœ¨Pythonè·¯å¾„ä¸­
- **ç‰ˆæœ¬ä¸åŒ¹é…**: ç¡®è®¤åœ¨æ­£ç¡®çš„gitåˆ†æ”¯ `causal-mvp`

#### 3. æ•°å­¦è®¡ç®—é—®é¢˜
- **ç»´åº¦ä¸åŒ¹é…**: æ£€æŸ¥ `causal_size = hidden_size` è®¾ç½®
- **æ¢¯åº¦æ¶ˆå¤±**: è°ƒæ•´å­¦ä¹ ç‡æˆ–åˆå§‹åŒ–ç­–ç•¥
- **æŸå¤±ä¸ºNaN**: æ£€æŸ¥OvRé˜ˆå€¼è®¾ç½®å’Œæ•°å€¼ç¨³å®šæ€§

#### 4. æ€§èƒ½é—®é¢˜
- **æ¨ç†é€Ÿåº¦æ…¢**: ç¡®è®¤ä½¿ç”¨ `torch.no_grad()` 
- **å†…å­˜å ç”¨é«˜**: è€ƒè™‘ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æˆ–æ¨¡å‹å¹¶è¡Œ

é€šè¿‡å®Œæˆæ‰€æœ‰æµ‹è¯•æ­¥éª¤å¹¶éªŒè¯ä¸Šè¿°æ¸…å•ï¼Œå¯ä»¥ç¡®ä¿¡CausalQwençš„å®ç°å¿ å®åœ°éµå¾ªäº†è®¾è®¡æ–‡æ¡£çš„ç†è®ºæ¡†æ¶ã€‚ 