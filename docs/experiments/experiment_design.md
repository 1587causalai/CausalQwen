# 因果语言模型实验设计

**作者**: Manus AI  
**版本**: 1.0  
**日期**: 2025年6月

## 实验目标

本实验旨在验证因果语言模型在数值预测任务上的有效性。通过对比微调前后的性能，我们将量化评估柯西分布建模和推断-行动范式对模型数值理解能力的提升。

## 实验设计

### 数据集设计

我们设计了四种类型的合成数据集，每种都针对不同的挑战场景：

1. **基础数值文本**：包含简单陈述句中的数字，如"The price is 25.5 dollars."
2. **问答格式**：以问答形式呈现的数字，测试模型的理解能力
3. **极端数值**：包含非常大或非常小的数字，验证重尾分布的优势
4. **边界值**：测试模型对特殊值（如0, 1）的处理能力

### 评估指标

- **分类准确率**：模型成功预测 `<NUM>` 词元的比例
- **平均排名**：`<NUM>` 词元在词汇表中的概率排名
- **回归误差**：数值预测的均方根误差（RMSE）

### 实验流程

1. 加载预训练模型（如Qwen2.5-0.5B）
2. 在评估数据集上测试基线性能
3. 使用因果框架微调模型
4. 重新评估微调后的性能
5. 分析结果并生成报告

## 预期结果

我们预期观察到：
- 分类准确率从接近0%提升到90%以上
- `<NUM>` 词元排名从数万名提升到前10名
- 回归误差显著降低，特别是在基础和边界值数据集上

这些结果将证明因果语言模型框架的有效性和实用价值。

