#!/usr/bin/env python3
"""
æµ‹è¯•CausalEngineçš„é»˜è®¤åˆå§‹åŒ–å€¼
"""

import numpy as np
import torch
import sys
sys.path.append('/Users/gongqian/DailyLog/CausalQwen')

from causal_engine.sklearn import MLPCausalRegressor

def test_default_initialization():
    """æµ‹è¯•é»˜è®¤åˆå§‹åŒ–æ˜¯å¦ç¬¦åˆé¢„æœŸ"""
    print("ğŸ” æµ‹è¯•CausalEngineé»˜è®¤åˆå§‹åŒ–å€¼...")
    
    # åˆ›å»ºé»˜è®¤é…ç½®çš„å›å½’å™¨
    print("\n1. åˆ›å»ºé»˜è®¤å›å½’å™¨:")
    regressor = MLPCausalRegressor()
    
    print(f"  æœŸæœ›: b_noise_init=0.1, gamma_init=10.0, ovr_threshold_init=0.0")
    print(f"  å®é™…: b_noise_init={regressor.b_noise_init}, gamma_init={regressor.gamma_init}, ovr_threshold_init={regressor.ovr_threshold_init}")
    
    # éªŒè¯é»˜è®¤å€¼
    assert regressor.b_noise_init == 0.1, f"b_noise_inité”™è¯¯: æœŸæœ›0.1, å®é™…{regressor.b_noise_init}"
    assert regressor.gamma_init == 10.0, f"gamma_inité”™è¯¯: æœŸæœ›10.0, å®é™…{regressor.gamma_init}"
    assert regressor.ovr_threshold_init == 0.0, f"ovr_threshold_inité”™è¯¯: æœŸæœ›0.0, å®é™…{regressor.ovr_threshold_init}"
    
    # åˆ›å»ºæœ€å°æ•°æ®é›†æ¥è§¦å‘æ¨¡å‹æ„å»º
    print("\n2. æ„å»ºæ¨¡å‹éªŒè¯å‚æ•°ä¼ é€’:")
    X = np.random.randn(10, 3)
    y = np.random.randn(10)
    
    # åªè®­ç»ƒ1è½®æ¥è§¦å‘æ¨¡å‹æ„å»º
    regressor.max_iter = 1
    regressor.verbose = False
    regressor.fit(X, y)
    
    # æ£€æŸ¥CausalEngineå†…éƒ¨å‚æ•°
    print("\n3. æ£€æŸ¥CausalEngineå†…éƒ¨å‚æ•°:")
    causal_engine = regressor.model['causal_engine']
    
    # æ£€æŸ¥b_noise
    b_noise = causal_engine.action.b_noise
    print(f"  b_noiseå½¢çŠ¶: {b_noise.shape}, å€¼: {b_noise}")
    print(f"  b_noiseå¹³å‡å€¼: {b_noise.mean().item():.6f} (æœŸæœ›çº¦0.1)")
    
    # æ£€æŸ¥gamma_Uçš„åˆå§‹åŒ–
    # éœ€è¦åˆ›å»ºæµ‹è¯•è¾“å…¥æ¥è·å–gamma_U
    actual_causal_size = causal_engine.causal_size
    print(f"  å®é™…causal_size: {actual_causal_size}")
    test_input = torch.randn(1, 1, actual_causal_size, dtype=torch.double)
    with torch.no_grad():
        loc_U, scale_U = causal_engine.abduction(test_input)
    
    gamma_U = scale_U.squeeze()
    print(f"  gamma_Uå½¢çŠ¶: {gamma_U.shape}, å€¼: {gamma_U}")
    print(f"  gamma_UèŒƒå›´: [{gamma_U.min().item():.3f}, {gamma_U.max().item():.3f}]")
    print(f"  gamma_Uå¹³å‡å€¼: {gamma_U.mean().item():.3f}")
    
    # éªŒè¯gamma_Uæ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
    # ç”±äºgamma_init=10.0ï¼Œä½†å®é™…åˆå§‹åŒ–ä½¿ç”¨linspace(1.0, 2.0)ï¼Œæˆ‘ä»¬éœ€è¦çœ‹å®é™…æ•ˆæœ
    print(f"\n4. åˆ†ægamma_Uåˆå§‹åŒ–:")
    print(f"  é…ç½®çš„gamma_init: {regressor.gamma_init}")
    print(f"  å®é™…gamma_UèŒƒå›´: [{gamma_U.min().item():.3f}, {gamma_U.max().item():.3f}]")
    
    # æ£€æŸ¥scale_netçš„biasæ¥ç†è§£åˆå§‹åŒ–
    abduction = causal_engine.abduction
    linear_modules = [m for m in abduction.scale_net.modules() if isinstance(m, torch.nn.Linear)]
    if linear_modules:
        last_layer = linear_modules[-1]
        bias_values = last_layer.bias.data
        print(f"  scale_netæœ€åå±‚bias: {bias_values}")
        print(f"  softplus(bias): {torch.nn.functional.softplus(bias_values)}")
    
    print(f"\nâœ… é»˜è®¤åˆå§‹åŒ–éªŒè¯å®Œæˆ!")
    return regressor

if __name__ == "__main__":
    regressor = test_default_initialization()